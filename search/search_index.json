{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"KYCC - Know Your Customer's Customer","text":""},{"location":"#overview","title":"Overview","text":"<p>KYCC (Know Your Customer's Customer) is an enterprise-grade supply chain credit scoring platform. It models companies (parties), their business relationships, and transaction history to compute creditworthiness scores using a transparent, auditable scorecard model enhanced by machine learning.</p>"},{"location":"#core-philosophy","title":"Core Philosophy","text":"<p>\"The Scorecard is King, Artificial Intelligence is the Advisor.\"</p> <p>Unlike black-box AI models that make decisions without explanation, KYCC uses an Expert Scorecard as the source of truth. The scorecard contains human-defined rules based on domain expertise. Machine learning operates in an advisory capacity, analyzing patterns in historical data and proposing improvements to scorecard weights only when it can demonstrate measurable performance gains.</p> <p>This approach ensures:</p> <ul> <li>Full transparency and explainability for every credit decision</li> <li>Regulatory compliance with credit scoring requirements</li> <li>Human oversight of the scoring logic</li> <li>Continuous improvement through ML-driven refinement</li> </ul>"},{"location":"#what-the-system-does","title":"What the System Does","text":"<ol> <li>Models Supply Chain Entities: Stores parties (suppliers, manufacturers, distributors, retailers), their relationships, and transaction history</li> <li>Extracts Features: Automatically derives meaningful signals from raw data including KYC scores, transaction patterns, and network metrics</li> <li>Computes Credit Scores: Applies weighted scorecard rules to produce 300-900 credit scores</li> <li>Learns and Improves: ML models train on historical outcomes and propose scorecard refinements</li> <li>Maintains Auditability: Logs all scoring requests with full feature snapshots for compliance</li> </ol>"},{"location":"#technology-stack","title":"Technology Stack","text":"Layer Technology Purpose Backend API FastAPI + Python 3.11 REST API with automatic OpenAPI documentation Database PostgreSQL 15 + SQLAlchemy 2.x Relational storage with ORM Orchestration Dagster Data pipeline orchestration and scheduling Validation Pydantic v2 Type-safe API schemas Frontend React + Vite Interactive web interface Visualization Recharts, ReactFlow Score charts and network graphs"},{"location":"#technology-rationale","title":"Technology Rationale","text":"<ul> <li>FastAPI: Type hints, async support, automatic OpenAPI documentation, Pydantic integration</li> <li>SQLAlchemy 2.x: Modern async support, clear ORM relationships, session management</li> <li>PostgreSQL: Native JSON support for feature snapshots, recursive CTEs for graph traversal, ACID guarantees</li> <li>Dagster: Asset-based pipelines, built-in observability, backfill support</li> <li>Pydantic v2: Strict validation, ORM mode for automatic conversion</li> </ul>"},{"location":"#key-concepts","title":"Key Concepts","text":""},{"location":"#parties","title":"Parties","text":"<p>Parties are the core entities in the supply chain. Each party represents a business entity such as:</p> <ul> <li>Suppliers</li> <li>Manufacturers</li> <li>Distributors</li> <li>Retailers</li> <li>Customers</li> </ul>"},{"location":"#relationships","title":"Relationships","text":"<p>Relationships model the business connections between parties:</p> <ul> <li><code>supplies_to</code>: Supplier provides goods to another party</li> <li><code>manufactures_for</code>: Manufacturer produces for another party</li> <li><code>distributes_for</code>: Distributor handles logistics for another party</li> <li><code>sells_to</code>: Retailer sells to end customer</li> </ul>"},{"location":"#transactions","title":"Transactions","text":"<p>Transactions record financial activity between parties:</p> <ul> <li>Invoices</li> <li>Payments</li> <li>Credit notes</li> </ul>"},{"location":"#features","title":"Features","text":"<p>Features are computed numeric values derived from raw data that feed into the scoring model:</p> <ul> <li>KYC features (verification status, company age)</li> <li>Transaction features (volume, regularity, recency)</li> <li>Network features (counterparty count, network depth)</li> </ul>"},{"location":"#credit-scores","title":"Credit Scores","text":"<p>Credit scores range from 300-900 (similar to FICO) and are computed by applying scorecard weights to extracted features. Scores are categorized into bands:</p> Band Score Range Interpretation Excellent 750-900 Very low risk Good 650-749 Low risk Fair 500-649 Moderate risk Poor 300-499 High risk"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>KYCC/\n\u251c\u2500\u2500 backend/                    # FastAPI backend\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 api/               # API route handlers\n\u2502   \u2502   \u251c\u2500\u2500 adapters/          # Data source adapters\n\u2502   \u2502   \u251c\u2500\u2500 cache/             # TTL cache implementation\n\u2502   \u2502   \u251c\u2500\u2500 config/            # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 db/                # Database connection and CRUD\n\u2502   \u2502   \u251c\u2500\u2500 extractors/        # Feature extractors\n\u2502   \u2502   \u251c\u2500\u2500 models/            # SQLAlchemy models\n\u2502   \u2502   \u251c\u2500\u2500 rules/             # Business rule evaluation\n\u2502   \u2502   \u251c\u2500\u2500 schemas/           # Pydantic schemas\n\u2502   \u2502   \u251c\u2500\u2500 scorecard/         # Scorecard engine\n\u2502   \u2502   \u251c\u2500\u2500 services/          # Business logic services\n\u2502   \u2502   \u2514\u2500\u2500 validators/        # Data validators\n\u2502   \u251c\u2500\u2500 dagster_home/          # Dagster pipeline definitions\n\u2502   \u251c\u2500\u2500 data/                  # Synthetic data files\n\u2502   \u251c\u2500\u2500 scripts/               # Utility scripts\n\u2502   \u251c\u2500\u2500 tests/                 # Test suite\n\u2502   \u2514\u2500\u2500 main.py                # FastAPI application entry\n\u251c\u2500\u2500 frontend/                   # React frontend\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 api/               # API client\n\u2502   \u2502   \u251c\u2500\u2500 components/        # Reusable components\n\u2502   \u2502   \u2514\u2500\u2500 pages/             # Page components\n\u2502   \u2514\u2500\u2500 package.json\n\u251c\u2500\u2500 docs/                       # Documentation (this site)\n\u251c\u2500\u2500 docker-compose.yml          # Docker orchestration\n\u2514\u2500\u2500 mkdocs.yml                  # Documentation configuration\n</code></pre>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Quick Start Guide - Get up and running in minutes</li> <li>Architecture Overview - Understand the system design</li> <li>API Reference - Complete API documentation</li> <li>ML Pipeline - Machine learning workflow</li> </ul>"},{"location":"api/overview/","title":"API Overview","text":"<p>KYCC exposes a REST API for credit scoring, pipeline management, and data operations.</p>"},{"location":"api/overview/#base-url","title":"Base URL","text":"<ul> <li>Development: <code>http://localhost:8000</code></li> <li>API Documentation: <code>http://localhost:8000/docs</code> (Swagger UI)</li> <li>Alternative Docs: <code>http://localhost:8000/redoc</code> (ReDoc)</li> </ul>"},{"location":"api/overview/#authentication","title":"Authentication","text":"<p>Currently, the API does not require authentication for development purposes.</p> <p>For production deployment, implement: - API key authentication - OAuth 2.0 / JWT tokens - Rate limiting</p>"},{"location":"api/overview/#api-structure","title":"API Structure","text":"<pre><code>/api\n\u251c\u2500\u2500 /scoring          # Credit scoring endpoints\n\u2502   \u251c\u2500\u2500 POST /run\n\u2502   \u251c\u2500\u2500 GET /party/{id}\n\u2502   \u251c\u2500\u2500 GET /statistics\n\u2502   \u2514\u2500\u2500 /versions\n\u251c\u2500\u2500 /pipeline         # Dagster pipeline endpoints\n\u2502   \u251c\u2500\u2500 POST /trigger/{pipeline}\n\u2502   \u251c\u2500\u2500 GET /status/{run_id}\n\u2502   \u2514\u2500\u2500 GET /runs\n\u251c\u2500\u2500 /parties          # Party management\n\u2502   \u251c\u2500\u2500 GET /\n\u2502   \u251c\u2500\u2500 GET /{id}\n\u2502   \u251c\u2500\u2500 POST /\n\u2502   \u2514\u2500\u2500 PUT /{id}\n\u251c\u2500\u2500 /relationships    # Relationship management\n\u2502   \u251c\u2500\u2500 GET /\n\u2502   \u251c\u2500\u2500 GET /{id}\n\u2502   \u2514\u2500\u2500 POST /\n\u2514\u2500\u2500 /synthetic        # Synthetic data\n    \u251c\u2500\u2500 POST /ingest\n    \u2514\u2500\u2500 GET /batches\n</code></pre>"},{"location":"api/overview/#response-format","title":"Response Format","text":""},{"location":"api/overview/#success-response","title":"Success Response","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    // Response data\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:45Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/overview/#error-response","title":"Error Response","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"PARTY_NOT_FOUND\",\n    \"message\": \"Party with ID 123 not found\",\n    \"details\": {}\n  },\n  \"meta\": {\n    \"timestamp\": \"2024-01-15T10:30:45Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/overview/#http-status-codes","title":"HTTP Status Codes","text":"Code Meaning 200 Success 201 Created 400 Bad Request 404 Not Found 422 Validation Error 500 Internal Server Error"},{"location":"api/overview/#common-headers","title":"Common Headers","text":""},{"location":"api/overview/#request-headers","title":"Request Headers","text":"<pre><code>Content-Type: application/json\nAccept: application/json\n</code></pre>"},{"location":"api/overview/#response-headers","title":"Response Headers","text":"<pre><code>Content-Type: application/json\nX-Request-ID: req_abc123\nX-Response-Time: 45ms\n</code></pre>"},{"location":"api/overview/#pagination","title":"Pagination","text":"<p>List endpoints support pagination:</p> <pre><code>GET /api/parties?page=1&amp;per_page=20\n</code></pre> <p>Response includes pagination metadata:</p> <pre><code>{\n  \"data\": [...],\n  \"pagination\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 150,\n    \"total_pages\": 8,\n    \"has_next\": true,\n    \"has_prev\": false\n  }\n}\n</code></pre>"},{"location":"api/overview/#filtering","title":"Filtering","text":"<p>List endpoints support filtering:</p> <pre><code>GET /api/parties?party_type=supplier&amp;batch_id=BATCH_001\nGET /api/scoring/statistics?band=excellent\n</code></pre>"},{"location":"api/overview/#quick-reference","title":"Quick Reference","text":""},{"location":"api/overview/#score-a-party","title":"Score a Party","text":"<pre><code>curl -X POST http://localhost:8000/api/scoring/run \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"party_id\": 123}'\n</code></pre>"},{"location":"api/overview/#trigger-pipeline","title":"Trigger Pipeline","text":"<pre><code>curl -X POST http://localhost:8000/api/pipeline/trigger/full_scoring_pipeline \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"batch_id\": \"BATCH_001\"}'\n</code></pre>"},{"location":"api/overview/#get-party-details","title":"Get Party Details","text":"<pre><code>curl http://localhost:8000/api/parties/123\n</code></pre>"},{"location":"api/overview/#ingest-synthetic-data","title":"Ingest Synthetic Data","text":"<pre><code>curl -X POST http://localhost:8000/api/synthetic/ingest \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"batch_id\": \"BATCH_001\", \"file_path\": \"data/synthetic_profiles.json\"}'\n</code></pre>"},{"location":"api/overview/#rate-limiting","title":"Rate Limiting","text":"<p>Production deployments should implement rate limiting:</p> Endpoint Type Limit Scoring 100 requests/minute Pipeline triggers 10 requests/minute Read operations 1000 requests/minute"},{"location":"api/overview/#versioning","title":"Versioning","text":"<p>Current API version: v1 (implicit in paths)</p> <p>Future versions will use explicit versioning: - <code>/api/v1/scoring</code> - <code>/api/v2/scoring</code></p>"},{"location":"api/parties/","title":"Parties API","text":"<p>The parties API manages supply chain participants in the credit scoring system.</p>"},{"location":"api/parties/#endpoints","title":"Endpoints","text":"Method Endpoint Description GET /api/parties List all parties GET /api/parties/{id} Get party details POST /api/parties Create a party PUT /api/parties/{id} Update a party DELETE /api/parties/{id} Delete a party"},{"location":"api/parties/#party-schema","title":"Party Schema","text":"<pre><code>{\n  \"id\": 123,\n  \"party_name\": \"Acme Corporation\",\n  \"party_type\": \"supplier\",\n  \"kyc_verified\": true,\n  \"contact_person\": \"John Smith\",\n  \"email\": \"john@acme.com\",\n  \"phone\": \"+1-555-0123\",\n  \"address\": \"123 Main St, City, State 12345\",\n  \"tax_id\": \"12-3456789\",\n  \"batch_id\": \"BATCH_001\",\n  \"created_at\": \"2024-01-15T10:30:45Z\",\n  \"updated_at\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre>"},{"location":"api/parties/#fields","title":"Fields","text":"Field Type Required Description party_name string Yes Company or individual name party_type string Yes Role in supply chain kyc_verified boolean No KYC verification status contact_person string No Primary contact name email string No Contact email phone string No Contact phone address string No Business address tax_id string No Tax identification number batch_id string No Import batch identifier"},{"location":"api/parties/#party-types","title":"Party Types","text":"Type Description manufacturer Produces goods distributor Distributes goods supplier Supplies materials retailer Sells to consumers customer End customer"},{"location":"api/parties/#get-apiparties","title":"GET /api/parties","text":"<p>List all parties with filtering and pagination.</p>"},{"location":"api/parties/#parameters","title":"Parameters","text":"Parameter Type Location Description party_type string query Filter by party type batch_id string query Filter by batch kyc_verified boolean query Filter by KYC status search string query Search in party_name page integer query Page number (default: 1) per_page integer query Items per page (default: 20)"},{"location":"api/parties/#response","title":"Response","text":"<pre><code>{\n  \"parties\": [\n    {\n      \"id\": 123,\n      \"party_name\": \"Acme Corporation\",\n      \"party_type\": \"supplier\",\n      \"kyc_verified\": true,\n      \"batch_id\": \"BATCH_001\",\n      \"latest_score\": 720\n    },\n    {\n      \"id\": 124,\n      \"party_name\": \"Beta Industries\",\n      \"party_type\": \"manufacturer\",\n      \"kyc_verified\": true,\n      \"batch_id\": \"BATCH_001\",\n      \"latest_score\": 680\n    }\n  ],\n  \"pagination\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 150,\n    \"total_pages\": 8\n  }\n}\n</code></pre>"},{"location":"api/parties/#example","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/parties?party_type=supplier&amp;kyc_verified=true\"\n</code></pre>"},{"location":"api/parties/#get-apipartiesid","title":"GET /api/parties/{id}","text":"<p>Get detailed information about a party.</p>"},{"location":"api/parties/#parameters_1","title":"Parameters","text":"Parameter Type Location Description id integer path Party ID include_features boolean query Include extracted features include_scores boolean query Include score history include_relationships boolean query Include relationships"},{"location":"api/parties/#response_1","title":"Response","text":"<pre><code>{\n  \"id\": 123,\n  \"party_name\": \"Acme Corporation\",\n  \"party_type\": \"supplier\",\n  \"kyc_verified\": true,\n  \"contact_person\": \"John Smith\",\n  \"email\": \"john@acme.com\",\n  \"phone\": \"+1-555-0123\",\n  \"address\": \"123 Main St, City, State 12345\",\n  \"tax_id\": \"12-3456789\",\n  \"batch_id\": \"BATCH_001\",\n  \"created_at\": \"2024-01-15T10:30:45Z\",\n  \"updated_at\": \"2024-01-15T10:30:45Z\",\n  \"features\": {\n    \"kyc_verified\": 1.0,\n    \"company_age_years\": 5.2,\n    \"transaction_count_6m\": 45,\n    \"avg_transaction_amount\": 5250.50,\n    \"network_size\": 12\n  },\n  \"latest_score\": {\n    \"total_score\": 720,\n    \"band\": \"good\",\n    \"computed_at\": \"2024-01-15T10:30:45Z\"\n  },\n  \"relationships\": {\n    \"suppliers\": [\n      {\"id\": 200, \"party_name\": \"Raw Materials Inc\"}\n    ],\n    \"customers\": [\n      {\"id\": 300, \"party_name\": \"Retail Chain Co\"}\n    ]\n  }\n}\n</code></pre>"},{"location":"api/parties/#example_1","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/parties/123?include_features=true&amp;include_scores=true\"\n</code></pre>"},{"location":"api/parties/#post-apiparties","title":"POST /api/parties","text":"<p>Create a new party.</p>"},{"location":"api/parties/#request","title":"Request","text":"<pre><code>{\n  \"party_name\": \"New Company Inc\",\n  \"party_type\": \"distributor\",\n  \"kyc_verified\": false,\n  \"contact_person\": \"Jane Doe\",\n  \"email\": \"jane@newcompany.com\",\n  \"phone\": \"+1-555-9876\",\n  \"address\": \"456 Business Ave, City, State 54321\",\n  \"tax_id\": \"98-7654321\",\n  \"batch_id\": \"MANUAL_001\"\n}\n</code></pre>"},{"location":"api/parties/#response_2","title":"Response","text":"<pre><code>{\n  \"id\": 125,\n  \"party_name\": \"New Company Inc\",\n  \"party_type\": \"distributor\",\n  \"kyc_verified\": false,\n  \"created_at\": \"2024-01-15T11:00:00Z\",\n  \"message\": \"Party created successfully\"\n}\n</code></pre>"},{"location":"api/parties/#example_2","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/parties \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"party_name\": \"New Company Inc\",\n    \"party_type\": \"distributor\",\n    \"contact_person\": \"Jane Doe\",\n    \"email\": \"jane@newcompany.com\"\n  }'\n</code></pre>"},{"location":"api/parties/#put-apipartiesid","title":"PUT /api/parties/{id}","text":"<p>Update an existing party.</p>"},{"location":"api/parties/#parameters_2","title":"Parameters","text":"Parameter Type Location Description id integer path Party ID"},{"location":"api/parties/#request_1","title":"Request","text":"<pre><code>{\n  \"kyc_verified\": true,\n  \"email\": \"updated@company.com\",\n  \"phone\": \"+1-555-1111\"\n}\n</code></pre>"},{"location":"api/parties/#response_3","title":"Response","text":"<pre><code>{\n  \"id\": 123,\n  \"party_name\": \"Acme Corporation\",\n  \"kyc_verified\": true,\n  \"email\": \"updated@company.com\",\n  \"phone\": \"+1-555-1111\",\n  \"updated_at\": \"2024-01-15T12:00:00Z\",\n  \"message\": \"Party updated successfully\"\n}\n</code></pre>"},{"location":"api/parties/#example_3","title":"Example","text":"<pre><code>curl -X PUT http://localhost:8000/api/parties/123 \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"kyc_verified\": true}'\n</code></pre>"},{"location":"api/parties/#delete-apipartiesid","title":"DELETE /api/parties/{id}","text":"<p>Delete a party.</p>"},{"location":"api/parties/#parameters_3","title":"Parameters","text":"Parameter Type Location Description id integer path Party ID cascade boolean query Delete related records"},{"location":"api/parties/#response_4","title":"Response","text":"<pre><code>{\n  \"id\": 123,\n  \"message\": \"Party deleted successfully\",\n  \"related_deleted\": {\n    \"features\": 16,\n    \"scores\": 5,\n    \"relationships\": 3\n  }\n}\n</code></pre>"},{"location":"api/parties/#example_4","title":"Example","text":"<pre><code>curl -X DELETE \"http://localhost:8000/api/parties/123?cascade=true\"\n</code></pre>"},{"location":"api/parties/#batch-operations","title":"Batch Operations","text":""},{"location":"api/parties/#post-apipartiesbulk","title":"POST /api/parties/bulk","text":"<p>Create multiple parties:</p> <pre><code>{\n  \"parties\": [\n    {\"party_name\": \"Company A\", \"party_type\": \"supplier\"},\n    {\"party_name\": \"Company B\", \"party_type\": \"manufacturer\"}\n  ],\n  \"batch_id\": \"BULK_001\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"created\": 2,\n  \"batch_id\": \"BULK_001\",\n  \"party_ids\": [126, 127]\n}\n</code></pre>"},{"location":"api/parties/#error-responses","title":"Error Responses","text":""},{"location":"api/parties/#party-not-found","title":"Party Not Found","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"PARTY_NOT_FOUND\",\n    \"message\": \"Party with ID 999 not found\"\n  }\n}\n</code></pre>"},{"location":"api/parties/#validation-error","title":"Validation Error","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid party data\",\n    \"details\": {\n      \"party_type\": \"Invalid party type. Must be one of: manufacturer, distributor, supplier, retailer, customer\"\n    }\n  }\n}\n</code></pre>"},{"location":"api/parties/#duplicate-party","title":"Duplicate Party","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"DUPLICATE_PARTY\",\n    \"message\": \"Party with name 'Acme Corporation' already exists in batch BATCH_001\"\n  }\n}\n</code></pre>"},{"location":"api/pipeline/","title":"Pipeline API","text":"<p>The pipeline API triggers and monitors Dagster pipelines for batch processing.</p>"},{"location":"api/pipeline/#endpoints","title":"Endpoints","text":"Method Endpoint Description POST /api/pipeline/trigger/{pipeline} Trigger a pipeline GET /api/pipeline/status/{run_id} Get pipeline run status GET /api/pipeline/runs List pipeline runs POST /api/pipeline/cancel/{run_id} Cancel a running pipeline"},{"location":"api/pipeline/#available-pipelines","title":"Available Pipelines","text":"Pipeline Description full_scoring_pipeline Complete: ingest, features, score, labels, train, refine ingest_pipeline Ingest synthetic data only feature_extraction_pipeline Extract features for a batch scoring_pipeline Score a batch ml_training_pipeline Train ML model and refine scorecard"},{"location":"api/pipeline/#post-apipipelinetriggerpipeline","title":"POST /api/pipeline/trigger/{pipeline}","text":"<p>Trigger a pipeline execution.</p>"},{"location":"api/pipeline/#parameters","title":"Parameters","text":"Parameter Type Location Description pipeline string path Pipeline name"},{"location":"api/pipeline/#request-body","title":"Request Body","text":"<pre><code>{\n  \"batch_id\": \"BATCH_001\",\n  \"config\": {\n    \"scorecard_version\": \"v1\",\n    \"observation_window_days\": 180\n  }\n}\n</code></pre> Field Type Required Description batch_id string Yes Batch identifier config object No Pipeline-specific configuration"},{"location":"api/pipeline/#response","title":"Response","text":"<pre><code>{\n  \"run_id\": \"run_abc123\",\n  \"pipeline\": \"full_scoring_pipeline\",\n  \"status\": \"STARTED\",\n  \"batch_id\": \"BATCH_001\",\n  \"started_at\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre>"},{"location":"api/pipeline/#example","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/pipeline/trigger/full_scoring_pipeline \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"batch_id\": \"BATCH_001\"}'\n</code></pre>"},{"location":"api/pipeline/#get-apipipelinestatusrun_id","title":"GET /api/pipeline/status/{run_id}","text":"<p>Get status of a pipeline run.</p>"},{"location":"api/pipeline/#parameters_1","title":"Parameters","text":"Parameter Type Location Description run_id string path Pipeline run ID"},{"location":"api/pipeline/#response_1","title":"Response","text":"<pre><code>{\n  \"run_id\": \"run_abc123\",\n  \"pipeline\": \"full_scoring_pipeline\",\n  \"status\": \"SUCCESS\",\n  \"batch_id\": \"BATCH_001\",\n  \"started_at\": \"2024-01-15T10:30:45Z\",\n  \"ended_at\": \"2024-01-15T10:35:12Z\",\n  \"duration_seconds\": 267,\n  \"assets\": {\n    \"ingest_synthetic_batch\": {\n      \"status\": \"SUCCESS\",\n      \"started_at\": \"2024-01-15T10:30:45Z\",\n      \"ended_at\": \"2024-01-15T10:31:00Z\",\n      \"output\": {\n        \"parties_created\": 100\n      }\n    },\n    \"extract_features\": {\n      \"status\": \"SUCCESS\",\n      \"started_at\": \"2024-01-15T10:31:00Z\",\n      \"ended_at\": \"2024-01-15T10:32:30Z\",\n      \"output\": {\n        \"features_extracted\": 1600\n      }\n    },\n    \"score_batch\": {\n      \"status\": \"SUCCESS\",\n      \"started_at\": \"2024-01-15T10:32:30Z\",\n      \"ended_at\": \"2024-01-15T10:33:00Z\",\n      \"output\": {\n        \"parties_scored\": 100\n      }\n    },\n    \"generate_scorecard_labels\": {\n      \"status\": \"SUCCESS\",\n      \"started_at\": \"2024-01-15T10:33:00Z\",\n      \"ended_at\": \"2024-01-15T10:33:30Z\",\n      \"output\": {\n        \"labels_generated\": 100\n      }\n    },\n    \"train_model_asset\": {\n      \"status\": \"SUCCESS\",\n      \"started_at\": \"2024-01-15T10:33:30Z\",\n      \"ended_at\": \"2024-01-15T10:34:30Z\",\n      \"output\": {\n        \"model_id\": \"model_BATCH_001\",\n        \"auc_roc\": 0.72\n      }\n    },\n    \"refine_scorecard\": {\n      \"status\": \"SUCCESS\",\n      \"started_at\": \"2024-01-15T10:34:30Z\",\n      \"ended_at\": \"2024-01-15T10:35:12Z\",\n      \"output\": {\n        \"new_version\": \"ml_v20240115\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"api/pipeline/#status-values","title":"Status Values","text":"Status Description QUEUED Waiting to start STARTED Currently running SUCCESS Completed successfully FAILURE Failed with error CANCELED Manually canceled"},{"location":"api/pipeline/#example_1","title":"Example","text":"<pre><code>curl http://localhost:8000/api/pipeline/status/run_abc123\n</code></pre>"},{"location":"api/pipeline/#get-apipipelineruns","title":"GET /api/pipeline/runs","text":"<p>List recent pipeline runs.</p>"},{"location":"api/pipeline/#parameters_2","title":"Parameters","text":"Parameter Type Location Description pipeline string query Filter by pipeline name status string query Filter by status batch_id string query Filter by batch limit integer query Max results (default: 20)"},{"location":"api/pipeline/#response_2","title":"Response","text":"<pre><code>{\n  \"runs\": [\n    {\n      \"run_id\": \"run_abc123\",\n      \"pipeline\": \"full_scoring_pipeline\",\n      \"status\": \"SUCCESS\",\n      \"batch_id\": \"BATCH_001\",\n      \"started_at\": \"2024-01-15T10:30:45Z\",\n      \"duration_seconds\": 267\n    },\n    {\n      \"run_id\": \"run_xyz789\",\n      \"pipeline\": \"scoring_pipeline\",\n      \"status\": \"FAILURE\",\n      \"batch_id\": \"BATCH_002\",\n      \"started_at\": \"2024-01-14T14:00:00Z\",\n      \"duration_seconds\": 45,\n      \"error\": \"Batch not found\"\n    }\n  ],\n  \"total\": 50,\n  \"page\": 1,\n  \"per_page\": 20\n}\n</code></pre>"},{"location":"api/pipeline/#example_2","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/pipeline/runs?status=FAILURE&amp;limit=10\"\n</code></pre>"},{"location":"api/pipeline/#post-apipipelinecancelrun_id","title":"POST /api/pipeline/cancel/{run_id}","text":"<p>Cancel a running pipeline.</p>"},{"location":"api/pipeline/#parameters_3","title":"Parameters","text":"Parameter Type Location Description run_id string path Pipeline run ID"},{"location":"api/pipeline/#response_3","title":"Response","text":"<pre><code>{\n  \"run_id\": \"run_abc123\",\n  \"status\": \"CANCELING\",\n  \"message\": \"Pipeline cancellation requested\"\n}\n</code></pre>"},{"location":"api/pipeline/#example_3","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/pipeline/cancel/run_abc123\n</code></pre>"},{"location":"api/pipeline/#pipeline-configuration","title":"Pipeline Configuration","text":""},{"location":"api/pipeline/#full_scoring_pipeline","title":"full_scoring_pipeline","text":"<pre><code>{\n  \"batch_id\": \"BATCH_001\",\n  \"config\": {\n    \"scorecard_version\": \"v1\",\n    \"observation_window_days\": 180,\n    \"blend_factor\": 0.5\n  }\n}\n</code></pre>"},{"location":"api/pipeline/#ml_training_pipeline","title":"ml_training_pipeline","text":"<pre><code>{\n  \"batch_id\": \"BATCH_001\",\n  \"config\": {\n    \"test_size\": 0.2,\n    \"min_samples\": 100,\n    \"auc_threshold\": 0.60\n  }\n}\n</code></pre>"},{"location":"api/pipeline/#webhook-notifications","title":"Webhook Notifications","text":"<p>Configure webhooks to receive pipeline completion notifications:</p>"},{"location":"api/pipeline/#post-apipipelinewebhooks","title":"POST /api/pipeline/webhooks","text":"<pre><code>{\n  \"url\": \"https://your-app.com/webhook\",\n  \"events\": [\"SUCCESS\", \"FAILURE\"],\n  \"pipelines\": [\"full_scoring_pipeline\"]\n}\n</code></pre> <p>Webhook payload:</p> <pre><code>{\n  \"event\": \"PIPELINE_COMPLETED\",\n  \"run_id\": \"run_abc123\",\n  \"pipeline\": \"full_scoring_pipeline\",\n  \"status\": \"SUCCESS\",\n  \"batch_id\": \"BATCH_001\",\n  \"timestamp\": \"2024-01-15T10:35:12Z\"\n}\n</code></pre>"},{"location":"api/pipeline/#error-responses","title":"Error Responses","text":""},{"location":"api/pipeline/#pipeline-not-found","title":"Pipeline Not Found","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"PIPELINE_NOT_FOUND\",\n    \"message\": \"Pipeline 'invalid_pipeline' not found\"\n  }\n}\n</code></pre>"},{"location":"api/pipeline/#run-not-found","title":"Run Not Found","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"RUN_NOT_FOUND\",\n    \"message\": \"Pipeline run 'run_invalid' not found\"\n  }\n}\n</code></pre>"},{"location":"api/pipeline/#pipeline-failed","title":"Pipeline Failed","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"PIPELINE_FAILED\",\n    \"message\": \"Pipeline execution failed\",\n    \"details\": {\n      \"failed_asset\": \"train_model_asset\",\n      \"error\": \"Insufficient samples: 50 &lt; 100\"\n    }\n  }\n}\n</code></pre>"},{"location":"api/relationships/","title":"Relationships API","text":"<p>The relationships API manages business connections between parties in the supply chain.</p>"},{"location":"api/relationships/#endpoints","title":"Endpoints","text":"Method Endpoint Description GET /api/relationships List relationships GET /api/relationships/{id} Get relationship details POST /api/relationships Create relationship DELETE /api/relationships/{id} Delete relationship GET /api/relationships/network/{party_id} Get party network"},{"location":"api/relationships/#relationship-schema","title":"Relationship Schema","text":"<pre><code>{\n  \"id\": 1,\n  \"from_party_id\": 123,\n  \"to_party_id\": 456,\n  \"relationship_type\": \"supplies_to\",\n  \"strength\": 0.8,\n  \"established_date\": \"2023-01-15\",\n  \"metadata\": {\n    \"contract_value\": 100000,\n    \"contract_end_date\": \"2025-01-15\"\n  },\n  \"created_at\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre>"},{"location":"api/relationships/#fields","title":"Fields","text":"Field Type Required Description from_party_id integer Yes Source party ID to_party_id integer Yes Target party ID relationship_type string Yes Type of relationship strength float No Relationship strength (0-1) established_date date No When relationship started metadata object No Additional relationship data"},{"location":"api/relationships/#relationship-types","title":"Relationship Types","text":"Type Direction Description supplies_to from -&gt; to from supplies materials to to buys_from from &lt;- to from buys from to distributes_for from -&gt; to from distributes for to manufactures_for from -&gt; to from manufactures for to"},{"location":"api/relationships/#get-apirelationships","title":"GET /api/relationships","text":"<p>List relationships with filtering.</p>"},{"location":"api/relationships/#parameters","title":"Parameters","text":"Parameter Type Location Description party_id integer query Filter by party (either direction) from_party_id integer query Filter by source party to_party_id integer query Filter by target party relationship_type string query Filter by type page integer query Page number per_page integer query Items per page"},{"location":"api/relationships/#response","title":"Response","text":"<pre><code>{\n  \"relationships\": [\n    {\n      \"id\": 1,\n      \"from_party\": {\n        \"id\": 123,\n        \"party_name\": \"Acme Corp\"\n      },\n      \"to_party\": {\n        \"id\": 456,\n        \"party_name\": \"Beta Inc\"\n      },\n      \"relationship_type\": \"supplies_to\",\n      \"strength\": 0.8,\n      \"established_date\": \"2023-01-15\"\n    }\n  ],\n  \"pagination\": {\n    \"page\": 1,\n    \"per_page\": 20,\n    \"total\": 50\n  }\n}\n</code></pre>"},{"location":"api/relationships/#example","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/relationships?party_id=123\"\n</code></pre>"},{"location":"api/relationships/#get-apirelationshipsid","title":"GET /api/relationships/{id}","text":"<p>Get relationship details.</p>"},{"location":"api/relationships/#parameters_1","title":"Parameters","text":"Parameter Type Location Description id integer path Relationship ID"},{"location":"api/relationships/#response_1","title":"Response","text":"<pre><code>{\n  \"id\": 1,\n  \"from_party\": {\n    \"id\": 123,\n    \"party_name\": \"Acme Corp\",\n    \"party_type\": \"supplier\"\n  },\n  \"to_party\": {\n    \"id\": 456,\n    \"party_name\": \"Beta Inc\",\n    \"party_type\": \"manufacturer\"\n  },\n  \"relationship_type\": \"supplies_to\",\n  \"strength\": 0.8,\n  \"established_date\": \"2023-01-15\",\n  \"metadata\": {\n    \"contract_value\": 100000,\n    \"contract_end_date\": \"2025-01-15\"\n  },\n  \"created_at\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre>"},{"location":"api/relationships/#post-apirelationships","title":"POST /api/relationships","text":"<p>Create a new relationship.</p>"},{"location":"api/relationships/#request","title":"Request","text":"<pre><code>{\n  \"from_party_id\": 123,\n  \"to_party_id\": 456,\n  \"relationship_type\": \"supplies_to\",\n  \"strength\": 0.8,\n  \"established_date\": \"2023-01-15\",\n  \"metadata\": {\n    \"contract_value\": 100000\n  }\n}\n</code></pre>"},{"location":"api/relationships/#response_2","title":"Response","text":"<pre><code>{\n  \"id\": 2,\n  \"from_party_id\": 123,\n  \"to_party_id\": 456,\n  \"relationship_type\": \"supplies_to\",\n  \"message\": \"Relationship created successfully\"\n}\n</code></pre>"},{"location":"api/relationships/#example_1","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/relationships \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"from_party_id\": 123,\n    \"to_party_id\": 456,\n    \"relationship_type\": \"supplies_to\"\n  }'\n</code></pre>"},{"location":"api/relationships/#delete-apirelationshipsid","title":"DELETE /api/relationships/{id}","text":"<p>Delete a relationship.</p>"},{"location":"api/relationships/#parameters_2","title":"Parameters","text":"Parameter Type Location Description id integer path Relationship ID"},{"location":"api/relationships/#response_3","title":"Response","text":"<pre><code>{\n  \"id\": 1,\n  \"message\": \"Relationship deleted successfully\"\n}\n</code></pre>"},{"location":"api/relationships/#get-apirelationshipsnetworkparty_id","title":"GET /api/relationships/network/{party_id}","text":"<p>Get the full network graph for a party.</p>"},{"location":"api/relationships/#parameters_3","title":"Parameters","text":"Parameter Type Location Description party_id integer path Central party ID direction string query \"upstream\", \"downstream\", or \"both\" max_depth integer query Maximum traversal depth (default: 3)"},{"location":"api/relationships/#response_4","title":"Response","text":"<pre><code>{\n  \"center_party\": {\n    \"id\": 123,\n    \"party_name\": \"Acme Corp\",\n    \"party_type\": \"distributor\"\n  },\n  \"nodes\": [\n    {\n      \"id\": 123,\n      \"party_name\": \"Acme Corp\",\n      \"party_type\": \"distributor\",\n      \"depth\": 0\n    },\n    {\n      \"id\": 100,\n      \"party_name\": \"Supplier A\",\n      \"party_type\": \"supplier\",\n      \"depth\": 1\n    },\n    {\n      \"id\": 200,\n      \"party_name\": \"Retailer B\",\n      \"party_type\": \"retailer\",\n      \"depth\": 1\n    },\n    {\n      \"id\": 300,\n      \"party_name\": \"Raw Materials Inc\",\n      \"party_type\": \"manufacturer\",\n      \"depth\": 2\n    }\n  ],\n  \"edges\": [\n    {\n      \"from\": 100,\n      \"to\": 123,\n      \"relationship_type\": \"supplies_to\",\n      \"strength\": 0.8\n    },\n    {\n      \"from\": 123,\n      \"to\": 200,\n      \"relationship_type\": \"supplies_to\",\n      \"strength\": 0.6\n    },\n    {\n      \"from\": 300,\n      \"to\": 100,\n      \"relationship_type\": \"supplies_to\",\n      \"strength\": 0.9\n    }\n  ],\n  \"statistics\": {\n    \"total_nodes\": 4,\n    \"total_edges\": 3,\n    \"upstream_count\": 2,\n    \"downstream_count\": 1,\n    \"max_depth_reached\": 2\n  }\n}\n</code></pre>"},{"location":"api/relationships/#example_2","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/relationships/network/123?direction=both&amp;max_depth=3\"\n</code></pre>"},{"location":"api/relationships/#bulk-operations","title":"Bulk Operations","text":""},{"location":"api/relationships/#post-apirelationshipsbulk","title":"POST /api/relationships/bulk","text":"<p>Create multiple relationships:</p> <pre><code>{\n  \"relationships\": [\n    {\n      \"from_party_id\": 123,\n      \"to_party_id\": 456,\n      \"relationship_type\": \"supplies_to\"\n    },\n    {\n      \"from_party_id\": 123,\n      \"to_party_id\": 789,\n      \"relationship_type\": \"supplies_to\"\n    }\n  ]\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"created\": 2,\n  \"relationship_ids\": [3, 4]\n}\n</code></pre>"},{"location":"api/relationships/#network-analysis","title":"Network Analysis","text":""},{"location":"api/relationships/#get-apirelationshipsanalysisparty_id","title":"GET /api/relationships/analysis/{party_id}","text":"<p>Get network analysis metrics:</p> <pre><code>{\n  \"party_id\": 123,\n  \"metrics\": {\n    \"degree_centrality\": 0.45,\n    \"betweenness_centrality\": 0.32,\n    \"upstream_dependency\": 0.25,\n    \"downstream_reach\": 0.60,\n    \"network_diversity\": 0.78\n  },\n  \"risk_factors\": {\n    \"single_supplier_dependency\": false,\n    \"single_customer_dependency\": true,\n    \"isolated\": false\n  }\n}\n</code></pre>"},{"location":"api/relationships/#error-responses","title":"Error Responses","text":""},{"location":"api/relationships/#relationship-not-found","title":"Relationship Not Found","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"RELATIONSHIP_NOT_FOUND\",\n    \"message\": \"Relationship with ID 999 not found\"\n  }\n}\n</code></pre>"},{"location":"api/relationships/#invalid-parties","title":"Invalid Parties","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"INVALID_PARTIES\",\n    \"message\": \"One or both parties not found\",\n    \"details\": {\n      \"from_party_id\": 123,\n      \"from_party_exists\": true,\n      \"to_party_id\": 999,\n      \"to_party_exists\": false\n    }\n  }\n}\n</code></pre>"},{"location":"api/relationships/#self-reference","title":"Self-Reference","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"SELF_REFERENCE\",\n    \"message\": \"Cannot create relationship from party to itself\"\n  }\n}\n</code></pre>"},{"location":"api/relationships/#duplicate-relationship","title":"Duplicate Relationship","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"DUPLICATE_RELATIONSHIP\",\n    \"message\": \"Relationship between parties 123 and 456 already exists\"\n  }\n}\n</code></pre>"},{"location":"api/scoring/","title":"Scoring API","text":"<p>The scoring API computes and retrieves credit scores for parties.</p>"},{"location":"api/scoring/#endpoints","title":"Endpoints","text":"Method Endpoint Description POST /api/scoring/run Compute score for a party GET /api/scoring/party/{id} Get score for a party GET /api/scoring/batch/{batch_id} Get scores for a batch GET /api/scoring/statistics Get scoring statistics GET /api/scoring/versions List scorecard versions POST /api/scoring/versions/{id}/activate Activate a version"},{"location":"api/scoring/#post-apiscoringrun","title":"POST /api/scoring/run","text":"<p>Compute credit score for a party.</p>"},{"location":"api/scoring/#request","title":"Request","text":"<pre><code>{\n  \"party_id\": 123,\n  \"scorecard_version\": \"v1\",\n  \"source\": \"database\"\n}\n</code></pre> Parameter Type Required Description party_id integer Yes Party ID to score scorecard_version string No Scorecard version (default: active) source string No Data source: \"database\" or \"synthetic\""},{"location":"api/scoring/#response","title":"Response","text":"<pre><code>{\n  \"party_id\": 123,\n  \"total_score\": 720,\n  \"band\": \"good\",\n  \"scorecard_version\": \"v1\",\n  \"components\": [\n    {\n      \"feature\": \"kyc_verified\",\n      \"value\": 1.0,\n      \"weight\": 15,\n      \"contribution\": 15.0,\n      \"max_contribution\": 15.0\n    },\n    {\n      \"feature\": \"company_age_years\",\n      \"value\": 5.0,\n      \"weight\": 10,\n      \"contribution\": 100.0,\n      \"max_contribution\": 200.0\n    }\n  ],\n  \"rules_applied\": [],\n  \"explanation\": \"kyc_verified: 100% of maximum; company_age_years: 50% of maximum\",\n  \"computed_at\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre>"},{"location":"api/scoring/#example","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/scoring/run \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"party_id\": 123}'\n</code></pre>"},{"location":"api/scoring/#get-apiscoringpartyid","title":"GET /api/scoring/party/{id}","text":"<p>Get the most recent score for a party.</p>"},{"location":"api/scoring/#parameters","title":"Parameters","text":"Parameter Type Location Description id integer path Party ID include_history boolean query Include score history"},{"location":"api/scoring/#response_1","title":"Response","text":"<pre><code>{\n  \"party_id\": 123,\n  \"current_score\": {\n    \"total_score\": 720,\n    \"band\": \"good\",\n    \"scorecard_version\": \"v1\",\n    \"computed_at\": \"2024-01-15T10:30:45Z\"\n  },\n  \"history\": [\n    {\n      \"total_score\": 680,\n      \"band\": \"fair\",\n      \"computed_at\": \"2024-01-01T08:00:00Z\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api/scoring/#example_1","title":"Example","text":"<pre><code>curl http://localhost:8000/api/scoring/party/123?include_history=true\n</code></pre>"},{"location":"api/scoring/#get-apiscoringbatchbatch_id","title":"GET /api/scoring/batch/{batch_id}","text":"<p>Get scores for all parties in a batch.</p>"},{"location":"api/scoring/#parameters_1","title":"Parameters","text":"Parameter Type Location Description batch_id string path Batch identifier band string query Filter by band min_score integer query Minimum score filter max_score integer query Maximum score filter"},{"location":"api/scoring/#response_2","title":"Response","text":"<pre><code>{\n  \"batch_id\": \"BATCH_001\",\n  \"total_parties\": 100,\n  \"scored_parties\": 98,\n  \"scores\": [\n    {\n      \"party_id\": 123,\n      \"party_name\": \"Acme Corp\",\n      \"total_score\": 720,\n      \"band\": \"good\"\n    },\n    {\n      \"party_id\": 124,\n      \"party_name\": \"Beta Inc\",\n      \"total_score\": 650,\n      \"band\": \"fair\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api/scoring/#example_2","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/scoring/batch/BATCH_001?band=excellent\"\n</code></pre>"},{"location":"api/scoring/#get-apiscoringstatistics","title":"GET /api/scoring/statistics","text":"<p>Get aggregate scoring statistics.</p>"},{"location":"api/scoring/#parameters_2","title":"Parameters","text":"Parameter Type Location Description batch_id string query Filter by batch from_date datetime query Start date to_date datetime query End date"},{"location":"api/scoring/#response_3","title":"Response","text":"<pre><code>{\n  \"total_scored\": 1000,\n  \"band_distribution\": {\n    \"excellent\": {\n      \"count\": 150,\n      \"percentage\": 15.0\n    },\n    \"good\": {\n      \"count\": 350,\n      \"percentage\": 35.0\n    },\n    \"fair\": {\n      \"count\": 300,\n      \"percentage\": 30.0\n    },\n    \"poor\": {\n      \"count\": 150,\n      \"percentage\": 15.0\n    },\n    \"very_poor\": {\n      \"count\": 50,\n      \"percentage\": 5.0\n    }\n  },\n  \"score_statistics\": {\n    \"mean\": 652,\n    \"median\": 665,\n    \"std_dev\": 85,\n    \"min\": 320,\n    \"max\": 875\n  },\n  \"period\": {\n    \"from\": \"2024-01-01T00:00:00Z\",\n    \"to\": \"2024-01-15T23:59:59Z\"\n  }\n}\n</code></pre>"},{"location":"api/scoring/#example_3","title":"Example","text":"<pre><code>curl \"http://localhost:8000/api/scoring/statistics?batch_id=BATCH_001\"\n</code></pre>"},{"location":"api/scoring/#get-apiscoringversions","title":"GET /api/scoring/versions","text":"<p>List all scorecard versions.</p>"},{"location":"api/scoring/#parameters_3","title":"Parameters","text":"Parameter Type Location Description include_inactive boolean query Include inactive versions"},{"location":"api/scoring/#response_4","title":"Response","text":"<pre><code>{\n  \"versions\": [\n    {\n      \"version_id\": \"ml_v20240115\",\n      \"status\": \"active\",\n      \"base_version\": \"v1\",\n      \"model_id\": \"model_BATCH_001\",\n      \"created_at\": \"2024-01-15T10:30:45Z\",\n      \"activated_at\": \"2024-01-15T14:00:00Z\"\n    },\n    {\n      \"version_id\": \"v1\",\n      \"status\": \"inactive\",\n      \"base_version\": null,\n      \"model_id\": null,\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"activated_at\": \"2024-01-01T00:00:00Z\"\n    }\n  ],\n  \"active_version\": \"ml_v20240115\"\n}\n</code></pre>"},{"location":"api/scoring/#post-apiscoringversionsidactivate","title":"POST /api/scoring/versions/{id}/activate","text":"<p>Activate a scorecard version.</p>"},{"location":"api/scoring/#parameters_4","title":"Parameters","text":"Parameter Type Location Description id string path Version ID to activate"},{"location":"api/scoring/#response_5","title":"Response","text":"<pre><code>{\n  \"version_id\": \"v1\",\n  \"status\": \"active\",\n  \"activated_at\": \"2024-01-15T14:00:00Z\",\n  \"previous_version\": \"ml_v20240115\"\n}\n</code></pre>"},{"location":"api/scoring/#example_4","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/scoring/versions/v1/activate\n</code></pre>"},{"location":"api/scoring/#synthetic-scoring","title":"Synthetic Scoring","text":"<p>Score synthetic profiles without storing in database:</p>"},{"location":"api/scoring/#post-apiscoringsynthetic","title":"POST /api/scoring/synthetic","text":"<pre><code>{\n  \"profile\": {\n    \"party_name\": \"Test Company\",\n    \"party_type\": \"supplier\",\n    \"kyc_verified\": true,\n    \"company_age_years\": 5,\n    \"transaction_count\": 45,\n    \"avg_transaction_amount\": 5000,\n    \"network_size\": 10\n  }\n}\n</code></pre> <p>Response returns score without persisting data.</p>"},{"location":"api/scoring/#error-responses","title":"Error Responses","text":""},{"location":"api/scoring/#party-not-found","title":"Party Not Found","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"PARTY_NOT_FOUND\",\n    \"message\": \"Party with ID 999 not found\"\n  }\n}\n</code></pre>"},{"location":"api/scoring/#insufficient-features","title":"Insufficient Features","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"INSUFFICIENT_FEATURES\",\n    \"message\": \"Cannot compute score: missing required features\",\n    \"details\": {\n      \"missing_features\": [\"kyc_verified\", \"transaction_count_6m\"]\n    }\n  }\n}\n</code></pre>"},{"location":"api/scoring/#invalid-version","title":"Invalid Version","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"INVALID_VERSION\",\n    \"message\": \"Scorecard version 'v99' not found\"\n  }\n}\n</code></pre>"},{"location":"architecture/data-flow/","title":"Data Flow","text":"<p>This document describes how data flows through the KYCC system from ingestion to scoring.</p>"},{"location":"architecture/data-flow/#overview","title":"Overview","text":"<p>Data flows through KYCC in several distinct pathways:</p> <ol> <li>Scoring Flow: Real-time score computation for a party</li> <li>Batch Flow: Processing multiple parties through the Dagster pipeline</li> <li>Training Flow: ML model training on historical data</li> </ol>"},{"location":"architecture/data-flow/#scoring-flow","title":"Scoring Flow","text":"<p>When a score is requested for a party, data flows through these stages:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         API Request                                 \u2502\n\u2502              GET /api/scoring/run?party_id=123                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                      \u2502\n                                      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      ScoringService                                 \u2502\n\u2502                  compute_score(party_id=123)                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                      \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                           \u2502                           \u2502\n          \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 KYC Extractor   \u2502       \u2502 Txn Extractor   \u2502       \u2502 Network Extract \u2502\n\u2502                 \u2502       \u2502                 \u2502       \u2502                 \u2502\n\u2502 Party Table     \u2502       \u2502 Transaction Tbl \u2502       \u2502 Relationship Tbl\u2502\n\u2502 \u2193               \u2502       \u2502 \u2193               \u2502       \u2502 \u2193               \u2502\n\u2502 kyc_verified    \u2502       \u2502 txn_count_6m    \u2502       \u2502 network_size    \u2502\n\u2502 company_age     \u2502       \u2502 avg_amount      \u2502       \u2502 counterparties  \u2502\n\u2502 party_type      \u2502       \u2502 regularity      \u2502       \u2502 depth           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                         \u2502                         \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Feature Store                                  \u2502\n\u2502              features table (party_id=123)                          \u2502\n\u2502                                                                     \u2502\n\u2502  feature_name          | feature_value | valid_from    | valid_to   \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  kyc_verified          | 1.0           | 2024-01-01    | NULL       \u2502\n\u2502  company_age_years     | 3.5           | 2024-01-01    | NULL       \u2502\n\u2502  transaction_count_6m  | 45.0          | 2024-01-01    | NULL       \u2502\n\u2502  network_size          | 12.0          | 2024-01-01    | NULL       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Scorecard Engine                                 \u2502\n\u2502                                                                     \u2502\n\u2502  base_score = 300                                                   \u2502\n\u2502  + kyc_verified * 15     = 15                                       \u2502\n\u2502  + company_age * 10      = 35 (capped at 5 years)                   \u2502\n\u2502  + txn_count_6m * 20     = 180 (capped at 50)                       \u2502\n\u2502  + network_size * 10     = 60 (capped at 20)                        \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                   \u2502\n\u2502  raw_score = 590                                                    \u2502\n\u2502  final_score = max(300, min(900, 590)) = 590                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Score Request (Audit)                            \u2502\n\u2502                                                                     \u2502\n\u2502  id: req_123_batch_001                                              \u2502\n\u2502  party_id: 123                                                      \u2502\n\u2502  final_score: 590                                                   \u2502\n\u2502  score_band: fair                                                   \u2502\n\u2502  features_snapshot: {kyc_verified: 1.0, ...}                        \u2502\n\u2502  model_version: scorecard_v1.0                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      API Response                                   \u2502\n\u2502  {                                                                  \u2502\n\u2502    \"party_id\": 123,                                                 \u2502\n\u2502    \"total_score\": 590,                                              \u2502\n\u2502    \"band\": \"fair\",                                                  \u2502\n\u2502    \"confidence\": 0.85,                                              \u2502\n\u2502    \"explanation\": {...}                                             \u2502\n\u2502  }                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/data-flow/#batch-processing-flow","title":"Batch Processing Flow","text":"<p>The Dagster pipeline processes entire batches:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 1: Ingestion                                     \u2502\n\u2502                                                                     \u2502\n\u2502  BATCH_001_profiles.json                                            \u2502\n\u2502         \u2502                                                           \u2502\n\u2502         \u25bc                                                           \u2502\n\u2502  ingest_synthetic_batch                                             \u2502\n\u2502         \u2502                                                           \u2502\n\u2502         \u25bc                                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502  \u2502   parties   \u2502  \u2502transactions \u2502  \u2502relationships\u2502                 \u2502\n\u2502  \u2502   table     \u2502  \u2502   table     \u2502  \u2502    table    \u2502                 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 2: Feature Extraction                            \u2502\n\u2502                                                                     \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502     \u2502 kyc_features \u2502  \u2502txn_features  \u2502  \u2502net_features  \u2502           \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502            \u2502                 \u2502                 \u2502                    \u2502\n\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502                       features_all                                  \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502                    \u2502  features table \u2502                              \u2502\n\u2502                    \u2502 (all parties)   \u2502                              \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 3: Scoring                                       \u2502\n\u2502                                                                     \u2502\n\u2502                      score_batch                                    \u2502\n\u2502                          \u2502                                          \u2502\n\u2502     For each party:      \u2502                                          \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502     \u2502 Load features      \u2502                    \u2502                    \u2502\n\u2502     \u2502 Apply scorecard    \u2502                    \u2502                    \u2502\n\u2502     \u2502 Save ScoreRequest  \u2502                    \u2502                    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2502\n\u2502               \u2502  score_requests     \u2502                               \u2502\n\u2502               \u2502  (all parties)      \u2502                               \u2502\n\u2502               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 4: Label Generation                              \u2502\n\u2502                                                                     \u2502\n\u2502                generate_scorecard_labels                            \u2502\n\u2502                          \u2502                                          \u2502\n\u2502     For each party:      \u2502                                          \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502     \u2502 Get score          \u2502                    \u2502                    \u2502\n\u2502     \u2502 Apply threshold    \u2502                    \u2502                    \u2502\n\u2502     \u2502 Create label       \u2502                    \u2502                    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2502\n\u2502               \u2502 ground_truth_labels \u2502                               \u2502\n\u2502               \u2502 (will_default 0/1)  \u2502                               \u2502\n\u2502               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/data-flow/#training-flow","title":"Training Flow","text":"<p>ML model training uses labeled historical data:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 5: Training Preparation                          \u2502\n\u2502                                                                     \u2502\n\u2502                  build_training_matrix                              \u2502\n\u2502                          \u2502                                          \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502     \u2502                    \u2502                    \u2502                    \u2502\n\u2502     \u25bc                    \u25bc                    \u25bc                    \u2502\n\u2502  features           ground_truth_labels    validation             \u2502\n\u2502     \u2502                    \u2502                    \u2502                    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502              \u2502   Training Matrix     \u2502                              \u2502\n\u2502              \u2502   X: features         \u2502                              \u2502\n\u2502              \u2502   y: will_default     \u2502                              \u2502\n\u2502              \u2502   train/test split    \u2502                              \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 6: Model Training                                \u2502\n\u2502                                                                     \u2502\n\u2502                   train_model_asset                                 \u2502\n\u2502                          \u2502                                          \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502     \u2502 Logistic Regression                     \u2502                    \u2502\n\u2502     \u2502 - balanced class weights                \u2502                    \u2502\n\u2502     \u2502 - L2 regularization                     \u2502                    \u2502\n\u2502     \u2502 - feature scaling                       \u2502                    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2502\n\u2502               \u2502  Trained Model      \u2502                               \u2502\n\u2502               \u2502  - coefficients     \u2502                               \u2502\n\u2502               \u2502  - scaler           \u2502                               \u2502\n\u2502               \u2502  - metrics          \u2502                               \u2502\n\u2502               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Stage 7: Scorecard Refinement                          \u2502\n\u2502                                                                     \u2502\n\u2502                    refine_scorecard                                 \u2502\n\u2502                          \u2502                                          \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502     \u2502 Extract weights from coefficients       \u2502                    \u2502\n\u2502     \u2502 Apply quality gates:                    \u2502                    \u2502\n\u2502     \u2502   - AUC &gt;= 0.55                         \u2502                    \u2502\n\u2502     \u2502   - Improvement &gt;= 0.5%                 \u2502                    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                          \u2502                                          \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502              \u2502                       \u2502                              \u2502\n\u2502              \u25bc                       \u25bc                              \u2502\n\u2502       Passes Gates            Fails Gates                          \u2502\n\u2502              \u2502                       \u2502                              \u2502\n\u2502              \u25bc                       \u25bc                              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502    \u2502 New Version     \u2502    \u2502 Failed Version  \u2502                      \u2502\n\u2502    \u2502 status: active  \u2502    \u2502 status: failed  \u2502                      \u2502\n\u2502    \u2502 (retire old)    \u2502    \u2502 (for review)    \u2502                      \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/data-flow/#data-transformations","title":"Data Transformations","text":""},{"location":"architecture/data-flow/#raw-data-to-features","title":"Raw Data to Features","text":"Source Raw Data Feature Transformation Party <code>created_at</code> <code>company_age_years</code> <code>(now - created_at).days / 365.25</code> Party <code>kyc_verified</code> <code>kyc_verified</code> Direct boolean to float Party <code>tax_id</code> <code>has_tax_id</code> <code>1.0 if exists else 0.0</code> Transaction count <code>transaction_count_6m</code> Count where date &gt;= 6 months ago Transaction amounts <code>avg_transaction_amount</code> <code>sum(amounts) / count</code> Transaction monthly volumes <code>transaction_regularity_score</code> <code>100 - (std/mean * 100)</code> Relationship count <code>direct_counterparty_count</code> Count upstream + downstream Relationship graph <code>network_size</code> Recursive traversal count"},{"location":"architecture/data-flow/#features-to-score","title":"Features to Score","text":"<pre><code>final_score = base_score + sum(\n    scaled_feature_value * weight\n    for feature, weight in scorecard.weights.items()\n)\n\nfinal_score = clip(final_score, 300, 900)\n</code></pre>"},{"location":"architecture/data-flow/#score-to-band","title":"Score to Band","text":"Score Range Band 750-900 Excellent 650-749 Good 500-649 Fair 300-499 Poor"},{"location":"architecture/data-flow/#cache-layer","title":"Cache Layer","text":"<p>Features are cached to avoid repeated extraction:</p> <pre><code>Request \u2192 Check Cache \u2192 Cache Hit? \u2192 Return cached features\n                            \u2502\n                            \u25bc Cache Miss\n                     Extract features\n                            \u2502\n                            \u25bc\n                     Store in cache (TTL: 5 min)\n                            \u2502\n                            \u25bc\n                     Store in database\n                            \u2502\n                            \u25bc\n                     Return features\n</code></pre> <p>Cache key format: <code>party:{party_id}:features:all</code></p>"},{"location":"architecture/overview/","title":"System Architecture Overview","text":"<p>This document provides a comprehensive overview of the KYCC system architecture.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              Frontend (React + Vite)                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Dashboard   \u2502 \u2502 ML Dashboard \u2502 \u2502  Party List  \u2502 \u2502  Network Graph   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502 REST API (HTTP/JSON)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           FastAPI Backend                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                        API Layer (Routers)                         \u2502    \u2502\n\u2502  \u2502  /api/scoring  \u2502  /api/pipeline  \u2502  /api/parties  \u2502  /api/...     \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                       Service Layer                                \u2502    \u2502\n\u2502  \u2502  ScoringService \u2502 FeaturePipelineService \u2502 ModelTrainingService   \u2502    \u2502\n\u2502  \u2502  LabelGenerationService \u2502 ScorecardVersionService \u2502 Analytics     \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                      Domain Layer                                  \u2502    \u2502\n\u2502  \u2502  Extractors \u2502 Scorecard Engine \u2502 Rule Evaluator \u2502 Adapters        \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                    \u2502                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                    Data Access Layer                               \u2502    \u2502\n\u2502  \u2502  SQLAlchemy ORM \u2502 Session Management \u2502 CRUD Operations            \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Dagster Pipeline                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502  Ingest    \u2502 \u2502  Features  \u2502 \u2502   Score    \u2502 \u2502   Train    \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PostgreSQL Database                                      \u2502\n\u2502  parties \u2502 transactions \u2502 relationships \u2502 features \u2502 scores \u2502 models       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/overview/#component-layers","title":"Component Layers","text":""},{"location":"architecture/overview/#1-presentation-layer-frontend","title":"1. Presentation Layer (Frontend)","text":"<p>The React frontend provides user interfaces for:</p> Component Purpose Dashboard Pipeline management, batch monitoring ML Dashboard Scorecard versions, weight evolution Party List CRUD operations for parties Party Detail Individual party view with scoring Network Graph Supply chain visualization Credit Score Score visualization <p>Technology: React 18, Vite, React Router v7, Recharts, ReactFlow</p>"},{"location":"architecture/overview/#2-api-layer","title":"2. API Layer","text":"<p>FastAPI routers expose RESTful endpoints:</p> Router Prefix Responsibility <code>scoring_v2</code> <code>/api/scoring</code> Score computation, history, versions <code>pipeline</code> <code>/api/pipeline</code> Batch management, training triggers <code>parties</code> <code>/api/parties</code> Party CRUD <code>relationships</code> <code>/api/relationships</code> Relationship CRUD <code>synthetic</code> <code>/synthetic</code> Synthetic data ingestion <p>Location: <code>backend/app/api/</code></p>"},{"location":"architecture/overview/#3-service-layer","title":"3. Service Layer","text":"<p>Business logic services orchestrate operations:</p> Service Responsibility <code>ScoringService</code> Score computation, model application <code>FeaturePipelineService</code> Feature extraction orchestration <code>ModelTrainingService</code> ML model training <code>LabelGenerationService</code> Ground truth label creation <code>ScorecardVersionService</code> Scorecard version management <code>AnalyticsService</code> Analytics and reporting <code>NetworkService</code> Network graph traversal <p>Location: <code>backend/app/services/</code></p>"},{"location":"architecture/overview/#4-domain-layer","title":"4. Domain Layer","text":"<p>Core business logic components:</p> Component Responsibility Feature Extractors Extract features from raw data Scorecard Engine Apply scorecard weights to features Rule Evaluator Evaluate business rules Adapters Normalize data from various sources Validators Validate data quality <p>Locations:  - <code>backend/app/extractors/</code> - <code>backend/app/scorecard/</code> - <code>backend/app/rules/</code> - <code>backend/app/adapters/</code> - <code>backend/app/validators/</code></p>"},{"location":"architecture/overview/#5-data-access-layer","title":"5. Data Access Layer","text":"<p>Database interaction through SQLAlchemy:</p> Component Responsibility Models SQLAlchemy table definitions Database Engine and session management CRUD Database operations <p>Location: <code>backend/app/db/</code>, <code>backend/app/models/</code></p>"},{"location":"architecture/overview/#6-pipeline-layer-dagster","title":"6. Pipeline Layer (Dagster)","text":"<p>Data pipeline orchestration:</p> Asset Responsibility <code>ingest_synthetic_batch</code> Load data from files <code>features_all</code> Extract all features <code>score_batch</code> Score all parties <code>generate_scorecard_labels</code> Create training labels <code>train_model_asset</code> Train ML model <code>refine_scorecard</code> Update scorecard weights <p>Location: <code>backend/dagster_home/definitions.py</code></p>"},{"location":"architecture/overview/#key-design-patterns","title":"Key Design Patterns","text":""},{"location":"architecture/overview/#1-extractor-pattern","title":"1. Extractor Pattern","text":"<p>All feature extractors inherit from <code>BaseFeatureExtractor</code>:</p> <pre><code>class BaseFeatureExtractor:\n    def get_source_type(self) -&gt; str:\n        \"\"\"Return source type identifier.\"\"\"\n        pass\n\n    def extract(self, party_id: int, db: Session, as_of_date: datetime = None) -&gt; List[FeatureExtractorResult]:\n        \"\"\"Extract features for a party.\"\"\"\n        pass\n</code></pre> <p>This pattern enables: - Consistent interface across extractors - Easy addition of new feature sources - Traceability through <code>source_type</code> metadata</p>"},{"location":"architecture/overview/#2-adapter-pattern","title":"2. Adapter Pattern","text":"<p>Data adapters normalize inputs from various sources:</p> <pre><code>class BaseAdapter:\n    def parse(self, data: dict) -&gt; dict:\n        \"\"\"Parse raw data into standard schema.\"\"\"\n        pass\n</code></pre> <p>Registry pattern enables runtime adapter selection:</p> <pre><code>AdapterRegistry.register(\"synthetic\", SyntheticAdapter)\nadapter = AdapterRegistry.get(\"synthetic\")\n</code></pre>"},{"location":"architecture/overview/#3-service-layer-pipeline","title":"3. Service Layer Pipeline","text":"<p>All scoring follows a consistent flow:</p> <pre><code>API Router\n    \u2514\u2500\u2500 ScoringService.compute_score()\n            \u251c\u2500\u2500 FeaturePipelineService.extract_all_features()\n            \u2502       \u251c\u2500\u2500 KYCFeatureExtractor.extract()\n            \u2502       \u251c\u2500\u2500 TransactionFeatureExtractor.extract()\n            \u2502       \u2514\u2500\u2500 NetworkFeatureExtractor.extract()\n            \u251c\u2500\u2500 ScorecardEngine.compute_scorecard_score()\n            \u251c\u2500\u2500 RuleEvaluator.evaluate()\n            \u2514\u2500\u2500 ScoreRequest (audit log)\n</code></pre>"},{"location":"architecture/overview/#4-temporal-versioning","title":"4. Temporal Versioning","text":"<p>Features use <code>valid_from</code>/<code>valid_to</code> for versioning:</p> <ul> <li><code>valid_to = NULL</code> indicates current version</li> <li>New features expire old ones</li> <li>Historical queries use date-based filtering</li> </ul>"},{"location":"architecture/overview/#communication-patterns","title":"Communication Patterns","text":""},{"location":"architecture/overview/#frontend-to-backend","title":"Frontend to Backend","text":"<ul> <li>Protocol: HTTP/JSON</li> <li>Authentication: None (development), JWT (production)</li> <li>Error Handling: HTTP status codes with JSON error bodies</li> </ul>"},{"location":"architecture/overview/#backend-to-database","title":"Backend to Database","text":"<ul> <li>ORM: SQLAlchemy 2.x</li> <li>Connection Pooling: Built-in pool</li> <li>Transactions: Per-request sessions</li> </ul>"},{"location":"architecture/overview/#dagster-to-backend","title":"Dagster to Backend","text":"<ul> <li>Shared database connection</li> <li>Direct Python imports of services</li> <li>Asset dependencies for ordering</li> </ul>"},{"location":"architecture/overview/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"architecture/overview/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Backend: Stateless, can run multiple instances</li> <li>Database: Read replicas for reporting</li> <li>Dagster: Distributed execution with Dagster+</li> </ul>"},{"location":"architecture/overview/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>TTL cache for feature lookups (5-minute default)</li> <li>Batch processing for large datasets</li> <li>Index optimization on frequently queried columns</li> <li>Lazy loading for relationships</li> </ul>"},{"location":"architecture/overview/#bottleneck-mitigation","title":"Bottleneck Mitigation","text":"Bottleneck Mitigation Database connections Connection pooling Feature extraction Parallel extractors Large batches Chunked processing Network graph traversal Depth limits"},{"location":"architecture/service-layer/","title":"Service Layer Architecture","text":"<p>The service layer contains the core business logic of KYCC. Services orchestrate operations between the API layer and data access layer.</p>"},{"location":"architecture/service-layer/#service-overview","title":"Service Overview","text":"Service File Responsibility ScoringService <code>scoring_service.py</code> Score computation and model application FeaturePipelineService <code>feature_pipeline_service.py</code> Feature extraction orchestration ModelTrainingService <code>model_training_service.py</code> ML model training LabelGenerationService <code>label_generation_service.py</code> Ground truth label creation ScorecardVersionService <code>scorecard_version_service.py</code> Scorecard version management AnalyticsService <code>analytics_service.py</code> Analytics and reporting NetworkService <code>network_service.py</code> Network graph operations FeatureValidationService <code>feature_validation_service.py</code> Feature quality validation FeatureMatrixBuilder <code>feature_matrix_builder.py</code> Training data preparation SyntheticSeedService <code>synthetic_seed_service.py</code> Synthetic data ingestion"},{"location":"architecture/service-layer/#scoringservice","title":"ScoringService","text":"<p>The main orchestrator for credit score computation.</p>"},{"location":"architecture/service-layer/#location","title":"Location","text":"<p><code>backend/app/services/scoring_service.py</code></p>"},{"location":"architecture/service-layer/#responsibilities","title":"Responsibilities","text":"<ul> <li>Coordinate feature extraction</li> <li>Fetch active scoring model</li> <li>Compute credit scores</li> <li>Apply decision rules</li> <li>Generate audit logs</li> </ul>"},{"location":"architecture/service-layer/#key-methods","title":"Key Methods","text":"<pre><code>class ScoringService:\n    def compute_score(\n        self, \n        party_id: int, \n        model_version: str = None,\n        include_explanation: bool = True\n    ) -&gt; dict:\n        \"\"\"\n        Compute credit score for a party.\n\n        Steps:\n        1. Ensure features exist\n        2. Get active model\n        3. Fetch features\n        4. Apply feature scaling\n        5. Compute score (scorecard or ML)\n        6. Normalize to 300-900\n        7. Assign score band\n        8. Apply decision rules\n        9. Generate explanation\n        10. Log score request\n        \"\"\"\n</code></pre>"},{"location":"architecture/service-layer/#score-computation-flow","title":"Score Computation Flow","text":"<pre><code>compute_score(party_id)\n    \u2502\n    \u251c\u2500\u2500 _ensure_features_exist(party_id)\n    \u2502       \u2514\u2500\u2500 FeaturePipelineService.extract_all_features()\n    \u2502\n    \u251c\u2500\u2500 Get active model from ModelRegistry or ScorecardVersion\n    \u2502\n    \u251c\u2500\u2500 _get_current_features(party_id, required_features)\n    \u2502\n    \u251c\u2500\u2500 Apply scaler if ML model\n    \u2502\n    \u251c\u2500\u2500 _compute_scorecard() or _compute_ml_model()\n    \u2502\n    \u251c\u2500\u2500 _normalize_score() \u2192 300-900 range\n    \u2502\n    \u251c\u2500\u2500 _get_score_band() \u2192 excellent/good/fair/poor\n    \u2502\n    \u251c\u2500\u2500 _compute_confidence()\n    \u2502\n    \u251c\u2500\u2500 _apply_decision_rules()\n    \u2502\n    \u251c\u2500\u2500 _generate_explanation()\n    \u2502\n    \u2514\u2500\u2500 Save ScoreRequest (audit log)\n</code></pre>"},{"location":"architecture/service-layer/#featurepipelineservice","title":"FeaturePipelineService","text":"<p>Orchestrates feature extraction from multiple sources.</p>"},{"location":"architecture/service-layer/#location_1","title":"Location","text":"<p><code>backend/app/services/feature_pipeline_service.py</code></p>"},{"location":"architecture/service-layer/#responsibilities_1","title":"Responsibilities","text":"<ul> <li>Coordinate all feature extractors</li> <li>Store extracted features</li> <li>Handle temporal versioning</li> </ul>"},{"location":"architecture/service-layer/#key-methods_1","title":"Key Methods","text":"<pre><code>class FeaturePipelineService:\n    def __init__(self, db: Session):\n        self.extractors = [\n            KYCFeatureExtractor(),\n            TransactionFeatureExtractor(),\n            NetworkFeatureExtractor()\n        ]\n\n    def extract_all_features(self, party_id: int, as_of_date: datetime = None) -&gt; dict:\n        \"\"\"Extract features from all sources for a party.\"\"\"\n\n    def extract_features(self, party_id: int, source_types: List[str] = None) -&gt; dict:\n        \"\"\"Extract features, optionally filtering by source type.\"\"\"\n\n    def run(self, batch_id: str) -&gt; dict:\n        \"\"\"Run feature extraction for all parties in a batch.\"\"\"\n\n    def run_single(self, batch_id: str, source: str) -&gt; dict:\n        \"\"\"Run extraction for a specific source.\"\"\"\n</code></pre>"},{"location":"architecture/service-layer/#source-type-mapping","title":"Source Type Mapping","text":"External Name Internal Type Extractor <code>kyc</code> <code>KYC</code> KYCFeatureExtractor <code>transaction</code> <code>TRANSACTIONS</code> TransactionFeatureExtractor <code>network</code> <code>RELATIONSHIPS</code> NetworkFeatureExtractor"},{"location":"architecture/service-layer/#modeltrainingservice","title":"ModelTrainingService","text":"<p>Handles ML model training on labeled data.</p>"},{"location":"architecture/service-layer/#location_2","title":"Location","text":"<p><code>backend/app/services/model_training_service.py</code></p>"},{"location":"architecture/service-layer/#responsibilities_2","title":"Responsibilities","text":"<ul> <li>Train logistic regression models</li> <li>Evaluate model performance</li> <li>Save models to registry</li> <li>Persist scalers</li> </ul>"},{"location":"architecture/service-layer/#key-methods_2","title":"Key Methods","text":"<pre><code>class ModelTrainingService:\n    def train_logistic_regression(\n        self,\n        X_train: pd.DataFrame,\n        y_train: pd.Series,\n        hyperparams: Dict = None\n    ) -&gt; Tuple[LogisticRegression, Dict]:\n        \"\"\"Train logistic regression with balanced class weights.\"\"\"\n\n    def evaluate_model(\n        self,\n        model: LogisticRegression,\n        X_test: pd.DataFrame,\n        y_test: pd.Series\n    ) -&gt; Dict:\n        \"\"\"Evaluate model with AUC, F1, precision, recall.\"\"\"\n\n    def save_to_registry(\n        self,\n        model: LogisticRegression,\n        metrics: Dict,\n        model_version: str,\n        scaler: Any = None\n    ) -&gt; Dict:\n        \"\"\"Save model and metrics to ModelRegistry.\"\"\"\n</code></pre>"},{"location":"architecture/service-layer/#default-hyperparameters","title":"Default Hyperparameters","text":"<pre><code>{\n    'C': 1.0,\n    'penalty': 'l2',\n    'max_iter': 1000,\n    'solver': 'lbfgs',\n    'class_weight': 'balanced'\n}\n</code></pre>"},{"location":"architecture/service-layer/#labelgenerationservice","title":"LabelGenerationService","text":"<p>Generates ground truth labels from scorecard scores.</p>"},{"location":"architecture/service-layer/#location_3","title":"Location","text":"<p><code>backend/app/services/label_generation_service.py</code></p>"},{"location":"architecture/service-layer/#responsibilities_3","title":"Responsibilities","text":"<ul> <li>Compute scorecard scores for all parties</li> <li>Determine default threshold</li> <li>Create binary labels</li> </ul>"},{"location":"architecture/service-layer/#key-methods_3","title":"Key Methods","text":"<pre><code>class LabelGenerationService:\n    def generate_labels_from_scorecard(\n        self,\n        features_list: List[Dict],\n        party_ids: List[int],\n        target_default_rate: float = 0.05,\n        batch_id: str = None\n    ) -&gt; Dict:\n        \"\"\"\n        Generate labels by thresholding scorecard scores.\n        Bottom X% are labeled as defaults.\n        \"\"\"\n\n    def determine_default_threshold(\n        self,\n        scores: List[float],\n        target_default_rate: float = 0.05\n    ) -&gt; float:\n        \"\"\"Calculate score threshold for target default rate.\"\"\"\n</code></pre>"},{"location":"architecture/service-layer/#label-generation-logic","title":"Label Generation Logic","text":"<ol> <li>Compute scorecard scores for all parties</li> <li>Find the score at the target percentile (e.g., 5th percentile)</li> <li>Parties below threshold: <code>will_default = 1</code></li> <li>Parties at or above threshold: <code>will_default = 0</code></li> </ol>"},{"location":"architecture/service-layer/#scorecardversionservice","title":"ScorecardVersionService","text":"<p>Manages versioned scorecards in the database.</p>"},{"location":"architecture/service-layer/#location_4","title":"Location","text":"<p><code>backend/app/services/scorecard_version_service.py</code></p>"},{"location":"architecture/service-layer/#responsibilities_4","title":"Responsibilities","text":"<ul> <li>Get active scorecard version</li> <li>Create new versions from ML refinement</li> <li>Enforce quality gates</li> <li>Retire old versions</li> </ul>"},{"location":"architecture/service-layer/#key-methods_4","title":"Key Methods","text":"<pre><code>class ScorecardVersionService:\n    def get_active_scorecard(self) -&gt; Dict:\n        \"\"\"Get currently active scorecard configuration.\"\"\"\n\n    def create_version_from_ml(\n        self,\n        weights: Dict[str, float],\n        ml_auc: float,\n        ml_f1: float,\n        ml_model_id: str = None,\n        notes: str = None\n    ) -&gt; Optional[ScorecardVersion]:\n        \"\"\"Create new version if it passes quality gates.\"\"\"\n\n    def ensure_initial_version(self):\n        \"\"\"Ensure initial expert scorecard exists.\"\"\"\n</code></pre>"},{"location":"architecture/service-layer/#quality-gates","title":"Quality Gates","text":"<pre><code>MIN_AUC_THRESHOLD = 0.55       # Minimum AUC to accept\nIMPROVEMENT_THRESHOLD = 0.005  # Must improve by 0.5%\n</code></pre> <p>If a model fails quality gates, it is saved with <code>status='failed'</code> for inspection.</p>"},{"location":"architecture/service-layer/#analyticsservice","title":"AnalyticsService","text":"<p>Provides analytics and reporting capabilities.</p>"},{"location":"architecture/service-layer/#location_5","title":"Location","text":"<p><code>backend/app/services/analytics_service.py</code></p>"},{"location":"architecture/service-layer/#key-methods_5","title":"Key Methods","text":"<pre><code>class AnalyticsService:\n    def get_scorecard_versions(self) -&gt; List[Dict]:\n        \"\"\"Get all scorecard versions with metadata.\"\"\"\n\n    def get_weights_evolution(self, top_n: int = 5) -&gt; Dict:\n        \"\"\"Get weight evolution for top features.\"\"\"\n\n    def get_score_impact(self, version_id: int, compare_to: int = None) -&gt; Dict:\n        \"\"\"Compare score distributions between versions.\"\"\"\n</code></pre>"},{"location":"architecture/service-layer/#service-dependencies","title":"Service Dependencies","text":"<pre><code>ScoringService\n    \u251c\u2500\u2500 FeaturePipelineService\n    \u2502       \u251c\u2500\u2500 KYCFeatureExtractor\n    \u2502       \u251c\u2500\u2500 TransactionFeatureExtractor\n    \u2502       \u2514\u2500\u2500 NetworkFeatureExtractor\n    \u251c\u2500\u2500 ScorecardEngine\n    \u2514\u2500\u2500 RuleEvaluator\n\nModelTrainingService\n    \u2514\u2500\u2500 FeatureMatrixBuilder\n\nLabelGenerationService\n    \u2514\u2500\u2500 ScorecardEngine\n\nScorecardVersionService\n    \u2514\u2500\u2500 (independent)\n\nAnalyticsService\n    \u2514\u2500\u2500 (independent)\n</code></pre>"},{"location":"architecture/service-layer/#error-handling","title":"Error Handling","text":"<p>Services follow consistent error handling:</p> <pre><code>try:\n    # Service operation\nexcept ValueError as e:\n    # Invalid input\n    raise HTTPException(status_code=400, detail=str(e))\nexcept Exception as e:\n    # Log error\n    logger.error(f\"Service error: {e}\")\n    raise\n</code></pre> <p>All services receive database sessions through dependency injection rather than creating their own sessions.</p>"},{"location":"dagster/assets/","title":"Dagster Assets","text":"<p>Assets are the core building blocks of KYCC pipelines, representing data artifacts produced by computations.</p>"},{"location":"dagster/assets/#asset-catalog","title":"Asset Catalog","text":"Asset Description Dependencies ingest_synthetic_batch Load synthetic profiles None extract_features Extract all features ingest_synthetic_batch extract_kyc_features Extract KYC features ingest_synthetic_batch extract_txn_features Extract transaction features ingest_synthetic_batch extract_network_features Extract network features ingest_synthetic_batch score_batch Compute credit scores extract_features generate_scorecard_labels Generate ML labels score_batch train_model_asset Train ML model generate_scorecard_labels refine_scorecard Refine scorecard weights train_model_asset"},{"location":"dagster/assets/#asset-definitions","title":"Asset Definitions","text":""},{"location":"dagster/assets/#ingest_synthetic_batch","title":"ingest_synthetic_batch","text":"<p>Loads synthetic profile data into the database.</p> <pre><code>@asset(\n    description=\"Ingest synthetic profiles from JSON file\",\n    group_name=\"data_ingestion\"\n)\ndef ingest_synthetic_batch(context) -&gt; dict:\n    \"\"\"\n    Load synthetic party profiles into the database.\n\n    Config:\n        batch_id: Unique identifier for this batch\n        file_path: Path to synthetic_profiles.json\n\n    Returns:\n        dict with parties_created count\n    \"\"\"\n    batch_id = context.op_config.get(\"batch_id\", f\"BATCH_{datetime.now():%Y%m%d}\")\n    file_path = context.op_config.get(\"file_path\", \"data/synthetic_profiles.json\")\n\n    db = context.resources.database\n\n    with open(file_path) as f:\n        profiles = json.load(f)\n\n    parties_created = 0\n    for profile in profiles:\n        party = Party(\n            party_name=profile[\"company_name\"],\n            party_type=profile[\"party_type\"],\n            kyc_verified=profile.get(\"kyc_verified\", False),\n            batch_id=batch_id,\n            # ... other fields\n        )\n        db.add(party)\n        parties_created += 1\n\n    db.commit()\n\n    context.log.info(f\"Created {parties_created} parties in batch {batch_id}\")\n\n    return {\n        \"batch_id\": batch_id,\n        \"parties_created\": parties_created\n    }\n</code></pre>"},{"location":"dagster/assets/#extract_features","title":"extract_features","text":"<p>Extracts features from all sources for a batch.</p> <pre><code>@asset(\n    description=\"Extract features from all sources for batch parties\",\n    group_name=\"feature_extraction\",\n    deps=[ingest_synthetic_batch]\n)\ndef extract_features(context, ingest_synthetic_batch: dict) -&gt; dict:\n    \"\"\"\n    Run feature extraction pipeline for all parties in batch.\n\n    Returns:\n        dict with features_extracted count\n    \"\"\"\n    batch_id = ingest_synthetic_batch[\"batch_id\"]\n    db = context.resources.database\n\n    pipeline = FeaturePipelineService(db)\n    result = pipeline.run(batch_id)\n\n    context.log.info(f\"Extracted features for {result['processed_parties']} parties\")\n\n    return {\n        \"batch_id\": batch_id,\n        \"features_extracted\": result[\"processed_parties\"] * 16  # ~16 features per party\n    }\n</code></pre>"},{"location":"dagster/assets/#extract_kyc_features","title":"extract_kyc_features","text":"<p>Extracts only KYC features.</p> <pre><code>@asset(\n    description=\"Extract KYC features only\",\n    group_name=\"feature_extraction\",\n    deps=[ingest_synthetic_batch]\n)\ndef extract_kyc_features(context, ingest_synthetic_batch: dict) -&gt; dict:\n    \"\"\"Extract KYC features for batch.\"\"\"\n    batch_id = ingest_synthetic_batch[\"batch_id\"]\n    db = context.resources.database\n\n    pipeline = FeaturePipelineService(db)\n    result = pipeline.run_single(batch_id, source=\"kyc\")\n\n    return {\n        \"batch_id\": batch_id,\n        \"source\": \"KYC\",\n        \"features_extracted\": result[\"features_count\"]\n    }\n</code></pre>"},{"location":"dagster/assets/#score_batch","title":"score_batch","text":"<p>Computes credit scores for all parties in a batch.</p> <pre><code>@asset(\n    description=\"Score all parties in batch\",\n    group_name=\"scoring\",\n    deps=[extract_features]\n)\ndef score_batch(context, extract_features: dict) -&gt; dict:\n    \"\"\"\n    Compute credit scores for batch.\n\n    Config:\n        scorecard_version: Version of scorecard to use\n\n    Returns:\n        dict with scoring statistics\n    \"\"\"\n    batch_id = extract_features[\"batch_id\"]\n    version = context.op_config.get(\"scorecard_version\", \"v1\")\n\n    db = context.resources.database\n    scoring_service = ScoringService(db)\n\n    result = scoring_service.score_batch(batch_id, scorecard_version=version)\n\n    context.log.info(f\"Scored {result['scored_count']} parties\")\n\n    # Calculate statistics\n    scores = [r[\"total_score\"] for r in result[\"results\"] if r.get(\"total_score\")]\n\n    return {\n        \"batch_id\": batch_id,\n        \"scored_count\": result[\"scored_count\"],\n        \"error_count\": result[\"error_count\"],\n        \"avg_score\": statistics.mean(scores) if scores else 0,\n        \"score_distribution\": _calculate_distribution(scores)\n    }\n</code></pre>"},{"location":"dagster/assets/#generate_scorecard_labels","title":"generate_scorecard_labels","text":"<p>Generates ground truth labels for ML training.</p> <pre><code>@asset(\n    description=\"Generate ground truth labels for ML training\",\n    group_name=\"ml_pipeline\",\n    deps=[score_batch]\n)\ndef generate_scorecard_labels(context, score_batch: dict) -&gt; dict:\n    \"\"\"\n    Generate labels based on credit outcomes.\n\n    Config:\n        observation_window_days: Days to observe outcome\n        default_rate: Target default rate for synthetic\n\n    Returns:\n        dict with label statistics\n    \"\"\"\n    batch_id = score_batch[\"batch_id\"]\n    window = context.op_config.get(\"observation_window_days\", 180)\n\n    db = context.resources.database\n    label_service = LabelGenerationService(db)\n\n    # Check if real outcomes available, else generate synthetic\n    real_labels = label_service.check_real_outcomes(batch_id)\n\n    if real_labels:\n        result = label_service.generate_labels(batch_id, observation_window_days=window)\n    else:\n        default_rate = context.op_config.get(\"default_rate\", 0.15)\n        result = label_service.generate_synthetic_labels(batch_id, default_rate)\n\n    context.log.info(f\"Generated {result['labels_created']} labels\")\n\n    return {\n        \"batch_id\": batch_id,\n        \"labels_created\": result[\"labels_created\"],\n        \"default_rate\": result[\"default_rate\"],\n        \"label_type\": \"real\" if real_labels else \"synthetic\"\n    }\n</code></pre>"},{"location":"dagster/assets/#train_model_asset","title":"train_model_asset","text":"<p>Trains ML model on labeled data.</p> <pre><code>@asset(\n    description=\"Train ML model on labeled data\",\n    group_name=\"ml_pipeline\",\n    deps=[generate_scorecard_labels]\n)\ndef train_model_asset(context, generate_scorecard_labels: dict) -&gt; dict:\n    \"\"\"\n    Train logistic regression model.\n\n    Config:\n        test_size: Fraction for test set\n        min_samples: Minimum required samples\n\n    Returns:\n        dict with model info and metrics\n    \"\"\"\n    batch_id = generate_scorecard_labels[\"batch_id\"]\n    test_size = context.op_config.get(\"test_size\", 0.2)\n    min_samples = context.op_config.get(\"min_samples\", 100)\n\n    # Check sample count\n    labels_count = generate_scorecard_labels[\"labels_created\"]\n    if labels_count &lt; min_samples:\n        context.log.warning(f\"Insufficient samples: {labels_count} &lt; {min_samples}\")\n        return {\n            \"batch_id\": batch_id,\n            \"status\": \"skipped\",\n            \"reason\": f\"Insufficient samples: {labels_count} &lt; {min_samples}\"\n        }\n\n    db = context.resources.database\n    training_service = ModelTrainingService(db)\n\n    result = training_service.train_model(batch_id, test_size=test_size)\n\n    context.log.info(f\"Model trained: AUC-ROC = {result['metrics']['auc_roc']:.3f}\")\n\n    return {\n        \"batch_id\": batch_id,\n        \"model_id\": result[\"model_id\"],\n        \"metrics\": result[\"metrics\"],\n        \"feature_importance\": result[\"feature_importance\"],\n        \"status\": \"trained\"\n    }\n</code></pre>"},{"location":"dagster/assets/#refine_scorecard","title":"refine_scorecard","text":"<p>Refines scorecard weights from ML model.</p> <pre><code>@asset(\n    description=\"Refine scorecard weights from ML model\",\n    group_name=\"ml_pipeline\",\n    deps=[train_model_asset]\n)\ndef refine_scorecard(context, train_model_asset: dict) -&gt; dict:\n    \"\"\"\n    Create refined scorecard version from ML model.\n\n    Config:\n        blend_factor: Weight for ML vs base (0-1)\n        base_version: Base scorecard version\n\n    Returns:\n        dict with new version info\n    \"\"\"\n    if train_model_asset.get(\"status\") != \"trained\":\n        return {\n            \"status\": \"skipped\",\n            \"reason\": train_model_asset.get(\"reason\", \"Model not trained\")\n        }\n\n    model_id = train_model_asset[\"model_id\"]\n    blend_factor = context.op_config.get(\"blend_factor\", 0.5)\n    base_version = context.op_config.get(\"base_version\", \"v1\")\n\n    db = context.resources.database\n    version_service = ScorecardVersionService(db)\n\n    result = version_service.refine_from_model(\n        model_id=model_id,\n        base_version=base_version,\n        blend_factor=blend_factor\n    )\n\n    context.log.info(f\"Created scorecard version: {result['version_id']}\")\n\n    return {\n        \"version_id\": result[\"version_id\"],\n        \"model_id\": model_id,\n        \"base_version\": base_version,\n        \"blend_factor\": blend_factor,\n        \"status\": \"draft\"\n    }\n</code></pre>"},{"location":"dagster/assets/#asset-groups","title":"Asset Groups","text":"<p>Assets are organized into groups:</p> Group Assets Purpose data_ingestion ingest_synthetic_batch Load data feature_extraction extract_* Extract features scoring score_batch Compute scores ml_pipeline generate_labels, train_model, refine_scorecard ML workflow"},{"location":"dagster/assets/#asset-metadata","title":"Asset Metadata","text":"<p>Assets emit metadata for tracking:</p> <pre><code>@asset\ndef score_batch(context, extract_features):\n    # ... scoring logic ...\n\n    context.add_output_metadata({\n        \"batch_id\": batch_id,\n        \"parties_scored\": MetadataValue.int(scored_count),\n        \"avg_score\": MetadataValue.float(avg_score),\n        \"band_distribution\": MetadataValue.json(distribution)\n    })\n\n    return result\n</code></pre>"},{"location":"dagster/assets/#testing-assets","title":"Testing Assets","text":"<pre><code>def test_ingest_synthetic_batch():\n    \"\"\"Test synthetic data ingestion.\"\"\"\n    from dagster import build_op_context\n\n    context = build_op_context(\n        config={\"batch_id\": \"TEST_001\", \"file_path\": \"test_data.json\"},\n        resources={\"database\": mock_database}\n    )\n\n    result = ingest_synthetic_batch(context)\n\n    assert result[\"parties_created\"] &gt; 0\n    assert result[\"batch_id\"] == \"TEST_001\"\n</code></pre>"},{"location":"dagster/jobs/","title":"Dagster Jobs","text":"<p>Jobs define executable pipelines composed of assets or ops.</p>"},{"location":"dagster/jobs/#job-catalog","title":"Job Catalog","text":"Job Description Assets full_scoring_job Complete pipeline All assets ingest_job Data ingestion only ingest_synthetic_batch feature_job Feature extraction only extract_* scoring_job Scoring only score_batch ml_training_job ML pipeline only generate_labels, train_model, refine_scorecard"},{"location":"dagster/jobs/#job-definitions","title":"Job Definitions","text":""},{"location":"dagster/jobs/#full_scoring_job","title":"full_scoring_job","text":"<p>Complete end-to-end pipeline.</p> <pre><code>from dagster import define_asset_job, AssetSelection\n\nfull_scoring_job = define_asset_job(\n    name=\"full_scoring_job\",\n    description=\"Complete scoring pipeline: ingest, extract, score, train, refine\",\n    selection=AssetSelection.all(),\n    config={\n        \"ops\": {\n            \"ingest_synthetic_batch\": {\n                \"config\": {\n                    \"batch_id\": {\"env\": \"BATCH_ID\"},\n                    \"file_path\": \"data/synthetic_profiles.json\"\n                }\n            },\n            \"score_batch\": {\n                \"config\": {\n                    \"scorecard_version\": \"v1\"\n                }\n            },\n            \"train_model_asset\": {\n                \"config\": {\n                    \"min_samples\": 100,\n                    \"test_size\": 0.2\n                }\n            },\n            \"refine_scorecard\": {\n                \"config\": {\n                    \"blend_factor\": 0.5\n                }\n            }\n        }\n    }\n)\n</code></pre>"},{"location":"dagster/jobs/#ingest_job","title":"ingest_job","text":"<p>Data ingestion only.</p> <pre><code>ingest_job = define_asset_job(\n    name=\"ingest_job\",\n    description=\"Ingest synthetic data\",\n    selection=AssetSelection.assets(ingest_synthetic_batch)\n)\n</code></pre>"},{"location":"dagster/jobs/#feature_job","title":"feature_job","text":"<p>Feature extraction only.</p> <pre><code>feature_job = define_asset_job(\n    name=\"feature_job\",\n    description=\"Extract features for existing batch\",\n    selection=AssetSelection.assets(\n        extract_features,\n        extract_kyc_features,\n        extract_txn_features,\n        extract_network_features\n    )\n)\n</code></pre>"},{"location":"dagster/jobs/#scoring_job","title":"scoring_job","text":"<p>Scoring only.</p> <pre><code>scoring_job = define_asset_job(\n    name=\"scoring_job\",\n    description=\"Score existing batch with extracted features\",\n    selection=AssetSelection.assets(score_batch)\n)\n</code></pre>"},{"location":"dagster/jobs/#ml_training_job","title":"ml_training_job","text":"<p>ML training pipeline only.</p> <pre><code>ml_training_job = define_asset_job(\n    name=\"ml_training_job\",\n    description=\"Train ML model and refine scorecard\",\n    selection=AssetSelection.assets(\n        generate_scorecard_labels,\n        train_model_asset,\n        refine_scorecard\n    )\n)\n</code></pre>"},{"location":"dagster/jobs/#run-configuration","title":"Run Configuration","text":""},{"location":"dagster/jobs/#default-configuration","title":"Default Configuration","text":"<pre><code>default_config = {\n    \"ops\": {\n        \"ingest_synthetic_batch\": {\n            \"config\": {\n                \"batch_id\": \"BATCH_001\",\n                \"file_path\": \"data/synthetic_profiles.json\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"dagster/jobs/#runtime-configuration","title":"Runtime Configuration","text":"<p>Jobs accept runtime configuration via Launchpad or API:</p> <pre><code>from dagster import RunRequest\n\ndef create_run_request(batch_id: str):\n    return RunRequest(\n        run_key=batch_id,\n        run_config={\n            \"ops\": {\n                \"ingest_synthetic_batch\": {\n                    \"config\": {\n                        \"batch_id\": batch_id\n                    }\n                }\n            }\n        }\n    )\n</code></pre>"},{"location":"dagster/jobs/#schedules","title":"Schedules","text":""},{"location":"dagster/jobs/#daily-scoring-schedule","title":"Daily Scoring Schedule","text":"<pre><code>from dagster import ScheduleDefinition\n\ndaily_scoring_schedule = ScheduleDefinition(\n    job=full_scoring_job,\n    cron_schedule=\"0 2 * * *\",  # 2 AM daily\n    run_config={\n        \"ops\": {\n            \"ingest_synthetic_batch\": {\n                \"config\": {\n                    \"batch_id\": {\"env\": \"DAILY_BATCH_ID\"}\n                }\n            }\n        }\n    }\n)\n</code></pre>"},{"location":"dagster/jobs/#weekly-ml-training-schedule","title":"Weekly ML Training Schedule","text":"<pre><code>weekly_ml_schedule = ScheduleDefinition(\n    job=ml_training_job,\n    cron_schedule=\"0 3 * * 0\",  # 3 AM Sunday\n    run_config={\n        \"ops\": {\n            \"train_model_asset\": {\n                \"config\": {\n                    \"min_samples\": 500\n                }\n            }\n        }\n    }\n)\n</code></pre>"},{"location":"dagster/jobs/#sensors","title":"Sensors","text":""},{"location":"dagster/jobs/#new-data-sensor","title":"New Data Sensor","text":"<p>Triggers pipeline when new data files appear.</p> <pre><code>from dagster import sensor, RunRequest\nimport os\n\n@sensor(job=full_scoring_job)\ndef new_data_sensor(context):\n    \"\"\"Detect new data files and trigger ingestion.\"\"\"\n    data_dir = \"data/incoming\"\n\n    for filename in os.listdir(data_dir):\n        if filename.endswith(\".json\"):\n            filepath = os.path.join(data_dir, filename)\n            batch_id = filename.replace(\".json\", \"\")\n\n            # Check if already processed\n            if not context.instance.has_run_for_key(batch_id):\n                yield RunRequest(\n                    run_key=batch_id,\n                    run_config={\n                        \"ops\": {\n                            \"ingest_synthetic_batch\": {\n                                \"config\": {\n                                    \"batch_id\": batch_id,\n                                    \"file_path\": filepath\n                                }\n                            }\n                        }\n                    }\n                )\n</code></pre>"},{"location":"dagster/jobs/#score-threshold-sensor","title":"Score Threshold Sensor","text":"<p>Triggers alert when scores fall below threshold.</p> <pre><code>@sensor(job=alert_job)\ndef low_score_sensor(context):\n    \"\"\"Alert when average score drops.\"\"\"\n    db = get_database()\n\n    recent_scores = db.query(ScoreRequest).filter(\n        ScoreRequest.created_at &gt;= datetime.utcnow() - timedelta(hours=1)\n    ).all()\n\n    if recent_scores:\n        avg_score = statistics.mean([s.total_score for s in recent_scores])\n\n        if avg_score &lt; 500:  # Threshold\n            yield RunRequest(\n                run_key=f\"low_score_alert_{datetime.utcnow():%Y%m%d%H}\",\n                run_config={\n                    \"ops\": {\n                        \"send_alert\": {\n                            \"config\": {\n                                \"message\": f\"Low average score: {avg_score:.0f}\",\n                                \"severity\": \"warning\"\n                            }\n                        }\n                    }\n                }\n            )\n</code></pre>"},{"location":"dagster/jobs/#executing-jobs","title":"Executing Jobs","text":""},{"location":"dagster/jobs/#via-dagster-ui","title":"Via Dagster UI","text":"<ol> <li>Navigate to <code>http://localhost:3000</code></li> <li>Select job from sidebar</li> <li>Click \"Launchpad\"</li> <li>Edit configuration if needed</li> <li>Click \"Launch Run\"</li> </ol>"},{"location":"dagster/jobs/#via-cli","title":"Via CLI","text":"<pre><code># Execute with default config\ndagster job execute -f dagster_home/definitions.py -j full_scoring_job\n\n# Execute with custom config\ndagster job execute -f dagster_home/definitions.py -j full_scoring_job \\\n  --config run_config.yaml\n\n# Execute specific assets only\ndagster asset materialize -f dagster_home/definitions.py --select score_batch\n</code></pre>"},{"location":"dagster/jobs/#via-python","title":"Via Python","text":"<pre><code>from dagster import DagsterInstance\nfrom dagster_home.definitions import full_scoring_job\n\ninstance = DagsterInstance.get()\n\nresult = full_scoring_job.execute_in_process(\n    run_config={\n        \"ops\": {\n            \"ingest_synthetic_batch\": {\n                \"config\": {\"batch_id\": \"BATCH_001\"}\n            }\n        }\n    },\n    instance=instance\n)\n\nif result.success:\n    print(\"Pipeline completed successfully\")\nelse:\n    print(f\"Pipeline failed: {result.failure_data}\")\n</code></pre>"},{"location":"dagster/jobs/#job-resources","title":"Job Resources","text":"<p>Jobs can share resources:</p> <pre><code>from dagster import Definitions, resource\n\n@resource\ndef database_resource():\n    from app.db.database import SessionLocal\n    return SessionLocal()\n\ndefs = Definitions(\n    assets=[...],\n    jobs=[full_scoring_job, ml_training_job],\n    resources={\n        \"database\": database_resource\n    }\n)\n</code></pre>"},{"location":"dagster/jobs/#error-handling","title":"Error Handling","text":""},{"location":"dagster/jobs/#retry-policy","title":"Retry Policy","text":"<pre><code>from dagster import RetryPolicy\n\n@asset(\n    retry_policy=RetryPolicy(\n        max_retries=3,\n        delay=30  # seconds\n    )\n)\ndef score_batch(context, extract_features):\n    # Will retry up to 3 times with 30s delay\n    pass\n</code></pre>"},{"location":"dagster/jobs/#failure-hooks","title":"Failure Hooks","text":"<pre><code>from dagster import failure_hook\n\n@failure_hook\ndef notify_on_failure(context):\n    \"\"\"Send notification on job failure.\"\"\"\n    send_slack_message(\n        channel=\"#alerts\",\n        message=f\"Job {context.job_name} failed: {context.op_exception}\"\n    )\n\nfull_scoring_job_with_hooks = full_scoring_job.with_hooks({notify_on_failure})\n</code></pre>"},{"location":"dagster/overview/","title":"Dagster Overview","text":"<p>Dagster orchestrates the KYCC data pipelines for batch processing, ML training, and scorecard refinement.</p>"},{"location":"dagster/overview/#overview","title":"Overview","text":"Property Value Location <code>backend/dagster_home/</code> UI Port 3000 Configuration <code>dagster.yaml</code>"},{"location":"dagster/overview/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Dagster Architecture                         \u2502\n\u2502                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                      Dagster Webserver                      \u2502  \u2502\n\u2502   \u2502                    http://localhost:3000                    \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                               \u2502                                     \u2502\n\u2502                               \u25bc                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                        Dagster Daemon                       \u2502  \u2502\n\u2502   \u2502              (Schedules, Sensors, Run Queue)                \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                               \u2502                                     \u2502\n\u2502                               \u25bc                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                     Asset Definitions                       \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n\u2502   \u2502   \u2502  ingest_synthetic_batch                             \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u2502                                           \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u25bc                                           \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502  extract_features \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u2502                          \u2502                \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u25bc                          \u25bc                \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502  score_batch              extract_kyc_features      \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u2502                 extract_txn_features      \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u2502                 extract_network_features  \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u25bc                          \u2502                \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502  generate_scorecard_labels \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u2502                                           \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u25bc                                           \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502  train_model_asset                                  \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u2502                                           \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502         \u25bc                                           \u2502  \u2502  \u2502\n\u2502   \u2502   \u2502  refine_scorecard                                   \u2502  \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dagster/overview/#file-structure","title":"File Structure","text":"<pre><code>backend/dagster_home/\n\u251c\u2500\u2500 definitions.py      # Asset and job definitions\n\u251c\u2500\u2500 sensors.py          # Event-driven triggers\n\u251c\u2500\u2500 dagster.yaml        # Dagster configuration\n\u2514\u2500\u2500 workspace.yaml      # Workspace configuration\n</code></pre>"},{"location":"dagster/overview/#starting-dagster","title":"Starting Dagster","text":""},{"location":"dagster/overview/#development","title":"Development","text":"<pre><code>cd backend\ndagster dev -f dagster_home/definitions.py\n</code></pre>"},{"location":"dagster/overview/#production","title":"Production","text":"<pre><code># Start webserver\ndagster-webserver -f dagster_home/definitions.py\n\n# Start daemon (separate process)\ndagster-daemon run -f dagster_home/definitions.py\n</code></pre>"},{"location":"dagster/overview/#docker","title":"Docker","text":"<pre><code># docker-compose.yml\ndagster:\n  image: dagster/dagster-k8s\n  ports:\n    - \"3000:3000\"\n  volumes:\n    - ./dagster_home:/opt/dagster/dagster_home\n  environment:\n    - DAGSTER_HOME=/opt/dagster/dagster_home\n</code></pre>"},{"location":"dagster/overview/#configuration","title":"Configuration","text":""},{"location":"dagster/overview/#dagsteryaml","title":"dagster.yaml","text":"<pre><code>scheduler:\n  module: dagster.core.scheduler\n  class: DagsterDaemonScheduler\n\nrun_queue:\n  max_concurrent_runs: 5\n\nrun_monitoring:\n  enabled: true\n  poll_interval_seconds: 60\n\ntelemetry:\n  enabled: false\n</code></pre>"},{"location":"dagster/overview/#workspaceyaml","title":"workspace.yaml","text":"<pre><code>load_from:\n  - python_file:\n      relative_path: definitions.py\n      location_name: kycc_scoring\n</code></pre>"},{"location":"dagster/overview/#resource-configuration","title":"Resource Configuration","text":"<p>Resources provide database connections and service instances:</p> <pre><code>from dagster import resource\n\n@resource\ndef database_resource(context):\n    \"\"\"Provide database session.\"\"\"\n    from app.db.database import SessionLocal\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n@resource\ndef scoring_service_resource(context):\n    \"\"\"Provide scoring service.\"\"\"\n    from app.services.scoring_service import ScoringService\n    db = context.resources.database\n    return ScoringService(db)\n</code></pre>"},{"location":"dagster/overview/#running-jobs","title":"Running Jobs","text":""},{"location":"dagster/overview/#via-ui","title":"Via UI","text":"<ol> <li>Navigate to <code>http://localhost:3000</code></li> <li>Select job from left sidebar</li> <li>Click \"Launchpad\"</li> <li>Configure run config</li> <li>Click \"Launch Run\"</li> </ol>"},{"location":"dagster/overview/#via-cli","title":"Via CLI","text":"<pre><code>dagster job execute -f dagster_home/definitions.py -j full_scoring_job \\\n  --config '{\"ops\": {\"ingest_synthetic_batch\": {\"config\": {\"batch_id\": \"BATCH_001\"}}}}'\n</code></pre>"},{"location":"dagster/overview/#via-api","title":"Via API","text":"<pre><code>from dagster import DagsterInstance\nfrom dagster_home.definitions import full_scoring_job\n\ninstance = DagsterInstance.get()\nresult = full_scoring_job.execute_in_process(\n    run_config={\n        \"ops\": {\n            \"ingest_synthetic_batch\": {\n                \"config\": {\"batch_id\": \"BATCH_001\"}\n            }\n        }\n    },\n    instance=instance\n)\n</code></pre>"},{"location":"dagster/overview/#monitoring","title":"Monitoring","text":""},{"location":"dagster/overview/#run-history","title":"Run History","text":"<p>View in UI at <code>http://localhost:3000/runs</code></p>"},{"location":"dagster/overview/#logs","title":"Logs","text":"<pre><code>@asset\ndef my_asset(context):\n    context.log.info(\"Processing started\")\n    context.log.warning(\"Low sample count\")\n    context.log.error(\"Processing failed\")\n</code></pre>"},{"location":"dagster/overview/#metrics","title":"Metrics","text":"<p>Custom metrics via Dagster events:</p> <pre><code>from dagster import Output, AssetMaterialization\n\n@asset\ndef score_batch(context, extract_features):\n    # ... scoring logic ...\n\n    yield AssetMaterialization(\n        asset_key=\"score_batch\",\n        metadata={\n            \"parties_scored\": len(results),\n            \"avg_score\": statistics.mean(scores),\n            \"processing_time_seconds\": elapsed\n        }\n    )\n\n    yield Output(results)\n</code></pre>"},{"location":"dagster/overview/#best-practices","title":"Best Practices","text":"<ol> <li>Idempotency: Assets should produce same output for same input</li> <li>Atomic Operations: Use database transactions</li> <li>Error Handling: Catch and log errors, allow retries</li> <li>Configuration: Use run config for runtime parameters</li> <li>Testing: Test assets in isolation with mock data</li> <li>Partitioning: Use partitions for large batch processing</li> </ol>"},{"location":"database/models/","title":"Database Models","text":"<p>This document provides a comprehensive reference for all database models in KYCC.</p>"},{"location":"database/models/#model-overview","title":"Model Overview","text":"<p>KYCC uses 17 database tables organized into functional groups:</p> Group Tables Purpose Core Entities Party, Relationship, Transaction, Account Supply chain data Feature Store Feature, FeatureDefinition, RawDataSource Computed features Scoring ScoreRequest, CreditScore, DecisionRule Score computation ML Pipeline GroundTruthLabel, ModelRegistry, ModelExperiment Machine learning Versioning ScorecardVersion, Batch, TrainingJob Version management Audit AuditLog Audit trail"},{"location":"database/models/#core-entities","title":"Core Entities","text":""},{"location":"database/models/#party","title":"Party","text":"<p>The central entity representing companies or individuals in the supply chain.</p> <pre><code>class Party(Base):\n    __tablename__ = \"parties\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    external_id = Column(String, unique=True, index=True)\n    batch_id = Column(String, index=True)\n    name = Column(String, nullable=False, index=True)\n    party_type = Column(String, nullable=False)  # supplier, manufacturer, etc.\n    tax_id = Column(String, unique=True, index=True)\n    registration_number = Column(String)\n    address = Column(Text)\n    contact_person = Column(String)\n    email = Column(String)\n    phone = Column(String)\n    kyc_verified = Column(Integer, default=0)  # 0 or 1\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n</code></pre> <p>Party Types:</p> <ul> <li><code>supplier</code></li> <li><code>manufacturer</code></li> <li><code>distributor</code></li> <li><code>retailer</code></li> <li><code>customer</code></li> <li><code>individual</code></li> <li><code>business</code></li> </ul>"},{"location":"database/models/#relationship","title":"Relationship","text":"<p>Models business connections between parties.</p> <pre><code>class Relationship(Base):\n    __tablename__ = \"relationships\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    batch_id = Column(String, index=True)\n    from_party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    to_party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    relationship_type = Column(Enum(RelationshipType), nullable=False)\n    established_date = Column(DateTime, default=datetime.utcnow)\n</code></pre> <p>Relationship Types:</p> <ul> <li><code>supplies_to</code></li> <li><code>manufactures_for</code></li> <li><code>distributes_for</code></li> <li><code>sells_to</code></li> </ul>"},{"location":"database/models/#transaction","title":"Transaction","text":"<p>Records financial activity between parties.</p> <pre><code>class Transaction(Base):\n    __tablename__ = \"transactions\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    batch_id = Column(String, index=True)\n    account_id = Column(Integer, ForeignKey(\"accounts.id\"))\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    counterparty_id = Column(Integer, ForeignKey(\"parties.id\"))\n    transaction_date = Column(DateTime, nullable=False)\n    amount = Column(Float, nullable=False)\n    transaction_type = Column(Enum(TransactionType), nullable=False)\n    reference = Column(String)\n    created_at = Column(DateTime, default=datetime.utcnow)\n</code></pre> <p>Transaction Types:</p> <ul> <li><code>invoice</code></li> <li><code>payment</code></li> <li><code>credit_note</code></li> </ul>"},{"location":"database/models/#account","title":"Account","text":"<p>Bank accounts tied to parties.</p> <pre><code>class Account(Base):\n    __tablename__ = \"accounts\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    external_id = Column(String, index=True)\n    batch_id = Column(String, index=True)\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    account_number = Column(String, nullable=False)\n    account_type = Column(String, default=\"checking\")\n    currency = Column(String, default=\"USD\")\n    balance = Column(Float, default=0.0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n</code></pre>"},{"location":"database/models/#feature-store","title":"Feature Store","text":""},{"location":"database/models/#feature","title":"Feature","text":"<p>Stores computed features with temporal versioning.</p> <pre><code>class Feature(Base):\n    __tablename__ = \"features\"\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    feature_name = Column(String, nullable=False, index=True)\n    feature_value = Column(Float)\n    value_text = Column(String)  # For categorical features\n    confidence_score = Column(Float)  # 0.0-1.0\n    computation_timestamp = Column(DateTime, default=datetime.utcnow)\n    valid_from = Column(DateTime, default=datetime.utcnow)\n    valid_to = Column(DateTime, nullable=True)  # NULL = current version\n    source_type = Column(String)  # KYC, TRANSACTIONS, RELATIONSHIPS\n    source_data_id = Column(String, ForeignKey(\"raw_data_sources.id\"))\n    feature_version = Column(String)\n    feature_metadata = Column(JSON)\n</code></pre> <p>Key Index: <code>idx_party_feature_valid</code> on <code>(party_id, feature_name, valid_to)</code></p> <p>Temporal Querying:</p> <ul> <li>Current features: <code>WHERE valid_to IS NULL</code></li> <li>Historical features: <code>WHERE valid_from &lt;= date AND (valid_to IS NULL OR valid_to &gt; date)</code></li> </ul>"},{"location":"database/models/#featuredefinition","title":"FeatureDefinition","text":"<p>Metadata about each feature type.</p> <pre><code>class FeatureDefinition(Base):\n    __tablename__ = \"feature_definitions\"\n\n    feature_name = Column(String, primary_key=True)\n    category = Column(String)  # stability, income, behavior\n    data_type = Column(String)  # numeric, categorical, boolean\n    description = Column(Text)\n    computation_logic = Column(Text)\n    required_sources = Column(JSON)  # ['KYC', 'TRANSACTIONS']\n    normalization_method = Column(String)  # min_max, z_score\n    normalization_params = Column(JSON)  # {min: 0, max: 100}\n    default_value = Column(Float)\n    is_active = Column(Integer, default=1)\n    created_at = Column(DateTime, default=datetime.utcnow)\n</code></pre>"},{"location":"database/models/#rawdatasource","title":"RawDataSource","text":"<p>Stores raw data snapshots for reprocessing.</p> <pre><code>class RawDataSource(Base):\n    __tablename__ = \"raw_data_sources\"\n\n    id = Column(String, primary_key=True)  # UUID\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    source_type = Column(String, nullable=False)  # KYC, TRANSACTIONS\n    source_subtype = Column(String)\n    data_payload = Column(JSON, nullable=False)\n    ingested_at = Column(DateTime, default=datetime.utcnow)\n    processed = Column(Integer, default=0)\n    processing_version = Column(String)\n</code></pre>"},{"location":"database/models/#scoring-models","title":"Scoring Models","text":""},{"location":"database/models/#scorerequest","title":"ScoreRequest","text":"<p>Audit log of all scoring computations.</p> <pre><code>class ScoreRequest(Base):\n    __tablename__ = \"score_requests\"\n\n    id = Column(String, primary_key=True)  # UUID\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    request_timestamp = Column(DateTime, default=datetime.utcnow, index=True)\n    model_version = Column(String, nullable=False)\n    model_type = Column(String, nullable=False)  # scorecard, ml_model\n    features_snapshot = Column(JSON, nullable=False)\n    raw_score = Column(Float)\n    final_score = Column(Integer)  # 300-900\n    score_band = Column(String)  # excellent, good, fair, poor\n    confidence_level = Column(Float)\n    decision = Column(String)  # approved, rejected, manual_review\n    decision_reasons = Column(JSON)\n    processing_time_ms = Column(Integer)\n    api_client_id = Column(String)\n    scorecard_version_id = Column(Integer, ForeignKey(\"scorecard_versions.id\"))\n</code></pre>"},{"location":"database/models/#creditscore","title":"CreditScore","text":"<p>Stores computed credit scores (legacy compatibility).</p> <pre><code>class CreditScore(Base):\n    __tablename__ = \"credit_scores\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), nullable=False)\n    overall_score = Column(Float, nullable=False)\n    payment_regularity_score = Column(Float)\n    transaction_volume_score = Column(Float)\n    kyc_score = Column(Float)\n    network_score = Column(Float)\n    calculated_at = Column(DateTime, default=datetime.utcnow)\n    score_request_id = Column(String, ForeignKey(\"score_requests.id\"))\n    scored_with_version = Column(String(50), ForeignKey(\"scorecard_versions.version\"))\n</code></pre>"},{"location":"database/models/#decisionrule","title":"DecisionRule","text":"<p>Business rules for credit decisions.</p> <pre><code>class DecisionRule(Base):\n    __tablename__ = \"decision_rules\"\n\n    rule_id = Column(String, primary_key=True)\n    rule_name = Column(String, nullable=False)\n    condition_expression = Column(Text, nullable=False)\n    action = Column(String, nullable=False)  # reject, flag, manual_review\n    priority = Column(Integer, nullable=False)\n    is_active = Column(Integer, default=1)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n</code></pre>"},{"location":"database/models/#ml-pipeline-models","title":"ML Pipeline Models","text":""},{"location":"database/models/#groundtruthlabel","title":"GroundTruthLabel","text":"<p>Ground truth labels for training data.</p> <pre><code>class GroundTruthLabel(Base):\n    __tablename__ = \"ground_truth_labels\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    party_id = Column(Integer, ForeignKey(\"parties.id\"), unique=True, nullable=False)\n    will_default = Column(Integer, nullable=False)  # 0 or 1\n    risk_level = Column(String(20), nullable=False)  # high, medium, low\n    label_source = Column(String(50), nullable=False)  # scorecard, observed, mixed\n    label_confidence = Column(Float, default=1.0)\n    scorecard_version = Column(String(20), nullable=True)\n    scorecard_raw_score = Column(Float, nullable=True)\n    reason = Column(Text, nullable=True)\n    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)\n    dataset_batch = Column(String(100), nullable=False, index=True)\n</code></pre>"},{"location":"database/models/#modelregistry","title":"ModelRegistry","text":"<p>Registry of trained ML models.</p> <pre><code>class ModelRegistry(Base):\n    __tablename__ = \"model_registry\"\n\n    model_version = Column(String(50), primary_key=True)\n    model_type = Column(String(50))  # scorecard, ml_model\n    model_config = Column(JSON)  # weights, intercept, hyperparams\n    feature_list = Column(JSON)  # list of feature names\n    intercept = Column(Float)\n    normalization_method = Column(String(50))\n    training_date = Column(DateTime, default=datetime.utcnow)\n    deployed_date = Column(DateTime)\n    is_active = Column(Integer, default=0)\n    performance_metrics = Column(JSON)  # auc, precision, recall, f1\n    scaler_binary = Column(LargeBinary)  # Serialized scaler\n    description = Column(Text)\n    created_by = Column(String(100))\n</code></pre>"},{"location":"database/models/#modelexperiment","title":"ModelExperiment","text":"<p>Hyperparameter tuning experiments.</p> <pre><code>class ModelExperiment(Base):\n    __tablename__ = \"model_experiments\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    experiment_name = Column(String(100), nullable=False, index=True)\n    algorithm = Column(String(50), nullable=False)\n    hyperparameters = Column(JSON, nullable=False)\n    cv_scores = Column(JSON, nullable=False)\n    mean_cv_score = Column(Float, nullable=False)\n    std_cv_score = Column(Float, nullable=False)\n    training_time_seconds = Column(Float, nullable=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    notes = Column(Text)\n</code></pre>"},{"location":"database/models/#version-management","title":"Version Management","text":""},{"location":"database/models/#scorecardversion","title":"ScorecardVersion","text":"<p>Versioned scorecard storage.</p> <pre><code>class ScorecardVersion(Base):\n    __tablename__ = \"scorecard_versions\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    version = Column(String(20), unique=True, nullable=False, index=True)\n    version_number = Column(Integer, index=True)\n    status = Column(String(20), nullable=False, default='active')  # active, archived, failed\n    weights = Column(JSON, nullable=False)\n    base_score = Column(Integer, nullable=False, default=300)\n    max_score = Column(Integer, nullable=False, default=900)\n    scaling_config = Column(JSON)\n    source = Column(String(20), nullable=False, default='expert')  # expert, ml_refined\n    ml_model_id = Column(String(50))\n    ml_auc = Column(Float)\n    ml_f1 = Column(Float)\n    training_data_count = Column(Integer)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    activated_at = Column(DateTime)\n    retired_at = Column(DateTime)\n    archived_at = Column(DateTime)\n    created_by = Column(String(100), default='system')\n    notes = Column(Text)\n</code></pre>"},{"location":"database/models/#batch","title":"Batch","text":"<p>Tracks lifecycle of data batches.</p> <pre><code>class Batch(Base):\n    __tablename__ = \"batches\"\n\n    id = Column(String(50), primary_key=True, index=True)\n    status = Column(String(50), nullable=False)  # ingested, scored, outcomes_generated\n    created_at = Column(DateTime, default=datetime.utcnow, index=True)\n    scored_at = Column(DateTime)\n    outcomes_generated_at = Column(DateTime)\n    profile_count = Column(Integer, default=0)\n    label_count = Column(Integer, default=0)\n    default_rate = Column(Float, default=0.0)\n</code></pre>"},{"location":"database/models/#trainingjob","title":"TrainingJob","text":"<p>Tracks ML training jobs.</p> <pre><code>class TrainingJob(Base):\n    __tablename__ = \"training_jobs\"\n\n    id = Column(String(50), primary_key=True)\n    status = Column(String(50), nullable=False)  # running, completed, failed\n    started_at = Column(DateTime, default=datetime.utcnow)\n    completed_at = Column(DateTime)\n    training_data_count = Column(Integer, default=0)\n    new_version_id = Column(Integer, ForeignKey(\"scorecard_versions.id\"))\n</code></pre>"},{"location":"database/models/#audit","title":"Audit","text":""},{"location":"database/models/#auditlog","title":"AuditLog","text":"<p>Audit trail for all operations.</p> <pre><code>class AuditLog(Base):\n    __tablename__ = \"audit_log\"\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    event_type = Column(String, nullable=False)\n    party_id = Column(Integer, ForeignKey(\"parties.id\"))\n    timestamp = Column(DateTime, default=datetime.utcnow, index=True)\n    user_id = Column(String)\n    api_client_id = Column(String)\n    model_version = Column(String)\n    request_payload = Column(JSON)\n    response_payload = Column(JSON)\n    ip_address = Column(String)\n</code></pre>"},{"location":"database/models/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Party     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  Relationship   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   Party     \u2502\n\u2502             \u2502  1:N  \u2502                 \u2502  N:1  \u2502             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502 1:N\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Transaction \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502    Account      \u2502\n\u2502             \u2502  N:1  \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502 (via party_id)\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Feature    \u2502       \u2502 GroundTruthLabel\u2502       \u2502   ScoreRequest    \u2502\n\u2502             \u2502       \u2502                 \u2502       \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                          \u2502\n                                                          \u2502 N:1\n                                                          \u25bc\n                                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                               \u2502 ScorecardVersion  \u2502\n                                               \u2502                   \u2502\n                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"database/schema/","title":"Database Schema Reference","text":"<p>This document provides the complete SQL schema reference for KYCC.</p>"},{"location":"database/schema/#table-schemas","title":"Table Schemas","text":""},{"location":"database/schema/#parties","title":"parties","text":"<pre><code>CREATE TABLE parties (\n    id SERIAL PRIMARY KEY,\n    external_id VARCHAR UNIQUE,\n    batch_id VARCHAR,\n    name VARCHAR NOT NULL,\n    party_type VARCHAR NOT NULL,\n    tax_id VARCHAR UNIQUE,\n    registration_number VARCHAR,\n    address TEXT,\n    contact_person VARCHAR,\n    email VARCHAR,\n    phone VARCHAR,\n    kyc_verified INTEGER DEFAULT 0,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_parties_external_id ON parties(external_id);\nCREATE INDEX idx_parties_batch_id ON parties(batch_id);\nCREATE INDEX idx_parties_name ON parties(name);\nCREATE INDEX idx_parties_tax_id ON parties(tax_id);\n</code></pre>"},{"location":"database/schema/#relationships","title":"relationships","text":"<pre><code>CREATE TABLE relationships (\n    id SERIAL PRIMARY KEY,\n    batch_id VARCHAR,\n    from_party_id INTEGER NOT NULL REFERENCES parties(id),\n    to_party_id INTEGER NOT NULL REFERENCES parties(id),\n    relationship_type VARCHAR NOT NULL,\n    established_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_relationships_batch_id ON relationships(batch_id);\nCREATE INDEX idx_relationships_from_party ON relationships(from_party_id);\nCREATE INDEX idx_relationships_to_party ON relationships(to_party_id);\n</code></pre>"},{"location":"database/schema/#transactions","title":"transactions","text":"<pre><code>CREATE TABLE transactions (\n    id SERIAL PRIMARY KEY,\n    batch_id VARCHAR,\n    account_id INTEGER REFERENCES accounts(id),\n    party_id INTEGER NOT NULL REFERENCES parties(id),\n    counterparty_id INTEGER REFERENCES parties(id),\n    transaction_date TIMESTAMP NOT NULL,\n    amount FLOAT NOT NULL,\n    transaction_type VARCHAR NOT NULL,\n    reference VARCHAR,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_transactions_batch_id ON transactions(batch_id);\nCREATE INDEX idx_transactions_party_id ON transactions(party_id);\nCREATE INDEX idx_transactions_date ON transactions(transaction_date);\n</code></pre>"},{"location":"database/schema/#accounts","title":"accounts","text":"<pre><code>CREATE TABLE accounts (\n    id SERIAL PRIMARY KEY,\n    external_id VARCHAR,\n    batch_id VARCHAR,\n    party_id INTEGER NOT NULL REFERENCES parties(id),\n    account_number VARCHAR NOT NULL,\n    account_type VARCHAR DEFAULT 'checking',\n    currency VARCHAR DEFAULT 'USD',\n    balance FLOAT DEFAULT 0.0,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_accounts_party_id ON accounts(party_id);\nCREATE INDEX idx_accounts_batch_id ON accounts(batch_id);\n</code></pre>"},{"location":"database/schema/#features","title":"features","text":"<pre><code>CREATE TABLE features (\n    id SERIAL PRIMARY KEY,\n    party_id INTEGER NOT NULL REFERENCES parties(id),\n    feature_name VARCHAR NOT NULL,\n    feature_value FLOAT,\n    value_text VARCHAR,\n    confidence_score FLOAT,\n    computation_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    valid_from TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    valid_to TIMESTAMP,\n    source_type VARCHAR,\n    source_data_id VARCHAR REFERENCES raw_data_sources(id),\n    feature_version VARCHAR,\n    feature_metadata JSONB\n);\n\nCREATE INDEX idx_features_feature_name ON features(feature_name);\nCREATE INDEX idx_party_feature_valid ON features(party_id, feature_name, valid_to);\n</code></pre>"},{"location":"database/schema/#feature_definitions","title":"feature_definitions","text":"<pre><code>CREATE TABLE feature_definitions (\n    feature_name VARCHAR PRIMARY KEY,\n    category VARCHAR,\n    data_type VARCHAR,\n    description TEXT,\n    computation_logic TEXT,\n    required_sources JSONB,\n    normalization_method VARCHAR,\n    normalization_params JSONB,\n    default_value FLOAT,\n    is_active INTEGER DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"database/schema/#raw_data_sources","title":"raw_data_sources","text":"<pre><code>CREATE TABLE raw_data_sources (\n    id VARCHAR PRIMARY KEY,\n    party_id INTEGER NOT NULL REFERENCES parties(id),\n    source_type VARCHAR NOT NULL,\n    source_subtype VARCHAR,\n    data_payload JSONB NOT NULL,\n    ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    processed INTEGER DEFAULT 0,\n    processing_version VARCHAR\n);\n</code></pre>"},{"location":"database/schema/#score_requests","title":"score_requests","text":"<pre><code>CREATE TABLE score_requests (\n    id VARCHAR PRIMARY KEY,\n    party_id INTEGER NOT NULL REFERENCES parties(id),\n    request_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    model_version VARCHAR NOT NULL,\n    model_type VARCHAR NOT NULL,\n    features_snapshot JSONB NOT NULL,\n    raw_score FLOAT,\n    final_score INTEGER,\n    score_band VARCHAR,\n    confidence_level FLOAT,\n    decision VARCHAR,\n    decision_reasons JSONB,\n    processing_time_ms INTEGER,\n    api_client_id VARCHAR,\n    scorecard_version_id INTEGER REFERENCES scorecard_versions(id)\n);\n\nCREATE INDEX idx_score_requests_timestamp ON score_requests(request_timestamp);\nCREATE INDEX idx_score_requests_party ON score_requests(party_id);\n</code></pre>"},{"location":"database/schema/#credit_scores","title":"credit_scores","text":"<pre><code>CREATE TABLE credit_scores (\n    id SERIAL PRIMARY KEY,\n    party_id INTEGER NOT NULL REFERENCES parties(id),\n    overall_score FLOAT NOT NULL,\n    payment_regularity_score FLOAT,\n    transaction_volume_score FLOAT,\n    kyc_score FLOAT,\n    network_score FLOAT,\n    calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    score_request_id VARCHAR REFERENCES score_requests(id),\n    scored_with_version VARCHAR(50) REFERENCES scorecard_versions(version)\n);\n\nCREATE INDEX idx_credit_scores_party ON credit_scores(party_id);\n</code></pre>"},{"location":"database/schema/#decision_rules","title":"decision_rules","text":"<pre><code>CREATE TABLE decision_rules (\n    rule_id VARCHAR PRIMARY KEY,\n    rule_name VARCHAR NOT NULL,\n    condition_expression TEXT NOT NULL,\n    action VARCHAR NOT NULL,\n    priority INTEGER NOT NULL,\n    is_active INTEGER DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"database/schema/#ground_truth_labels","title":"ground_truth_labels","text":"<pre><code>CREATE TABLE ground_truth_labels (\n    id SERIAL PRIMARY KEY,\n    party_id INTEGER UNIQUE NOT NULL REFERENCES parties(id),\n    will_default INTEGER NOT NULL,\n    risk_level VARCHAR(20) NOT NULL,\n    label_source VARCHAR(50) NOT NULL,\n    label_confidence FLOAT DEFAULT 1.0,\n    scorecard_version VARCHAR(20),\n    scorecard_raw_score FLOAT,\n    reason TEXT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,\n    dataset_batch VARCHAR(100) NOT NULL\n);\n\nCREATE INDEX idx_labels_party ON ground_truth_labels(party_id);\nCREATE INDEX idx_labels_batch ON ground_truth_labels(dataset_batch);\n</code></pre>"},{"location":"database/schema/#model_registry","title":"model_registry","text":"<pre><code>CREATE TABLE model_registry (\n    model_version VARCHAR(50) PRIMARY KEY,\n    model_type VARCHAR(50),\n    model_config JSONB,\n    feature_list JSONB,\n    intercept FLOAT,\n    normalization_method VARCHAR(50),\n    training_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    deployed_date TIMESTAMP,\n    is_active INTEGER DEFAULT 0,\n    performance_metrics JSONB,\n    scaler_binary BYTEA,\n    description TEXT,\n    created_by VARCHAR(100)\n);\n</code></pre>"},{"location":"database/schema/#model_experiments","title":"model_experiments","text":"<pre><code>CREATE TABLE model_experiments (\n    id SERIAL PRIMARY KEY,\n    experiment_name VARCHAR(100) NOT NULL,\n    algorithm VARCHAR(50) NOT NULL,\n    hyperparameters JSONB NOT NULL,\n    cv_scores JSONB NOT NULL,\n    mean_cv_score FLOAT NOT NULL,\n    std_cv_score FLOAT NOT NULL,\n    training_time_seconds FLOAT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    notes TEXT\n);\n\nCREATE INDEX idx_experiments_name ON model_experiments(experiment_name);\n</code></pre>"},{"location":"database/schema/#scorecard_versions","title":"scorecard_versions","text":"<pre><code>CREATE TABLE scorecard_versions (\n    id SERIAL PRIMARY KEY,\n    version VARCHAR(20) UNIQUE NOT NULL,\n    version_number INTEGER,\n    status VARCHAR(20) NOT NULL DEFAULT 'active',\n    weights JSONB NOT NULL,\n    base_score INTEGER NOT NULL DEFAULT 300,\n    max_score INTEGER NOT NULL DEFAULT 900,\n    scaling_config JSONB,\n    source VARCHAR(20) NOT NULL DEFAULT 'expert',\n    ml_model_id VARCHAR(50),\n    ml_auc FLOAT,\n    ml_f1 FLOAT,\n    training_data_count INTEGER,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,\n    activated_at TIMESTAMP,\n    retired_at TIMESTAMP,\n    archived_at TIMESTAMP,\n    created_by VARCHAR(100) DEFAULT 'system',\n    notes TEXT\n);\n\nCREATE INDEX idx_scorecard_version ON scorecard_versions(version);\nCREATE INDEX idx_scorecard_version_number ON scorecard_versions(version_number);\n</code></pre>"},{"location":"database/schema/#batches","title":"batches","text":"<pre><code>CREATE TABLE batches (\n    id VARCHAR(50) PRIMARY KEY,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    scored_at TIMESTAMP,\n    outcomes_generated_at TIMESTAMP,\n    profile_count INTEGER DEFAULT 0,\n    label_count INTEGER DEFAULT 0,\n    default_rate FLOAT DEFAULT 0.0\n);\n\nCREATE INDEX idx_batch_status ON batches(status);\n</code></pre>"},{"location":"database/schema/#training_jobs","title":"training_jobs","text":"<pre><code>CREATE TABLE training_jobs (\n    id VARCHAR(50) PRIMARY KEY,\n    status VARCHAR(50) NOT NULL,\n    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    completed_at TIMESTAMP,\n    training_data_count INTEGER DEFAULT 0,\n    new_version_id INTEGER REFERENCES scorecard_versions(id)\n);\n</code></pre>"},{"location":"database/schema/#audit_log","title":"audit_log","text":"<pre><code>CREATE TABLE audit_log (\n    id SERIAL PRIMARY KEY,\n    event_type VARCHAR NOT NULL,\n    party_id INTEGER REFERENCES parties(id),\n    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    user_id VARCHAR,\n    api_client_id VARCHAR,\n    model_version VARCHAR,\n    request_payload JSONB,\n    response_payload JSONB,\n    ip_address VARCHAR\n);\n\nCREATE INDEX idx_audit_timestamp ON audit_log(timestamp);\n</code></pre>"},{"location":"database/schema/#common-queries","title":"Common Queries","text":""},{"location":"database/schema/#get-current-features-for-a-party","title":"Get Current Features for a Party","text":"<pre><code>SELECT feature_name, feature_value, source_type\nFROM features\nWHERE party_id = :party_id\n  AND valid_to IS NULL\nORDER BY feature_name;\n</code></pre>"},{"location":"database/schema/#get-active-scorecard","title":"Get Active Scorecard","text":"<pre><code>SELECT id, version, weights, base_score, max_score, ml_auc\nFROM scorecard_versions\nWHERE status = 'active'\nORDER BY id DESC\nLIMIT 1;\n</code></pre>"},{"location":"database/schema/#get-score-history-for-a-party","title":"Get Score History for a Party","text":"<pre><code>SELECT final_score, score_band, decision, request_timestamp, model_version\nFROM score_requests\nWHERE party_id = :party_id\nORDER BY request_timestamp DESC\nLIMIT 10;\n</code></pre>"},{"location":"database/schema/#count-parties-by-batch","title":"Count Parties by Batch","text":"<pre><code>SELECT batch_id, COUNT(*) as party_count\nFROM parties\nGROUP BY batch_id\nORDER BY batch_id;\n</code></pre>"},{"location":"database/schema/#get-default-rate-by-batch","title":"Get Default Rate by Batch","text":"<pre><code>SELECT \n    dataset_batch,\n    COUNT(*) as total,\n    SUM(will_default) as defaults,\n    ROUND(100.0 * SUM(will_default) / COUNT(*), 2) as default_rate\nFROM ground_truth_labels\nGROUP BY dataset_batch;\n</code></pre>"},{"location":"database/schema/#get-feature-statistics","title":"Get Feature Statistics","text":"<pre><code>SELECT \n    feature_name,\n    COUNT(*) as count,\n    AVG(feature_value) as mean,\n    MIN(feature_value) as min,\n    MAX(feature_value) as max\nFROM features\nWHERE valid_to IS NULL\nGROUP BY feature_name\nORDER BY feature_name;\n</code></pre>"},{"location":"database/schema/#migrations","title":"Migrations","text":"<p>KYCC uses Alembic for database migrations.</p>"},{"location":"database/schema/#create-migration","title":"Create Migration","text":"<pre><code>cd backend\nalembic revision --autogenerate -m \"description\"\n</code></pre>"},{"location":"database/schema/#apply-migrations","title":"Apply Migrations","text":"<pre><code>alembic upgrade head\n</code></pre>"},{"location":"database/schema/#rollback-migration","title":"Rollback Migration","text":"<pre><code>alembic downgrade -1\n</code></pre>"},{"location":"database/schema/#view-current-version","title":"View Current Version","text":"<pre><code>alembic current\n</code></pre>"},{"location":"database/schema/#sqlite-vs-postgresql","title":"SQLite vs PostgreSQL","text":"<p>KYCC supports both PostgreSQL (primary) and SQLite (fallback).</p>"},{"location":"database/schema/#feature-differences","title":"Feature Differences","text":"Feature PostgreSQL SQLite JSON columns JSONB (native) TEXT (serialized) Enum types Native ENUM VARCHAR Binary data BYTEA BLOB Boolean BOOLEAN INTEGER (0/1) Concurrent writes Full support Limited"},{"location":"database/schema/#connection-string-formats","title":"Connection String Formats","text":"<p>PostgreSQL: <pre><code>postgresql://user:password@host:port/database\n</code></pre></p> <p>SQLite: <pre><code>sqlite:///path/to/database.db\n</code></pre></p>"},{"location":"database/sessions/","title":"Session Management","text":"<p>This document covers database session management patterns in KYCC.</p>"},{"location":"database/sessions/#overview","title":"Overview","text":"<p>KYCC uses SQLAlchemy 2.x for database operations with a dependency injection pattern for session management.</p>"},{"location":"database/sessions/#database-connection","title":"Database Connection","text":""},{"location":"database/sessions/#location","title":"Location","text":"<p><code>backend/app/db/database.py</code></p>"},{"location":"database/sessions/#engine-creation","title":"Engine Creation","text":"<pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import declarative_base, sessionmaker\n\nDATABASE_URL = os.getenv(\n    \"DATABASE_URL\", \n    \"postgresql://localhost/kycc_db\"\n)\n\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = declarative_base()\n</code></pre>"},{"location":"database/sessions/#automatic-fallback","title":"Automatic Fallback","text":"<p>KYCC implements automatic fallback to SQLite if PostgreSQL is unavailable:</p> <pre><code>def _test_engine_connection(engine, timeout: float = 2.0) -&gt; bool:\n    \"\"\"Test if database connection works.\"\"\"\n    try:\n        with engine.connect() as conn:\n            conn.execute(text(\"SELECT 1\"))\n        return True\n    except Exception:\n        return False\n\n# If PostgreSQL fails, fall back to SQLite\nif not _test_engine_connection(engine):\n    print(\"[FALLBACK] Using SQLite\")\n    engine = create_engine(\"sqlite:///kycc_local.db\")\n</code></pre>"},{"location":"database/sessions/#session-dependency-injection","title":"Session Dependency Injection","text":""},{"location":"database/sessions/#the-get_db-pattern","title":"The get_db Pattern","text":"<p>All API routes use dependency injection for database sessions:</p> <pre><code>def get_db():\n    \"\"\"\n    Dependency that provides a database session.\n    Session is automatically closed after request completes.\n    \"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n</code></pre>"},{"location":"database/sessions/#usage-in-routes","title":"Usage in Routes","text":"<pre><code>from fastapi import Depends\nfrom sqlalchemy.orm import Session\nfrom app.db.database import get_db\n\n@router.get(\"/parties/{party_id}\")\ndef get_party(party_id: int, db: Session = Depends(get_db)):\n    party = db.query(Party).filter(Party.id == party_id).first()\n    if not party:\n        raise HTTPException(status_code=404, detail=\"Party not found\")\n    return party\n</code></pre>"},{"location":"database/sessions/#session-lifecycle","title":"Session Lifecycle","text":""},{"location":"database/sessions/#request-lifecycle","title":"Request Lifecycle","text":"<pre><code>1. Request arrives at FastAPI endpoint\n2. Depends(get_db) creates new SessionLocal()\n3. Session is passed to route handler\n4. Route handler performs database operations\n5. Route returns response\n6. finally block calls db.close()\n7. Connection returned to pool\n</code></pre>"},{"location":"database/sessions/#context-manager-pattern","title":"Context Manager Pattern","text":"<p>For non-request contexts (scripts, Dagster):</p> <pre><code>with SessionLocal() as db:\n    # Perform database operations\n    result = db.query(Party).all()\n    # Session automatically closed on exit\n</code></pre> <p>Or using try/finally:</p> <pre><code>db = SessionLocal()\ntry:\n    result = db.query(Party).all()\nfinally:\n    db.close()\n</code></pre>"},{"location":"database/sessions/#transaction-management","title":"Transaction Management","text":""},{"location":"database/sessions/#auto-commit-disabled","title":"Auto-commit Disabled","text":"<p>Sessions are created with <code>autocommit=False</code>, requiring explicit commits:</p> <pre><code>def create_party(db: Session, party_data: dict):\n    party = Party(**party_data)\n    db.add(party)\n    db.commit()\n    db.refresh(party)\n    return party\n</code></pre>"},{"location":"database/sessions/#rollback-on-error","title":"Rollback on Error","text":"<pre><code>def create_party_with_transactions(db: Session, data: dict):\n    try:\n        party = Party(**data[\"party\"])\n        db.add(party)\n\n        for txn_data in data[\"transactions\"]:\n            txn = Transaction(party_id=party.id, **txn_data)\n            db.add(txn)\n\n        db.commit()\n    except Exception:\n        db.rollback()\n        raise\n</code></pre>"},{"location":"database/sessions/#nested-transactions","title":"Nested Transactions","text":"<p>For complex operations requiring partial rollback:</p> <pre><code>from sqlalchemy import savepoint\n\ndef complex_operation(db: Session):\n    # Main transaction\n    party = Party(name=\"Test\")\n    db.add(party)\n\n    # Savepoint for nested operation\n    sp = db.begin_nested()\n    try:\n        risky_operation(db)\n        sp.commit()\n    except Exception:\n        sp.rollback()\n        # Main transaction continues\n\n    db.commit()\n</code></pre>"},{"location":"database/sessions/#common-patterns","title":"Common Patterns","text":""},{"location":"database/sessions/#query-patterns","title":"Query Patterns","text":"<pre><code># Single record by primary key\nparty = db.query(Party).get(party_id)\n\n# Single record with filter\nparty = db.query(Party).filter(Party.external_id == ext_id).first()\n\n# Multiple records\nparties = db.query(Party).filter(Party.batch_id == batch_id).all()\n\n# Count\ncount = db.query(Party).filter(Party.batch_id == batch_id).count()\n\n# Exists check\nexists = db.query(Party).filter(Party.external_id == ext_id).first() is not None\n</code></pre>"},{"location":"database/sessions/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Bulk insert\ndb.bulk_insert_mappings(Party, party_dicts)\ndb.commit()\n\n# Bulk update\ndb.query(Feature).filter(\n    Feature.party_id == party_id,\n    Feature.valid_to == None\n).update({\"valid_to\": datetime.utcnow()})\ndb.commit()\n</code></pre>"},{"location":"database/sessions/#eager-loading","title":"Eager Loading","text":"<p>To avoid N+1 queries:</p> <pre><code>from sqlalchemy.orm import joinedload\n\n# Load party with relationships\nparty = db.query(Party).options(\n    joinedload(Party.relationships_from),\n    joinedload(Party.relationships_to)\n).filter(Party.id == party_id).first()\n</code></pre>"},{"location":"database/sessions/#service-layer-sessions","title":"Service Layer Sessions","text":"<p>Services receive sessions through their constructors:</p> <pre><code>class ScoringService:\n    def __init__(self, db: Session):\n        self.db = db\n\n    def compute_score(self, party_id: int) -&gt; dict:\n        # Use self.db for all database operations\n        party = self.db.query(Party).get(party_id)\n        ...\n</code></pre>"},{"location":"database/sessions/#why-not-create-sessions-in-services","title":"Why Not Create Sessions in Services?","text":"<p>Creating sessions inside services leads to:</p> <ol> <li>Session leaks: Forgotten closes</li> <li>Transaction confusion: Multiple transactions per request</li> <li>Testing difficulty: Hard to mock database</li> <li>Connection exhaustion: Too many connections</li> </ol> <p>Always inject sessions from the outer layer (route handler or script).</p>"},{"location":"database/sessions/#testing-sessions","title":"Testing Sessions","text":""},{"location":"database/sessions/#test-isolation","title":"Test Isolation","text":"<p>Tests use SQLite with a fresh database:</p> <pre><code># conftest.py\nimport os\nos.environ[\"DATABASE_URL\"] = \"sqlite:///test_run.db\"\n\n# Delete old test database\nif Path(\"test_run.db\").exists():\n    Path(\"test_run.db\").unlink()\n\n# Import after setting environment\nfrom app.db.database import engine, Base\nBase.metadata.create_all(bind=engine)\n</code></pre>"},{"location":"database/sessions/#test-fixtures","title":"Test Fixtures","text":"<pre><code>import pytest\nfrom app.db.database import SessionLocal\n\n@pytest.fixture\ndef db():\n    \"\"\"Provide a database session for tests.\"\"\"\n    session = SessionLocal()\n    try:\n        yield session\n    finally:\n        session.rollback()\n        session.close()\n</code></pre>"},{"location":"database/sessions/#connection-pooling","title":"Connection Pooling","text":"<p>SQLAlchemy manages a connection pool automatically:</p> <pre><code>engine = create_engine(\n    DATABASE_URL,\n    pool_size=5,           # Number of persistent connections\n    max_overflow=10,       # Additional connections when pool exhausted\n    pool_timeout=30,       # Seconds to wait for connection\n    pool_recycle=1800,     # Recycle connections after 30 minutes\n)\n</code></pre>"},{"location":"database/sessions/#monitoring-pool","title":"Monitoring Pool","text":"<pre><code>from sqlalchemy import event\n\n@event.listens_for(engine, \"checkout\")\ndef receive_checkout(dbapi_connection, connection_record, connection_proxy):\n    print(f\"Connection checked out: {connection_record}\")\n\n@event.listens_for(engine, \"checkin\")\ndef receive_checkin(dbapi_connection, connection_record):\n    print(f\"Connection checked in: {connection_record}\")\n</code></pre>"},{"location":"database/sessions/#best-practices","title":"Best Practices","text":""},{"location":"database/sessions/#do","title":"Do","text":"<ul> <li>Use <code>get_db</code> dependency in all routes</li> <li>Pass sessions to services via constructor</li> <li>Commit explicitly after writes</li> <li>Use <code>db.refresh()</code> after commit to get updated values</li> <li>Close sessions in finally blocks</li> </ul>"},{"location":"database/sessions/#do-not","title":"Do Not","text":"<ul> <li>Create <code>SessionLocal()</code> directly in route handlers</li> <li>Store sessions in global variables</li> <li>Share sessions between threads</li> <li>Forget to close sessions</li> <li>Use autocommit mode</li> </ul>"},{"location":"deployment/docker/","title":"Docker Deployment","text":"<p>This guide covers deploying KYCC using Docker and Docker Compose.</p>"},{"location":"deployment/docker/#overview","title":"Overview","text":"Service Image Port Backend Python 3.11 8000 PostgreSQL postgres:15-alpine 5433 Dagster Python 3.11 3000"},{"location":"deployment/docker/#docker-compose-configuration","title":"Docker Compose Configuration","text":""},{"location":"deployment/docker/#docker-composeyml","title":"docker-compose.yml","text":"<pre><code>version: \"3.8\"\n\nservices:\n  postgres:\n    image: postgres:15-alpine\n    container_name: kycc-postgres\n    environment:\n      POSTGRES_USER: kycc\n      POSTGRES_PASSWORD: kycc_password\n      POSTGRES_DB: kycc_db\n    ports:\n      - \"5433:5432\"\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U kycc -d kycc_db\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: kycc-backend\n    environment:\n      DATABASE_URL: postgresql://kycc:kycc_password@postgres:5432/kycc_db\n      PYTHONUNBUFFERED: 1\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n    volumes:\n      - ./backend:/app\n    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload\n\n  dagster:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: kycc-dagster\n    environment:\n      DATABASE_URL: postgresql://kycc:kycc_password@postgres:5432/kycc_db\n      DAGSTER_HOME: /app/dagster_home\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n    volumes:\n      - ./backend:/app\n      - dagster_storage:/app/dagster_instance\n    command: dagster dev -h 0.0.0.0 -p 3000 -f dagster_home/definitions.py\n    working_dir: /app\n\nvolumes:\n  postgres_data:\n  dagster_storage:\n</code></pre>"},{"location":"deployment/docker/#backend-dockerfile","title":"Backend Dockerfile","text":"<pre><code># backend/Dockerfile\n\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    libpq-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Create non-root user\nRUN useradd -m appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\n# Expose port\nEXPOSE 8000\n\n# Default command\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"deployment/docker/#quick-start","title":"Quick Start","text":""},{"location":"deployment/docker/#start-all-services","title":"Start All Services","text":"<pre><code>docker-compose up -d\n</code></pre>"},{"location":"deployment/docker/#view-logs","title":"View Logs","text":"<pre><code># All services\ndocker-compose logs -f\n\n# Specific service\ndocker-compose logs -f backend\n</code></pre>"},{"location":"deployment/docker/#stop-services","title":"Stop Services","text":"<pre><code>docker-compose down\n</code></pre>"},{"location":"deployment/docker/#stop-and-remove-volumes","title":"Stop and Remove Volumes","text":"<pre><code>docker-compose down -v\n</code></pre>"},{"location":"deployment/docker/#individual-service-commands","title":"Individual Service Commands","text":""},{"location":"deployment/docker/#postgresql","title":"PostgreSQL","text":"<pre><code># Start only PostgreSQL\ndocker-compose up -d postgres\n\n# Connect to database\ndocker exec -it kycc-postgres psql -U kycc -d kycc_db\n\n# View logs\ndocker-compose logs -f postgres\n</code></pre>"},{"location":"deployment/docker/#backend","title":"Backend","text":"<pre><code># Start backend\ndocker-compose up -d backend\n\n# Run migrations\ndocker exec kycc-backend alembic upgrade head\n\n# View logs\ndocker-compose logs -f backend\n\n# Shell access\ndocker exec -it kycc-backend bash\n</code></pre>"},{"location":"deployment/docker/#dagster","title":"Dagster","text":"<pre><code># Start Dagster\ndocker-compose up -d dagster\n\n# View logs\ndocker-compose logs -f dagster\n</code></pre>"},{"location":"deployment/docker/#database-migrations","title":"Database Migrations","text":""},{"location":"deployment/docker/#run-migrations-in-container","title":"Run Migrations in Container","text":"<pre><code>docker exec kycc-backend alembic upgrade head\n</code></pre>"},{"location":"deployment/docker/#create-new-migration","title":"Create New Migration","text":"<pre><code>docker exec kycc-backend alembic revision --autogenerate -m \"description\"\n</code></pre>"},{"location":"deployment/docker/#rollback-migration","title":"Rollback Migration","text":"<pre><code>docker exec kycc-backend alembic downgrade -1\n</code></pre>"},{"location":"deployment/docker/#seeding-data","title":"Seeding Data","text":""},{"location":"deployment/docker/#seed-synthetic-data","title":"Seed Synthetic Data","text":"<pre><code>docker exec kycc-backend python -c \"\nfrom app.services.synthetic_seed_service import ingest_seed_file\nfrom app.db.database import SessionLocal\ndb = SessionLocal()\ningest_seed_file(db, 'data/synthetic_profiles.json', batch_id='BATCH_001')\ndb.close()\n\"\n</code></pre>"},{"location":"deployment/docker/#verify-data","title":"Verify Data","text":"<pre><code>docker exec kycc-backend python -c \"\nfrom app.db.database import SessionLocal\nfrom app.models.models import Party\ndb = SessionLocal()\ncount = db.query(Party).count()\nprint(f'Total parties: {count}')\ndb.close()\n\"\n</code></pre>"},{"location":"deployment/docker/#environment-variables","title":"Environment Variables","text":""},{"location":"deployment/docker/#required-variables","title":"Required Variables","text":"Variable Description Example DATABASE_URL PostgreSQL connection <code>postgresql://user:pass@host:5432/db</code> PYTHONUNBUFFERED Disable output buffering <code>1</code> DAGSTER_HOME Dagster home directory <code>/app/dagster_home</code>"},{"location":"deployment/docker/#optional-variables","title":"Optional Variables","text":"Variable Description Default LOG_LEVEL Logging level <code>INFO</code> CORS_ORIGINS Allowed CORS origins <code>*</code> API_KEY API authentication key None"},{"location":"deployment/docker/#using-env-file","title":"Using .env File","text":"<p>Create <code>.env</code> file:</p> <pre><code>DATABASE_URL=postgresql://kycc:kycc_password@postgres:5432/kycc_db\nPYTHONUNBUFFERED=1\nLOG_LEVEL=INFO\n</code></pre> <p>Reference in docker-compose.yml:</p> <pre><code>services:\n  backend:\n    env_file:\n      - .env\n</code></pre>"},{"location":"deployment/docker/#volume-management","title":"Volume Management","text":""},{"location":"deployment/docker/#list-volumes","title":"List Volumes","text":"<pre><code>docker volume ls\n</code></pre>"},{"location":"deployment/docker/#inspect-volume","title":"Inspect Volume","text":"<pre><code>docker volume inspect kycc_postgres_data\n</code></pre>"},{"location":"deployment/docker/#backup-database-volume","title":"Backup Database Volume","text":"<pre><code>docker run --rm \\\n  -v kycc_postgres_data:/data \\\n  -v $(pwd)/backup:/backup \\\n  alpine tar cvf /backup/postgres_backup.tar /data\n</code></pre>"},{"location":"deployment/docker/#restore-database-volume","title":"Restore Database Volume","text":"<pre><code>docker run --rm \\\n  -v kycc_postgres_data:/data \\\n  -v $(pwd)/backup:/backup \\\n  alpine tar xvf /backup/postgres_backup.tar -C /\n</code></pre>"},{"location":"deployment/docker/#networking","title":"Networking","text":""},{"location":"deployment/docker/#default-network","title":"Default Network","text":"<p>Docker Compose creates a default network: <code>kycc_default</code></p>"},{"location":"deployment/docker/#service-discovery","title":"Service Discovery","text":"<p>Services can reach each other by service name: - <code>postgres:5432</code> - PostgreSQL - <code>backend:8000</code> - Backend API - <code>dagster:3000</code> - Dagster UI</p>"},{"location":"deployment/docker/#external-access","title":"External Access","text":"<ul> <li>Backend API: <code>http://localhost:8000</code></li> <li>Dagster UI: <code>http://localhost:3000</code></li> <li>PostgreSQL: <code>localhost:5433</code></li> </ul>"},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":""},{"location":"deployment/docker/#postgresql-health-check","title":"PostgreSQL Health Check","text":"<pre><code>healthcheck:\n  test: [\"CMD-SHELL\", \"pg_isready -U kycc -d kycc_db\"]\n  interval: 10s\n  timeout: 5s\n  retries: 5\n</code></pre>"},{"location":"deployment/docker/#backend-health-check","title":"Backend Health Check","text":"<pre><code>healthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n  interval: 30s\n  timeout: 10s\n  retries: 3\n</code></pre>"},{"location":"deployment/docker/#check-health-status","title":"Check Health Status","text":"<pre><code>docker-compose ps\ndocker inspect kycc-backend --format='{{.State.Health.Status}}'\n</code></pre>"},{"location":"deployment/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker/#container-wont-start","title":"Container Won't Start","text":"<pre><code># Check logs\ndocker-compose logs backend\n\n# Check container status\ndocker ps -a\n\n# Inspect container\ndocker inspect kycc-backend\n</code></pre>"},{"location":"deployment/docker/#database-connection-issues","title":"Database Connection Issues","text":"<pre><code># Verify PostgreSQL is running\ndocker-compose ps postgres\n\n# Test connection from backend\ndocker exec kycc-backend python -c \"\nfrom app.db.database import engine\nprint(engine.connect())\n\"\n</code></pre>"},{"location":"deployment/docker/#permission-issues","title":"Permission Issues","text":"<pre><code># Fix volume permissions\ndocker exec -u root kycc-backend chown -R appuser:appuser /app\n</code></pre>"},{"location":"deployment/docker/#out-of-disk-space","title":"Out of Disk Space","text":"<pre><code># Remove unused containers\ndocker container prune\n\n# Remove unused images\ndocker image prune\n\n# Remove unused volumes\ndocker volume prune\n\n# Remove everything unused\ndocker system prune -a\n</code></pre>"},{"location":"deployment/docker/#production-considerations","title":"Production Considerations","text":"<ol> <li>Remove --reload flag in production</li> <li>Use secrets management for passwords</li> <li>Enable SSL/TLS for database connections</li> <li>Set resource limits on containers</li> <li>Use external PostgreSQL for production</li> <li>Configure logging to external service</li> <li>Set up monitoring with Prometheus/Grafana</li> </ol>"},{"location":"deployment/production/","title":"Production Deployment","text":"<p>This guide covers deploying KYCC to a production environment.</p>"},{"location":"deployment/production/#overview","title":"Overview","text":"<p>Production deployment involves:</p> <ol> <li>Infrastructure setup</li> <li>Database configuration</li> <li>Backend deployment</li> <li>Frontend deployment</li> <li>Monitoring and logging</li> <li>Security hardening</li> </ol>"},{"location":"deployment/production/#infrastructure-requirements","title":"Infrastructure Requirements","text":""},{"location":"deployment/production/#minimum-requirements","title":"Minimum Requirements","text":"Component Specification CPU 2 cores RAM 4 GB Storage 20 GB SSD OS Ubuntu 22.04 LTS"},{"location":"deployment/production/#recommended-requirements","title":"Recommended Requirements","text":"Component Specification CPU 4+ cores RAM 8+ GB Storage 100 GB SSD OS Ubuntu 22.04 LTS"},{"location":"deployment/production/#database-setup","title":"Database Setup","text":""},{"location":"deployment/production/#postgresql-installation","title":"PostgreSQL Installation","text":"<pre><code># Install PostgreSQL 15\nsudo apt update\nsudo apt install postgresql-15 postgresql-contrib-15\n\n# Start service\nsudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"deployment/production/#database-configuration","title":"Database Configuration","text":"<pre><code># Connect as postgres user\nsudo -u postgres psql\n\n# Create database and user\nCREATE USER kycc WITH PASSWORD 'secure_password_here';\nCREATE DATABASE kycc_db OWNER kycc;\nGRANT ALL PRIVILEGES ON DATABASE kycc_db TO kycc;\n\n# Enable extensions\n\\c kycc_db\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\n\\q\n</code></pre>"},{"location":"deployment/production/#postgresql-performance-tuning","title":"PostgreSQL Performance Tuning","text":"<p>Edit <code>/etc/postgresql/15/main/postgresql.conf</code>:</p> <pre><code># Memory\nshared_buffers = 2GB\neffective_cache_size = 6GB\nwork_mem = 50MB\nmaintenance_work_mem = 512MB\n\n# Connections\nmax_connections = 100\n\n# Write ahead log\nwal_buffers = 64MB\ncheckpoint_completion_target = 0.9\n\n# Query planner\nrandom_page_cost = 1.1\neffective_io_concurrency = 200\n</code></pre>"},{"location":"deployment/production/#connection-security","title":"Connection Security","text":"<p>Edit <code>/etc/postgresql/15/main/pg_hba.conf</code>:</p> <pre><code># IPv4 local connections\nhost    kycc_db    kycc    127.0.0.1/32    scram-sha-256\nhost    kycc_db    kycc    10.0.0.0/8      scram-sha-256\n</code></pre>"},{"location":"deployment/production/#backend-deployment","title":"Backend Deployment","text":""},{"location":"deployment/production/#system-setup","title":"System Setup","text":"<pre><code># Install Python 3.11\nsudo apt install python3.11 python3.11-venv python3.11-dev\n\n# Install system dependencies\nsudo apt install gcc libpq-dev nginx\n\n# Create application user\nsudo useradd -m -s /bin/bash kycc\nsudo mkdir -p /opt/kycc\nsudo chown kycc:kycc /opt/kycc\n</code></pre>"},{"location":"deployment/production/#application-setup","title":"Application Setup","text":"<pre><code># Switch to application user\nsudo su - kycc\n\n# Clone repository\ncd /opt/kycc\ngit clone https://github.com/kzauha/KYCC.git .\n\n# Create virtual environment\ncd backend\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install --upgrade pip\npip install -r requirements.txt\npip install gunicorn\n</code></pre>"},{"location":"deployment/production/#environment-configuration","title":"Environment Configuration","text":"<p>Create <code>/opt/kycc/backend/.env</code>:</p> <pre><code>DATABASE_URL=postgresql://kycc:secure_password@localhost:5432/kycc_db\nLOG_LEVEL=INFO\nCORS_ORIGINS=https://yourdomain.com\nSECRET_KEY=your-secret-key-here\n</code></pre>"},{"location":"deployment/production/#database-migrations","title":"Database Migrations","text":"<pre><code>cd /opt/kycc/backend\nsource venv/bin/activate\nalembic upgrade head\n</code></pre>"},{"location":"deployment/production/#gunicorn-configuration","title":"Gunicorn Configuration","text":"<p>Create <code>/opt/kycc/backend/gunicorn.conf.py</code>:</p> <pre><code># Gunicorn configuration\n\nbind = \"127.0.0.1:8000\"\nworkers = 4\nworker_class = \"uvicorn.workers.UvicornWorker\"\ntimeout = 120\nkeepalive = 5\nerrorlog = \"/var/log/kycc/gunicorn-error.log\"\naccesslog = \"/var/log/kycc/gunicorn-access.log\"\nloglevel = \"info\"\n</code></pre>"},{"location":"deployment/production/#systemd-service","title":"Systemd Service","text":"<p>Create <code>/etc/systemd/system/kycc-backend.service</code>:</p> <pre><code>[Unit]\nDescription=KYCC Backend API\nAfter=network.target postgresql.service\n\n[Service]\nUser=kycc\nGroup=kycc\nWorkingDirectory=/opt/kycc/backend\nEnvironment=\"PATH=/opt/kycc/backend/venv/bin\"\nEnvironmentFile=/opt/kycc/backend/.env\nExecStart=/opt/kycc/backend/venv/bin/gunicorn main:app -c gunicorn.conf.py\nRestart=always\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable and start:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable kycc-backend\nsudo systemctl start kycc-backend\n</code></pre>"},{"location":"deployment/production/#nginx-configuration","title":"Nginx Configuration","text":""},{"location":"deployment/production/#ssl-certificate","title":"SSL Certificate","text":"<pre><code># Install certbot\nsudo apt install certbot python3-certbot-nginx\n\n# Obtain certificate\nsudo certbot --nginx -d yourdomain.com\n</code></pre>"},{"location":"deployment/production/#nginx-site-configuration","title":"Nginx Site Configuration","text":"<p>Create <code>/etc/nginx/sites-available/kycc</code>:</p> <pre><code>upstream kycc_backend {\n    server 127.0.0.1:8000;\n}\n\nserver {\n    listen 80;\n    server_name yourdomain.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name yourdomain.com;\n\n    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;\n\n    # API endpoints\n    location /api {\n        proxy_pass http://kycc_backend;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_read_timeout 120s;\n    }\n\n    # Health check\n    location /health {\n        proxy_pass http://kycc_backend/health;\n    }\n\n    # Static files (frontend)\n    location / {\n        root /opt/kycc/frontend/dist;\n        try_files $uri $uri/ /index.html;\n    }\n\n    # Gzip compression\n    gzip on;\n    gzip_types text/plain application/json application/javascript text/css;\n    gzip_min_length 1000;\n}\n</code></pre> <p>Enable site:</p> <pre><code>sudo ln -s /etc/nginx/sites-available/kycc /etc/nginx/sites-enabled/\nsudo nginx -t\nsudo systemctl reload nginx\n</code></pre>"},{"location":"deployment/production/#frontend-deployment","title":"Frontend Deployment","text":""},{"location":"deployment/production/#build-frontend","title":"Build Frontend","text":"<pre><code>cd /opt/kycc/frontend\nnpm install\nnpm run build\n</code></pre>"},{"location":"deployment/production/#deploy-to-nginx","title":"Deploy to Nginx","text":"<pre><code># Built files are in /opt/kycc/frontend/dist\n# Nginx serves them from the location / block\n</code></pre>"},{"location":"deployment/production/#dagster-deployment","title":"Dagster Deployment","text":""},{"location":"deployment/production/#systemd-service_1","title":"Systemd Service","text":"<p>Create <code>/etc/systemd/system/kycc-dagster.service</code>:</p> <pre><code>[Unit]\nDescription=KYCC Dagster Pipeline\nAfter=network.target postgresql.service\n\n[Service]\nUser=kycc\nGroup=kycc\nWorkingDirectory=/opt/kycc/backend\nEnvironment=\"PATH=/opt/kycc/backend/venv/bin\"\nEnvironment=\"DAGSTER_HOME=/opt/kycc/backend/dagster_home\"\nEnvironmentFile=/opt/kycc/backend/.env\nExecStart=/opt/kycc/backend/venv/bin/dagster dev -h 127.0.0.1 -p 3000 -f dagster_home/definitions.py\nRestart=always\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"deployment/production/#nginx-proxy-for-dagster","title":"Nginx Proxy for Dagster","text":"<p>Add to Nginx configuration:</p> <pre><code>location /dagster {\n    proxy_pass http://127.0.0.1:3000;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_set_header Host $host;\n}\n</code></pre>"},{"location":"deployment/production/#logging","title":"Logging","text":""},{"location":"deployment/production/#create-log-directory","title":"Create Log Directory","text":"<pre><code>sudo mkdir -p /var/log/kycc\nsudo chown kycc:kycc /var/log/kycc\n</code></pre>"},{"location":"deployment/production/#log-rotation","title":"Log Rotation","text":"<p>Create <code>/etc/logrotate.d/kycc</code>:</p> <pre><code>/var/log/kycc/*.log {\n    daily\n    missingok\n    rotate 14\n    compress\n    delaycompress\n    notifempty\n    create 0640 kycc kycc\n    sharedscripts\n    postrotate\n        systemctl reload kycc-backend\n    endscript\n}\n</code></pre>"},{"location":"deployment/production/#monitoring","title":"Monitoring","text":""},{"location":"deployment/production/#health-check-endpoint","title":"Health Check Endpoint","text":"<p>Backend provides <code>/health</code> endpoint:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"database\": \"connected\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre>"},{"location":"deployment/production/#monitoring-script","title":"Monitoring Script","text":"<p>Create <code>/opt/kycc/scripts/health_check.sh</code>:</p> <pre><code>#!/bin/bash\nRESPONSE=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8000/health)\n\nif [ \"$RESPONSE\" != \"200\" ]; then\n    echo \"Health check failed: HTTP $RESPONSE\"\n    systemctl restart kycc-backend\nfi\n</code></pre> <p>Add to crontab:</p> <pre><code>*/5 * * * * /opt/kycc/scripts/health_check.sh\n</code></pre>"},{"location":"deployment/production/#security-checklist","title":"Security Checklist","text":"<ol> <li> <p>Firewall Configuration <pre><code>sudo ufw allow 22/tcp\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\nsudo ufw enable\n</code></pre></p> </li> <li> <p>Database Security</p> </li> <li>Use strong passwords</li> <li>Restrict connections to localhost/VPC</li> <li> <p>Enable SSL for database connections</p> </li> <li> <p>Application Security</p> </li> <li>Set SECRET_KEY environment variable</li> <li>Configure CORS properly</li> <li> <p>Enable rate limiting</p> </li> <li> <p>SSL/TLS</p> </li> <li>Use Let's Encrypt for certificates</li> <li>Enable HSTS</li> <li> <p>Use TLS 1.2+</p> </li> <li> <p>Updates <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n</code></pre></p> </li> </ol>"},{"location":"deployment/production/#backup-strategy","title":"Backup Strategy","text":""},{"location":"deployment/production/#database-backup","title":"Database Backup","text":"<pre><code>#!/bin/bash\n# /opt/kycc/scripts/backup.sh\n\nDATE=$(date +%Y%m%d_%H%M%S)\nBACKUP_DIR=/opt/kycc/backups\n\nmkdir -p $BACKUP_DIR\npg_dump -U kycc kycc_db | gzip &gt; $BACKUP_DIR/kycc_db_$DATE.sql.gz\n\n# Keep only last 7 days\nfind $BACKUP_DIR -name \"*.sql.gz\" -mtime +7 -delete\n</code></pre>"},{"location":"deployment/production/#cron-schedule","title":"Cron Schedule","text":"<pre><code>0 2 * * * /opt/kycc/scripts/backup.sh\n</code></pre>"},{"location":"deployment/production/#deployment-commands-summary","title":"Deployment Commands Summary","text":"<pre><code># Pull latest code\ncd /opt/kycc\ngit pull origin main\n\n# Update backend\ncd backend\nsource venv/bin/activate\npip install -r requirements.txt\nalembic upgrade head\nsudo systemctl restart kycc-backend\n\n# Update frontend\ncd ../frontend\nnpm install\nnpm run build\n</code></pre>"},{"location":"features/caching/","title":"Feature Caching","text":"<p>KYCC implements a TTL (Time-To-Live) cache for feature lookups to improve performance.</p>"},{"location":"features/caching/#overview","title":"Overview","text":"Property Value Location <code>backend/app/cache/ttl_cache.py</code> Default TTL 300 seconds (5 minutes) Thread Safety Yes (threading.Lock) Storage In-memory dictionary"},{"location":"features/caching/#cache-architecture","title":"Cache Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        TTL Cache                                    \u2502\n\u2502                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Key: \"party:123:features:all\"                              \u2502  \u2502\n\u2502   \u2502  Value: {                                                   \u2502  \u2502\n\u2502   \u2502    \"features\": [...],                                       \u2502  \u2502\n\u2502   \u2502    \"timestamp\": 1703001234.567                              \u2502  \u2502\n\u2502   \u2502  }                                                          \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Key: \"party:456:features:all\"                              \u2502  \u2502\n\u2502   \u2502  Value: {...}                                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                     \u2502\n\u2502   Thread Lock: threading.Lock()                                     \u2502\n\u2502   TTL Check: current_time - timestamp &gt; ttl                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"features/caching/#implementation","title":"Implementation","text":"<pre><code>import threading\nimport time\nfrom typing import Any, Optional\n\nclass TTLCache:\n    \"\"\"Thread-safe in-memory cache with TTL expiration.\"\"\"\n\n    def __init__(self, default_ttl: int = 300):\n        \"\"\"\n        Initialize cache.\n\n        Args:\n            default_ttl: Default time-to-live in seconds\n        \"\"\"\n        self._cache = {}\n        self._lock = threading.Lock()\n        self._default_ttl = default_ttl\n\n    def get(self, key: str) -&gt; Optional[Any]:\n        \"\"\"\n        Get value from cache if not expired.\n\n        Args:\n            key: Cache key\n\n        Returns:\n            Cached value or None if expired/missing\n        \"\"\"\n        with self._lock:\n            if key not in self._cache:\n                return None\n\n            entry = self._cache[key]\n            if time.time() - entry['timestamp'] &gt; entry['ttl']:\n                # Expired - remove and return None\n                del self._cache[key]\n                return None\n\n            return entry['value']\n\n    def set(self, key: str, value: Any, ttl: int = None):\n        \"\"\"\n        Set value in cache.\n\n        Args:\n            key: Cache key\n            value: Value to cache\n            ttl: Optional TTL override\n        \"\"\"\n        with self._lock:\n            self._cache[key] = {\n                'value': value,\n                'timestamp': time.time(),\n                'ttl': ttl or self._default_ttl\n            }\n\n    def delete(self, key: str):\n        \"\"\"Remove key from cache.\"\"\"\n        with self._lock:\n            self._cache.pop(key, None)\n\n    def clear(self):\n        \"\"\"Clear all cached entries.\"\"\"\n        with self._lock:\n            self._cache.clear()\n\n    def cleanup(self):\n        \"\"\"Remove all expired entries.\"\"\"\n        with self._lock:\n            current_time = time.time()\n            expired_keys = [\n                key for key, entry in self._cache.items()\n                if current_time - entry['timestamp'] &gt; entry['ttl']\n            ]\n            for key in expired_keys:\n                del self._cache[key]\n</code></pre>"},{"location":"features/caching/#key-format","title":"Key Format","text":"<p>Cache keys follow a consistent pattern:</p> <pre><code>party:{party_id}:features:all\n</code></pre> <p>Examples: - <code>party:123:features:all</code> - <code>party:456:features:all</code></p>"},{"location":"features/caching/#usage-in-feature-pipeline","title":"Usage in Feature Pipeline","text":"<pre><code>from app.cache.ttl_cache import TTLCache\n\n# Global cache instance\nfeature_cache = TTLCache(default_ttl=300)\n\ndef get_features_for_party(party_id: int, db: Session) -&gt; dict:\n    \"\"\"Get features with caching.\"\"\"\n    cache_key = f\"party:{party_id}:features:all\"\n\n    # Check cache first\n    cached = feature_cache.get(cache_key)\n    if cached:\n        return cached\n\n    # Cache miss - extract features\n    pipeline = FeaturePipelineService(db)\n    features = pipeline.extract_all_features(party_id)\n\n    # Store in cache\n    feature_cache.set(cache_key, features)\n\n    return features\n</code></pre>"},{"location":"features/caching/#cache-invalidation","title":"Cache Invalidation","text":""},{"location":"features/caching/#automatic-expiration","title":"Automatic Expiration","text":"<p>Entries automatically expire after TTL:</p> <pre><code># Entry created at T=0\ncache.set(\"key\", value, ttl=300)\n\n# At T=299, entry is valid\ncache.get(\"key\")  # Returns value\n\n# At T=301, entry is expired\ncache.get(\"key\")  # Returns None (and deletes entry)\n</code></pre>"},{"location":"features/caching/#manual-invalidation","title":"Manual Invalidation","text":"<p>Invalidate when features are recomputed:</p> <pre><code>def update_features(party_id: int, db: Session):\n    \"\"\"Recompute features and invalidate cache.\"\"\"\n    # Invalidate cache\n    cache_key = f\"party:{party_id}:features:all\"\n    feature_cache.delete(cache_key)\n\n    # Recompute\n    pipeline = FeaturePipelineService(db)\n    return pipeline.extract_all_features(party_id)\n</code></pre>"},{"location":"features/caching/#batch-invalidation","title":"Batch Invalidation","text":"<p>Invalidate all entries for a batch:</p> <pre><code>def invalidate_batch(batch_id: str, db: Session):\n    \"\"\"Invalidate cache for all parties in batch.\"\"\"\n    parties = db.query(Party.id).filter(Party.batch_id == batch_id).all()\n\n    for (party_id,) in parties:\n        cache_key = f\"party:{party_id}:features:all\"\n        feature_cache.delete(cache_key)\n</code></pre>"},{"location":"features/caching/#configuration","title":"Configuration","text":""},{"location":"features/caching/#ttl-configuration","title":"TTL Configuration","text":"<p>Default TTL can be configured:</p> <pre><code># Short TTL for frequently changing data\nvolatile_cache = TTLCache(default_ttl=60)  # 1 minute\n\n# Long TTL for stable data\nstable_cache = TTLCache(default_ttl=3600)  # 1 hour\n\n# Per-key TTL override\ncache.set(\"key\", value, ttl=120)  # 2 minutes\n</code></pre>"},{"location":"features/caching/#memory-limits","title":"Memory Limits","text":"<p>Current implementation has no memory limits. For production:</p> <pre><code>class BoundedTTLCache(TTLCache):\n    def __init__(self, default_ttl: int = 300, max_size: int = 1000):\n        super().__init__(default_ttl)\n        self._max_size = max_size\n\n    def set(self, key: str, value: Any, ttl: int = None):\n        with self._lock:\n            # Evict oldest if at capacity\n            if len(self._cache) &gt;= self._max_size:\n                oldest = min(self._cache.items(), key=lambda x: x[1]['timestamp'])\n                del self._cache[oldest[0]]\n\n            super().set(key, value, ttl)\n</code></pre>"},{"location":"features/caching/#thread-safety","title":"Thread Safety","text":"<p>The cache uses <code>threading.Lock()</code> for thread safety:</p> <pre><code># Multiple threads can safely read/write\nimport threading\n\ndef worker(party_id):\n    features = get_features_for_party(party_id, db)\n    # Process features\n\nthreads = [\n    threading.Thread(target=worker, args=(i,))\n    for i in range(10)\n]\n\nfor t in threads:\n    t.start()\n\nfor t in threads:\n    t.join()\n</code></pre>"},{"location":"features/caching/#monitoring","title":"Monitoring","text":""},{"location":"features/caching/#cache-statistics","title":"Cache Statistics","text":"<pre><code>class TTLCache:\n    def __init__(self, default_ttl: int = 300):\n        # ...\n        self._hits = 0\n        self._misses = 0\n\n    def get(self, key: str) -&gt; Optional[Any]:\n        with self._lock:\n            if key in self._cache and not expired:\n                self._hits += 1\n                return entry['value']\n            else:\n                self._misses += 1\n                return None\n\n    def stats(self) -&gt; dict:\n        with self._lock:\n            total = self._hits + self._misses\n            return {\n                'hits': self._hits,\n                'misses': self._misses,\n                'hit_rate': self._hits / total if total &gt; 0 else 0,\n                'size': len(self._cache)\n            }\n</code></pre>"},{"location":"features/caching/#best-practices","title":"Best Practices","text":"<ol> <li>Use consistent key formats: Always use <code>party:{id}:features:all</code></li> <li>Invalidate on updates: Clear cache when features are recomputed</li> <li>Tune TTL: Balance freshness vs. database load</li> <li>Monitor hit rate: Low hit rate indicates TTL too short</li> <li>Handle cache failures gracefully: Fall back to database on cache errors</li> </ol>"},{"location":"features/kyc-extractor/","title":"KYC Feature Extractor","text":"<p>The KYC Feature Extractor derives features from party profile data (KYC - Know Your Customer).</p>"},{"location":"features/kyc-extractor/#overview","title":"Overview","text":"Property Value Location <code>backend/app/extractors/kyc_extractor.py</code> Source Type <code>KYC</code> Source Table <code>parties</code> Features 5"},{"location":"features/kyc-extractor/#features-extracted","title":"Features Extracted","text":""},{"location":"features/kyc-extractor/#kyc_verified","title":"kyc_verified","text":"<p>Indicates whether the party has passed KYC verification.</p> Property Value Type Binary Range 0 or 1 Default 0 Confidence 1.0 <p>Logic: <pre><code>feature_value = float(party.kyc_verified)\n</code></pre></p> <p>Significance: Verified parties have confirmed identity, reducing fraud risk.</p>"},{"location":"features/kyc-extractor/#company_age_years","title":"company_age_years","text":"<p>Number of years since the company was created.</p> Property Value Type Numeric Range 0 to unlimited Default 0 Confidence 0.9 <p>Logic: <pre><code>years = (reference_date - party.created_at).days / 365.25\nfeature_value = max(0.0, years)\n</code></pre></p> <p>Significance: Older companies are generally more stable and lower risk.</p>"},{"location":"features/kyc-extractor/#party_type_score","title":"party_type_score","text":"<p>Numerical score based on the party's role in the supply chain.</p> Property Value Type Categorical encoded Range 5 to 10 Default 5 Confidence 1.0 <p>Encoding:</p> Party Type Score manufacturer 10 distributor 8 supplier 7 retailer 6 customer 5 <p>Logic: <pre><code>party_type_scores = {\n    \"manufacturer\": 10,\n    \"distributor\": 8,\n    \"supplier\": 7,\n    \"retailer\": 6,\n    \"customer\": 5\n}\nparty_type_key = party.party_type.lower()\nfeature_value = party_type_scores.get(party_type_key, 5)\n</code></pre></p> <p>Significance: Different party types have different risk profiles based on their position in the supply chain.</p>"},{"location":"features/kyc-extractor/#contact_completeness","title":"contact_completeness","text":"<p>Percentage of contact information fields that are filled.</p> Property Value Type Percentage Range 0 to 100 Default 0 Confidence 1.0 <p>Fields Checked: - contact_person - email - phone - address</p> <p>Logic: <pre><code>contact_fields = [party.contact_person, party.email, party.phone, party.address]\ncompleteness = sum(1 for f in contact_fields if f) / len(contact_fields)\nfeature_value = completeness * 100\n</code></pre></p> <p>Significance: Complete profiles indicate professional operations and easier communication.</p>"},{"location":"features/kyc-extractor/#has_tax_id","title":"has_tax_id","text":"<p>Indicates whether the party has a tax ID on file.</p> Property Value Type Binary Range 0 or 1 Default 0 Confidence 1.0 <p>Logic: <pre><code>feature_value = 1.0 if party.tax_id else 0.0\n</code></pre></p> <p>Significance: Missing tax IDs are red flags for legitimacy and compliance.</p>"},{"location":"features/kyc-extractor/#implementation","title":"Implementation","text":"<pre><code>class KYCFeatureExtractor(BaseFeatureExtractor):\n    \"\"\"Extract features from Party (KYC) data\"\"\"\n\n    def get_source_type(self) -&gt; str:\n        return \"KYC\"\n\n    def extract(self, party_id: int, db, as_of_date: datetime = None) -&gt; List[FeatureExtractorResult]:\n        party = db.query(Party).filter(Party.id == party_id).first()\n\n        if not party:\n            return []\n\n        ref_date = as_of_date or datetime.utcnow()\n        features = []\n\n        # kyc_verified\n        features.append(FeatureExtractorResult(\n            feature_name=\"kyc_verified\",\n            feature_value=float(party.kyc_verified),\n            confidence=1.0\n        ))\n\n        # company_age_years\n        if party.created_at:\n            years = (ref_date - party.created_at).days / 365.25\n            features.append(FeatureExtractorResult(\n                feature_name=\"company_age_years\",\n                feature_value=max(0.0, years),\n                confidence=0.9\n            ))\n\n        # party_type_score\n        party_type_scores = {\n            \"manufacturer\": 10,\n            \"distributor\": 8,\n            \"supplier\": 7,\n            \"retailer\": 6,\n            \"customer\": 5\n        }\n        party_type_key = party.party_type.lower() if party.party_type else \"customer\"\n        features.append(FeatureExtractorResult(\n            feature_name=\"party_type_score\",\n            feature_value=party_type_scores.get(party_type_key, 5),\n            confidence=1.0\n        ))\n\n        # contact_completeness\n        contact_fields = [party.contact_person, party.email, party.phone, party.address]\n        completeness = sum(1 for f in contact_fields if f) / len(contact_fields)\n        features.append(FeatureExtractorResult(\n            feature_name=\"contact_completeness\",\n            feature_value=completeness * 100,\n            confidence=1.0\n        ))\n\n        # has_tax_id\n        features.append(FeatureExtractorResult(\n            feature_name=\"has_tax_id\",\n            feature_value=1.0 if party.tax_id else 0.0,\n            confidence=1.0\n        ))\n\n        return features\n</code></pre>"},{"location":"features/kyc-extractor/#usage","title":"Usage","text":"<pre><code>from app.extractors.kyc_extractor import KYCFeatureExtractor\n\nextractor = KYCFeatureExtractor()\nfeatures = extractor.extract(party_id=123, db=session)\n\nfor f in features:\n    print(f\"{f.feature_name}: {f.feature_value}\")\n</code></pre> <p>Output: <pre><code>kyc_verified: 1.0\ncompany_age_years: 3.5\nparty_type_score: 8\ncontact_completeness: 75.0\nhas_tax_id: 1.0\n</code></pre></p>"},{"location":"features/kyc-extractor/#temporal-analysis","title":"Temporal Analysis","text":"<p>When <code>as_of_date</code> is provided, the extractor calculates age relative to that date:</p> <pre><code># Age as of January 1, 2024\nfeatures = extractor.extract(\n    party_id=123, \n    db=session, \n    as_of_date=datetime(2024, 1, 1)\n)\n</code></pre> <p>This enables historical analysis and prevents data leakage in training.</p>"},{"location":"features/network-extractor/","title":"Network Feature Extractor","text":"<p>The Network Feature Extractor derives features from business relationship graphs.</p>"},{"location":"features/network-extractor/#overview","title":"Overview","text":"Property Value Location <code>backend/app/extractors/network_extractor.py</code> Source Type <code>RELATIONSHIPS</code> Source Table <code>relationships</code> Features 6"},{"location":"features/network-extractor/#features-extracted","title":"Features Extracted","text":""},{"location":"features/network-extractor/#direct_counterparty_count","title":"direct_counterparty_count","text":"<p>Total number of direct business partners (suppliers and customers).</p> Property Value Type Count Range 0 to unlimited Default 0 Confidence 1.0 <p>Logic: <pre><code># Count downstream (customers)\ndownstream = db.query(Relationship).filter(\n    Relationship.from_party_id == party_id\n).count()\n\n# Count upstream (suppliers)\nupstream = db.query(Relationship).filter(\n    Relationship.to_party_id == party_id\n).count()\n\nfeature_value = float(downstream + upstream)\n</code></pre></p> <p>Significance: More direct partners indicate diversified business and lower concentration risk.</p>"},{"location":"features/network-extractor/#network_depth_downstream","title":"network_depth_downstream","text":"<p>Maximum number of hops to the furthest customer in the supply chain.</p> Property Value Type Count Range 0 to max_depth (typically 5) Default 0 Confidence 0.9 <p>Logic: <pre><code>downstream_network = get_downstream_network(db, party_id, max_depth=5)\nmax_depth = max([node['depth'] for node in downstream_network['nodes']], default=0)\nfeature_value = float(max_depth)\n</code></pre></p> <p>Significance: Deeper networks indicate reach and influence in the supply chain.</p>"},{"location":"features/network-extractor/#network_size","title":"network_size","text":"<p>Total unique parties connected to this party (directly or indirectly).</p> Property Value Type Count Range 0 to unlimited Default 0 Confidence 0.9 <p>Logic: <pre><code>downstream_network = get_downstream_network(db, party_id, max_depth=5)\nfeature_value = float(len(downstream_network['nodes']))\n</code></pre></p> <p>Significance: Larger networks indicate integration into the supply chain ecosystem.</p>"},{"location":"features/network-extractor/#supplier_count","title":"supplier_count","text":"<p>Number of upstream suppliers.</p> Property Value Type Count Range 0 to unlimited Default 0 Confidence 1.0 <p>Logic: <pre><code>feature_value = float(db.query(Relationship).filter(\n    Relationship.to_party_id == party_id\n).count())\n</code></pre></p> <p>Significance: Multiple suppliers reduce dependency on single sources.</p>"},{"location":"features/network-extractor/#customer_count","title":"customer_count","text":"<p>Number of downstream customers.</p> Property Value Type Count Range 0 to unlimited Default 0 Confidence 1.0 <p>Logic: <pre><code>feature_value = float(db.query(Relationship).filter(\n    Relationship.from_party_id == party_id\n).count())\n</code></pre></p> <p>Significance: Multiple customers indicate diversified revenue streams.</p>"},{"location":"features/network-extractor/#network_balance_ratio","title":"network_balance_ratio","text":"<p>Ratio indicating balance between suppliers and customers.</p> Property Value Type Ratio Range 0 to 1 Default 0.5 Confidence 0.8 <p>Logic: <pre><code>total = supplier_count + customer_count\nif total == 0:\n    feature_value = 0.5\nelse:\n    # Ratio of smaller to larger\n    smaller = min(supplier_count, customer_count)\n    larger = max(supplier_count, customer_count)\n    feature_value = smaller / larger if larger &gt; 0 else 0.5\n</code></pre></p> <p>Significance: Balanced networks (ratio closer to 1) indicate stable supply chain position.</p>"},{"location":"features/network-extractor/#implementation","title":"Implementation","text":"<pre><code>class NetworkFeatureExtractor(BaseFeatureExtractor):\n    \"\"\"Extract features from business network\"\"\"\n\n    def get_source_type(self) -&gt; str:\n        return \"RELATIONSHIPS\"\n\n    def extract(self, party_id: int, db, as_of_date: datetime = None) -&gt; List[FeatureExtractorResult]:\n        features = []\n        filter_date = as_of_date or datetime.utcnow()\n\n        # Helper to apply date filter\n        def filter_rel(query):\n            if as_of_date:\n                return query.filter(Relationship.established_date &lt;= filter_date)\n            return query\n\n        # Count direct relationships\n        downstream_q = db.query(Relationship).filter(\n            Relationship.from_party_id == party_id\n        )\n        downstream = filter_rel(downstream_q).count()\n\n        upstream_q = db.query(Relationship).filter(\n            Relationship.to_party_id == party_id\n        )\n        upstream = filter_rel(upstream_q).count()\n\n        # direct_counterparty_count\n        features.append(FeatureExtractorResult(\n            feature_name=\"direct_counterparty_count\",\n            feature_value=float(downstream + upstream),\n            confidence=1.0\n        ))\n\n        # Network graph analysis\n        try:\n            network = get_downstream_network(db, party_id, max_depth=5, as_of_date=filter_date)\n            max_depth = max([n['depth'] for n in network['nodes']], default=0)\n            network_size = len(network['nodes'])\n        except Exception:\n            max_depth = 0\n            network_size = 0\n\n        # network_depth_downstream\n        features.append(FeatureExtractorResult(\n            feature_name=\"network_depth_downstream\",\n            feature_value=float(max_depth),\n            confidence=0.9\n        ))\n\n        # network_size\n        features.append(FeatureExtractorResult(\n            feature_name=\"network_size\",\n            feature_value=float(network_size),\n            confidence=0.9\n        ))\n\n        # supplier_count\n        features.append(FeatureExtractorResult(\n            feature_name=\"supplier_count\",\n            feature_value=float(upstream),\n            confidence=1.0\n        ))\n\n        # customer_count\n        features.append(FeatureExtractorResult(\n            feature_name=\"customer_count\",\n            feature_value=float(downstream),\n            confidence=1.0\n        ))\n\n        # network_balance_ratio\n        total = upstream + downstream\n        if total &gt; 0:\n            smaller = min(upstream, downstream)\n            larger = max(upstream, downstream)\n            balance = smaller / larger if larger &gt; 0 else 0.5\n        else:\n            balance = 0.5\n\n        features.append(FeatureExtractorResult(\n            feature_name=\"network_balance_ratio\",\n            feature_value=balance,\n            confidence=0.8\n        ))\n\n        return features\n</code></pre>"},{"location":"features/network-extractor/#network-traversal","title":"Network Traversal","text":"<p>The <code>get_downstream_network</code> function performs recursive graph traversal:</p> <pre><code>def get_downstream_network(\n    db: Session, \n    party_id: int, \n    max_depth: int = 5,\n    as_of_date: datetime = None\n) -&gt; dict:\n    \"\"\"\n    Traverse downstream network from a party.\n\n    Returns:\n        dict with 'nodes' and 'edges' lists\n    \"\"\"\n    visited = set()\n    nodes = []\n    edges = []\n\n    def traverse(current_id, depth):\n        if depth &gt; max_depth or current_id in visited:\n            return\n\n        visited.add(current_id)\n        nodes.append({'id': current_id, 'depth': depth})\n\n        # Get downstream relationships\n        query = db.query(Relationship).filter(\n            Relationship.from_party_id == current_id\n        )\n        if as_of_date:\n            query = query.filter(Relationship.established_date &lt;= as_of_date)\n\n        for rel in query.all():\n            edges.append({'from': current_id, 'to': rel.to_party_id})\n            traverse(rel.to_party_id, depth + 1)\n\n    traverse(party_id, 0)\n    return {'nodes': nodes, 'edges': edges}\n</code></pre>"},{"location":"features/network-extractor/#usage","title":"Usage","text":"<pre><code>from app.extractors.network_extractor import NetworkFeatureExtractor\n\nextractor = NetworkFeatureExtractor()\nfeatures = extractor.extract(party_id=123, db=session)\n\nfor f in features:\n    print(f\"{f.feature_name}: {f.feature_value}\")\n</code></pre> <p>Output: <pre><code>direct_counterparty_count: 8.0\nnetwork_depth_downstream: 3.0\nnetwork_size: 15.0\nsupplier_count: 3.0\ncustomer_count: 5.0\nnetwork_balance_ratio: 0.6\n</code></pre></p>"},{"location":"features/network-extractor/#temporal-analysis","title":"Temporal Analysis","text":"<p>The extractor respects <code>as_of_date</code> for historical network analysis:</p> <pre><code># Network as it existed on January 1, 2024\nfeatures = extractor.extract(\n    party_id=123,\n    db=session,\n    as_of_date=datetime(2024, 1, 1)\n)\n</code></pre> <p>Only relationships with <code>established_date &lt;= as_of_date</code> are included.</p>"},{"location":"features/network-extractor/#performance-considerations","title":"Performance Considerations","text":"Factor Impact Mitigation Deep networks Exponential traversal max_depth limit (default: 5) Large networks Memory for visited set Efficient set operations Cyclic relationships Infinite loops visited set tracking"},{"location":"features/pipeline/","title":"Feature Extraction Pipeline","text":"<p>The feature extraction pipeline transforms raw party data into numerical features suitable for credit scoring.</p>"},{"location":"features/pipeline/#overview","title":"Overview","text":"<p>Features are extracted from three data sources by specialized extractors:</p> Extractor Source Table Features KYCFeatureExtractor parties kyc_verified, company_age_years, party_type_score, contact_completeness, has_tax_id TransactionFeatureExtractor transactions transaction_count_6m, avg_transaction_amount, total_transaction_volume_6m, transaction_regularity_score, recent_activity_flag NetworkFeatureExtractor relationships direct_counterparty_count, network_depth_downstream, network_size, supplier_count, customer_count, network_balance_ratio"},{"location":"features/pipeline/#pipeline-architecture","title":"Pipeline Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   FeaturePipelineService                            \u2502\n\u2502                                                                     \u2502\n\u2502   extract_all_features(party_id)                                    \u2502\n\u2502         \u2502                                                           \u2502\n\u2502         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502         \u2502                 \u2502                 \u2502                 \u2502    \u2502\n\u2502         \u25bc                 \u25bc                 \u25bc                 \u2502    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502    \u2502\n\u2502   \u2502    KYC    \u2502    \u2502Transaction\u2502    \u2502  Network  \u2502           \u2502    \u2502\n\u2502   \u2502 Extractor \u2502    \u2502 Extractor \u2502    \u2502 Extractor \u2502           \u2502    \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518           \u2502    \u2502\n\u2502         \u2502                \u2502                \u2502                 \u2502    \u2502\n\u2502         \u25bc                \u25bc                \u25bc                 \u2502    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502    \u2502\n\u2502   \u2502 Features  \u2502    \u2502 Features  \u2502    \u2502 Features  \u2502           \u2502    \u2502\n\u2502   \u2502  + meta   \u2502    \u2502  + meta   \u2502    \u2502  + meta   \u2502           \u2502    \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518           \u2502    \u2502\n\u2502         \u2502                \u2502                \u2502                 \u2502    \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502    \u2502\n\u2502                          \u25bc                                  \u2502    \u2502\n\u2502                   _store_features()                         \u2502    \u2502\n\u2502                          \u2502                                  \u2502    \u2502\n\u2502                          \u25bc                                  \u2502    \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502    \u2502\n\u2502                   \u2502  features   \u2502                           \u2502    \u2502\n\u2502                   \u2502   table     \u2502                           \u2502    \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"features/pipeline/#featurepipelineservice","title":"FeaturePipelineService","text":""},{"location":"features/pipeline/#location","title":"Location","text":"<p><code>backend/app/services/feature_pipeline_service.py</code></p>"},{"location":"features/pipeline/#initialization","title":"Initialization","text":"<pre><code>class FeaturePipelineService:\n    def __init__(self, db: Session):\n        self.db = db\n        self.extractors = [\n            KYCFeatureExtractor(),\n            TransactionFeatureExtractor(),\n            NetworkFeatureExtractor()\n        ]\n\n        self.source_name_map = {\n            \"kyc\": \"KYC\",\n            \"transaction\": \"TRANSACTIONS\",\n            \"network\": \"RELATIONSHIPS\"\n        }\n</code></pre>"},{"location":"features/pipeline/#key-methods","title":"Key Methods","text":""},{"location":"features/pipeline/#extract_all_features","title":"extract_all_features","text":"<p>Extracts features from all sources for a single party:</p> <pre><code>def extract_all_features(self, party_id: int, as_of_date: datetime = None) -&gt; dict:\n    \"\"\"\n    Extract features from all sources for a party.\n\n    Args:\n        party_id: ID of the party\n        as_of_date: Optional historical date for temporal analysis\n\n    Returns:\n        dict with party_id, feature_count, sources, features_list\n    \"\"\"\n</code></pre>"},{"location":"features/pipeline/#run","title":"run","text":"<p>Extracts features for all parties in a batch:</p> <pre><code>def run(self, batch_id: str) -&gt; dict:\n    \"\"\"\n    Run feature extraction for all parties in a batch.\n\n    Returns:\n        dict with batch_id, processed_parties, status\n    \"\"\"\n</code></pre>"},{"location":"features/pipeline/#run_single","title":"run_single","text":"<p>Extracts features from a specific source:</p> <pre><code>def run_single(self, batch_id: str, source: str) -&gt; dict:\n    \"\"\"\n    Run extraction for a specific source type.\n\n    Args:\n        batch_id: Batch identifier\n        source: 'kyc', 'transaction', or 'network'\n    \"\"\"\n</code></pre>"},{"location":"features/pipeline/#base-extractor-interface","title":"Base Extractor Interface","text":""},{"location":"features/pipeline/#location_1","title":"Location","text":"<p><code>backend/app/extractors/base_extractor.py</code></p>"},{"location":"features/pipeline/#interface","title":"Interface","text":"<pre><code>from dataclasses import dataclass, field\nfrom typing import List, Any, Dict\n\n@dataclass\nclass FeatureExtractorResult:\n    feature_name: str\n    feature_value: float\n    confidence: float = 1.0\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\nclass BaseFeatureExtractor:\n    def get_source_type(self) -&gt; str:\n        \"\"\"Return the source type identifier (e.g., 'KYC', 'TRANSACTIONS').\"\"\"\n        raise NotImplementedError\n\n    def extract(\n        self, \n        party_id: int, \n        db: Session, \n        as_of_date: datetime = None\n    ) -&gt; List[FeatureExtractorResult]:\n        \"\"\"\n        Extract features for a party.\n\n        Args:\n            party_id: ID of the party\n            db: Database session\n            as_of_date: Optional date for temporal analysis\n\n        Returns:\n            List of FeatureExtractorResult objects\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"features/pipeline/#feature-storage","title":"Feature Storage","text":""},{"location":"features/pipeline/#temporal-versioning","title":"Temporal Versioning","text":"<p>Features use <code>valid_from</code> and <code>valid_to</code> for versioning:</p> <ul> <li><code>valid_to = NULL</code>: Current version</li> <li><code>valid_to = timestamp</code>: Expired version</li> </ul> <p>When new features are extracted:</p> <ol> <li>Previous features with matching <code>source_type</code> are expired (<code>valid_to = NOW()</code>)</li> <li>New features are inserted with <code>valid_from = NOW()</code>, <code>valid_to = NULL</code></li> </ol>"},{"location":"features/pipeline/#storage-logic","title":"Storage Logic","text":"<pre><code>def _store_features(self, party_id: int, features: list, affected_sources: List[str] = None):\n    \"\"\"\n    Store features in database.\n\n    Args:\n        party_id: Party ID\n        features: List of FeatureExtractorResult\n        affected_sources: Source types to expire (None = all)\n    \"\"\"\n    # Expire old features\n    query = self.db.query(Feature).filter(\n        Feature.party_id == party_id,\n        Feature.valid_to == None\n    )\n\n    if affected_sources:\n        query = query.filter(Feature.source_type.in_(affected_sources))\n\n    query.update({\"valid_to\": datetime.utcnow()})\n\n    # Insert new features\n    for feat in features:\n        feature = Feature(\n            party_id=party_id,\n            feature_name=feat.feature_name,\n            feature_value=feat.feature_value,\n            confidence_score=feat.confidence,\n            source_type=feat.metadata.get(\"source_type\"),\n            feature_metadata=feat.metadata,\n            valid_from=datetime.utcnow()\n        )\n        self.db.add(feature)\n\n    self.db.commit()\n</code></pre>"},{"location":"features/pipeline/#temporal-feature-extraction","title":"Temporal Feature Extraction","text":"<p>The <code>as_of_date</code> parameter enables historical analysis:</p> <pre><code># Get features as of January 1, 2024\nfeatures = pipeline.extract_all_features(\n    party_id=123,\n    as_of_date=datetime(2024, 1, 1)\n)\n</code></pre> <p>When <code>as_of_date</code> is provided:</p> <ol> <li>Transactions are filtered: <code>transaction_date &lt;= as_of_date</code></li> <li>Relationships are filtered: <code>established_date &lt;= as_of_date</code></li> <li>Company age is calculated relative to <code>as_of_date</code></li> <li>Features are NOT stored in database (read-only analysis)</li> </ol>"},{"location":"features/pipeline/#feature-list","title":"Feature List","text":""},{"location":"features/pipeline/#kyc-features","title":"KYC Features","text":"Feature Type Range Description kyc_verified Binary 0-1 Whether party passed KYC verification company_age_years Numeric 0+ Years since company creation party_type_score Numeric 5-10 Score based on party type contact_completeness Percentage 0-100 Percentage of contact fields filled has_tax_id Binary 0-1 Whether party has tax ID on file"},{"location":"features/pipeline/#transaction-features","title":"Transaction Features","text":"Feature Type Range Description transaction_count_6m Count 0+ Number of transactions in last 6 months avg_transaction_amount Currency 0+ Average transaction amount total_transaction_volume_6m Currency 0+ Total transaction volume in 6 months transaction_regularity_score Percentage 0-100 Consistency of monthly volumes recent_activity_flag Binary 0-1 Activity in last 30 days"},{"location":"features/pipeline/#network-features","title":"Network Features","text":"Feature Type Range Description direct_counterparty_count Count 0+ Direct business partners network_depth_downstream Count 0+ Maximum hops to furthest customer network_size Count 0+ Total unique parties in network supplier_count Count 0+ Number of upstream suppliers customer_count Count 0+ Number of downstream customers network_balance_ratio Ratio 0-1 Ratio of suppliers to customers"},{"location":"features/pipeline/#batch-processing","title":"Batch Processing","text":"<p>For processing entire batches:</p> <pre><code># Run all extractors for a batch\npipeline = FeaturePipelineService(db)\nresult = pipeline.run(batch_id=\"BATCH_001\")\n\n# Output: {\"batch_id\": \"BATCH_001\", \"processed_parties\": 100, \"status\": \"completed\"}\n</code></pre> <p>Or run specific sources:</p> <pre><code># Run only KYC extraction\npipeline.run_single(batch_id=\"BATCH_001\", source=\"kyc\")\n\n# Run only transaction extraction\npipeline.run_single(batch_id=\"BATCH_001\", source=\"transaction\")\n</code></pre>"},{"location":"features/pipeline/#error-handling","title":"Error Handling","text":"<p>Extractors handle errors gracefully:</p> <pre><code>for extractor in self.extractors:\n    try:\n        features = extractor.extract(party_id, self.db, as_of_date=as_of_date)\n        all_features.extend(features)\n    except Exception as e:\n        print(f\"Error extracting from {extractor.get_source_type()}: {e}\")\n        # Continue with other extractors\n</code></pre> <p>Failed extractions: - Log the error - Continue with remaining extractors - Return partial results</p>"},{"location":"features/transaction-extractor/","title":"Transaction Feature Extractor","text":"<p>The Transaction Feature Extractor derives features from financial transaction history.</p>"},{"location":"features/transaction-extractor/#overview","title":"Overview","text":"Property Value Location <code>backend/app/extractors/transaction_extractor.py</code> Source Type <code>TRANSACTIONS</code> Source Table <code>transactions</code> Features 5 Time Window 6 months"},{"location":"features/transaction-extractor/#features-extracted","title":"Features Extracted","text":""},{"location":"features/transaction-extractor/#transaction_count_6m","title":"transaction_count_6m","text":"<p>Number of transactions in the last 6 months.</p> Property Value Type Count Range 0 to unlimited Default 0 Confidence 1.0 <p>Logic: <pre><code>transactions = db.query(Transaction).filter(\n    Transaction.party_id == party_id,\n    Transaction.transaction_date &gt;= six_months_ago,\n    Transaction.transaction_date &lt;= reference_date\n).all()\n\nfeature_value = float(len(transactions))\n</code></pre></p> <p>Significance: Active parties with more transactions show healthy business operations.</p>"},{"location":"features/transaction-extractor/#avg_transaction_amount","title":"avg_transaction_amount","text":"<p>Average transaction amount over the period.</p> Property Value Type Currency Range 0 to unlimited Default 0 Confidence 1.0 <p>Logic: <pre><code>amounts = [t.amount for t in transactions]\nfeature_value = sum(amounts) / len(amounts) if amounts else 0\n</code></pre></p> <p>Significance: Indicates typical deal size and business scale.</p>"},{"location":"features/transaction-extractor/#total_transaction_volume_6m","title":"total_transaction_volume_6m","text":"<p>Total monetary volume of all transactions.</p> Property Value Type Currency Range 0 to unlimited Default 0 Confidence 1.0 <p>Logic: <pre><code>feature_value = sum(t.amount for t in transactions)\n</code></pre></p> <p>Significance: Higher volume indicates larger business scale and capacity.</p>"},{"location":"features/transaction-extractor/#transaction_regularity_score","title":"transaction_regularity_score","text":"<p>Measures consistency of monthly transaction volumes using coefficient of variation.</p> Property Value Type Percentage Range 0 to 100 Default 0 Confidence 0.9 <p>Logic: <pre><code># Group transactions by month\nmonthly_volumes = {}\nfor txn in transactions:\n    month_key = txn.transaction_date.strftime(\"%Y-%m\")\n    monthly_volumes[month_key] = monthly_volumes.get(month_key, 0.0) + txn.amount\n\n# Calculate coefficient of variation\nvolumes = list(monthly_volumes.values())\nmean_vol = np.mean(volumes)\nstd_vol = np.std(volumes)\n\n# CV = std / mean (lower is more regular)\ncv = std_vol / mean_vol if mean_vol &gt; 0 else 1.0\n\n# Convert to 0-100 score (higher is more regular)\nfeature_value = max(0, 100 - (cv * 100))\n</code></pre></p> <p>Significance: Regular, predictable cash flows indicate stable operations.</p>"},{"location":"features/transaction-extractor/#recent_activity_flag","title":"recent_activity_flag","text":"<p>Binary flag indicating activity in the last 30 days.</p> Property Value Type Binary Range 0 or 1 Default 0 Confidence 1.0 <p>Logic: <pre><code>thirty_days_ago = reference_date - timedelta(days=30)\nrecent_txns = [t for t in transactions if t.transaction_date &gt;= thirty_days_ago]\nfeature_value = 1.0 if recent_txns else 0.0\n</code></pre></p> <p>Significance: Recent activity confirms the business is currently operational.</p>"},{"location":"features/transaction-extractor/#implementation","title":"Implementation","text":"<pre><code>class TransactionFeatureExtractor(BaseFeatureExtractor):\n    \"\"\"Extract features from Transaction history\"\"\"\n\n    def get_source_type(self) -&gt; str:\n        return \"TRANSACTIONS\"\n\n    def extract(self, party_id: int, db, as_of_date: datetime = None) -&gt; List[FeatureExtractorResult]:\n        features = []\n        ref_date = as_of_date or datetime.utcnow()\n        six_months_ago = ref_date - timedelta(days=180)\n\n        # Query transactions within time window\n        transactions = db.query(Transaction).filter(\n            Transaction.party_id == party_id,\n            Transaction.transaction_date &gt;= six_months_ago,\n            Transaction.transaction_date &lt;= ref_date\n        ).all()\n\n        if not transactions:\n            return self._get_default_features()\n\n        # transaction_count_6m\n        features.append(FeatureExtractorResult(\n            feature_name=\"transaction_count_6m\",\n            feature_value=float(len(transactions)),\n            confidence=1.0\n        ))\n\n        # avg_transaction_amount\n        amounts = [t.amount for t in transactions]\n        features.append(FeatureExtractorResult(\n            feature_name=\"avg_transaction_amount\",\n            feature_value=sum(amounts) / len(amounts),\n            confidence=1.0\n        ))\n\n        # total_transaction_volume_6m\n        features.append(FeatureExtractorResult(\n            feature_name=\"total_transaction_volume_6m\",\n            feature_value=sum(amounts),\n            confidence=1.0\n        ))\n\n        # transaction_regularity_score\n        monthly_volumes = {}\n        for txn in transactions:\n            month_key = txn.transaction_date.strftime(\"%Y-%m\")\n            monthly_volumes[month_key] = monthly_volumes.get(month_key, 0.0) + txn.amount\n\n        if len(monthly_volumes) &gt;= 2:\n            volumes = list(monthly_volumes.values())\n            mean_vol = np.mean(volumes)\n            std_vol = np.std(volumes)\n            cv = std_vol / mean_vol if mean_vol &gt; 0 else 1.0\n            regularity = max(0, 100 - (cv * 100))\n        else:\n            regularity = 50.0  # Default for single month\n\n        features.append(FeatureExtractorResult(\n            feature_name=\"transaction_regularity_score\",\n            feature_value=regularity,\n            confidence=0.9\n        ))\n\n        # recent_activity_flag\n        thirty_days_ago = ref_date - timedelta(days=30)\n        recent = any(t.transaction_date &gt;= thirty_days_ago for t in transactions)\n        features.append(FeatureExtractorResult(\n            feature_name=\"recent_activity_flag\",\n            feature_value=1.0 if recent else 0.0,\n            confidence=1.0\n        ))\n\n        return features\n\n    def _get_default_features(self) -&gt; List[FeatureExtractorResult]:\n        \"\"\"Return default values when no transactions exist.\"\"\"\n        return [\n            FeatureExtractorResult(\"transaction_count_6m\", 0.0, 1.0),\n            FeatureExtractorResult(\"avg_transaction_amount\", 0.0, 1.0),\n            FeatureExtractorResult(\"total_transaction_volume_6m\", 0.0, 1.0),\n            FeatureExtractorResult(\"transaction_regularity_score\", 0.0, 0.5),\n            FeatureExtractorResult(\"recent_activity_flag\", 0.0, 1.0),\n        ]\n</code></pre>"},{"location":"features/transaction-extractor/#usage","title":"Usage","text":"<pre><code>from app.extractors.transaction_extractor import TransactionFeatureExtractor\n\nextractor = TransactionFeatureExtractor()\nfeatures = extractor.extract(party_id=123, db=session)\n\nfor f in features:\n    print(f\"{f.feature_name}: {f.feature_value}\")\n</code></pre> <p>Output: <pre><code>transaction_count_6m: 45.0\navg_transaction_amount: 5250.50\ntotal_transaction_volume_6m: 236272.50\ntransaction_regularity_score: 78.5\nrecent_activity_flag: 1.0\n</code></pre></p>"},{"location":"features/transaction-extractor/#temporal-analysis","title":"Temporal Analysis","text":"<p>The extractor respects <code>as_of_date</code> for historical analysis:</p> <pre><code># Get transaction features as of 6 months ago\nfeatures = extractor.extract(\n    party_id=123,\n    db=session,\n    as_of_date=datetime(2024, 1, 1)\n)\n</code></pre> <p>Only transactions with <code>transaction_date &lt;= as_of_date</code> are included.</p>"},{"location":"features/transaction-extractor/#edge-cases","title":"Edge Cases","text":"Scenario Behavior No transactions Return default features with 0 values Single transaction Regularity score = 50 (unknown) All transactions in one month Regularity score = 50 Negative amounts Included in calculations (credit notes)"},{"location":"frontend/dashboard/","title":"Main Dashboard","text":"<p>The main dashboard provides an overview of credit scoring statistics and batch processing status.</p>"},{"location":"frontend/dashboard/#overview","title":"Overview","text":"Property Value Location <code>frontend/src/pages/Dashboard.jsx</code> Route <code>/</code> Data Source <code>/api/scoring/statistics</code>"},{"location":"frontend/dashboard/#features","title":"Features","text":""},{"location":"frontend/dashboard/#score-distribution-chart","title":"Score Distribution Chart","text":"<p>Displays distribution of scores across bands:</p> <pre><code>import { BarChart, Bar, XAxis, YAxis, Tooltip, ResponsiveContainer } from 'recharts'\n\nfunction ScoreDistribution({ data }) {\n  const chartData = [\n    { band: 'Excellent', count: data.excellent, color: '#22c55e' },\n    { band: 'Good', count: data.good, color: '#84cc16' },\n    { band: 'Fair', count: data.fair, color: '#eab308' },\n    { band: 'Poor', count: data.poor, color: '#f97316' },\n    { band: 'Very Poor', count: data.very_poor, color: '#ef4444' }\n  ]\n\n  return (\n    &lt;ResponsiveContainer width=\"100%\" height={300}&gt;\n      &lt;BarChart data={chartData}&gt;\n        &lt;XAxis dataKey=\"band\" /&gt;\n        &lt;YAxis /&gt;\n        &lt;Tooltip /&gt;\n        &lt;Bar dataKey=\"count\" fill=\"#3b82f6\" /&gt;\n      &lt;/BarChart&gt;\n    &lt;/ResponsiveContainer&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/dashboard/#statistics-summary","title":"Statistics Summary","text":"<p>Key metrics cards:</p> <pre><code>function StatsSummary({ statistics }) {\n  return (\n    &lt;div className=\"stats-grid\"&gt;\n      &lt;StatCard \n        label=\"Total Scored\" \n        value={statistics.total_scored} \n        icon=\"users\"\n      /&gt;\n      &lt;StatCard \n        label=\"Average Score\" \n        value={statistics.score_statistics.mean.toFixed(0)} \n        icon=\"chart\"\n      /&gt;\n      &lt;StatCard \n        label=\"Excellent Rate\" \n        value={`${statistics.band_distribution.excellent.percentage.toFixed(1)}%`} \n        icon=\"star\"\n      /&gt;\n      &lt;StatCard \n        label=\"High Risk\" \n        value={`${(statistics.band_distribution.poor.percentage + \n                   statistics.band_distribution.very_poor.percentage).toFixed(1)}%`} \n        icon=\"alert\"\n      /&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/dashboard/#recent-activity","title":"Recent Activity","text":"<p>List of recent scoring events:</p> <pre><code>function RecentActivity({ scores }) {\n  return (\n    &lt;div className=\"activity-list\"&gt;\n      &lt;h3&gt;Recent Scores&lt;/h3&gt;\n      &lt;ul&gt;\n        {scores.map(score =&gt; (\n          &lt;li key={score.id} className={`band-${score.band}`}&gt;\n            &lt;span className=\"party-name\"&gt;{score.party_name}&lt;/span&gt;\n            &lt;span className=\"score\"&gt;{score.total_score}&lt;/span&gt;\n            &lt;span className=\"band\"&gt;{score.band}&lt;/span&gt;\n            &lt;span className=\"time\"&gt;{formatTime(score.computed_at)}&lt;/span&gt;\n          &lt;/li&gt;\n        ))}\n      &lt;/ul&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/dashboard/#batch-selector","title":"Batch Selector","text":"<p>Switch between batches:</p> <pre><code>function BatchSelector({ batches, selected, onChange }) {\n  return (\n    &lt;select \n      value={selected} \n      onChange={(e) =&gt; onChange(e.target.value)}\n      className=\"batch-select\"\n    &gt;\n      &lt;option value=\"\"&gt;All Batches&lt;/option&gt;\n      {batches.map(batch =&gt; (\n        &lt;option key={batch.id} value={batch.id}&gt;\n          {batch.id} ({batch.count} parties)\n        &lt;/option&gt;\n      ))}\n    &lt;/select&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/dashboard/#complete-component","title":"Complete Component","text":"<pre><code>import { useState, useEffect } from 'react'\nimport { BarChart, Bar, XAxis, YAxis, Tooltip, ResponsiveContainer } from 'recharts'\nimport { getStatistics, getRecentScores, getBatches } from '../api/scoring'\n\nfunction Dashboard() {\n  const [statistics, setStatistics] = useState(null)\n  const [recentScores, setRecentScores] = useState([])\n  const [batches, setBatches] = useState([])\n  const [selectedBatch, setSelectedBatch] = useState('')\n  const [loading, setLoading] = useState(true)\n  const [error, setError] = useState(null)\n\n  useEffect(() =&gt; {\n    async function fetchData() {\n      try {\n        setLoading(true)\n        const [statsData, scoresData, batchesData] = await Promise.all([\n          getStatistics(selectedBatch),\n          getRecentScores(selectedBatch),\n          getBatches()\n        ])\n        setStatistics(statsData)\n        setRecentScores(scoresData)\n        setBatches(batchesData)\n      } catch (err) {\n        setError(err.message)\n      } finally {\n        setLoading(false)\n      }\n    }\n    fetchData()\n  }, [selectedBatch])\n\n  if (loading) return &lt;div className=\"loading\"&gt;Loading...&lt;/div&gt;\n  if (error) return &lt;div className=\"error\"&gt;Error: {error}&lt;/div&gt;\n\n  const chartData = Object.entries(statistics.band_distribution).map(([band, data]) =&gt; ({\n    band: band.replace('_', ' '),\n    count: data.count,\n    percentage: data.percentage\n  }))\n\n  return (\n    &lt;div className=\"dashboard\"&gt;\n      &lt;header className=\"dashboard-header\"&gt;\n        &lt;h1&gt;Credit Scoring Dashboard&lt;/h1&gt;\n        &lt;BatchSelector \n          batches={batches}\n          selected={selectedBatch}\n          onChange={setSelectedBatch}\n        /&gt;\n      &lt;/header&gt;\n\n      &lt;div className=\"stats-grid\"&gt;\n        &lt;div className=\"stat-card\"&gt;\n          &lt;div className=\"stat-value\"&gt;{statistics.total_scored}&lt;/div&gt;\n          &lt;div className=\"stat-label\"&gt;Total Scored&lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div className=\"stat-card\"&gt;\n          &lt;div className=\"stat-value\"&gt;{statistics.score_statistics.mean.toFixed(0)}&lt;/div&gt;\n          &lt;div className=\"stat-label\"&gt;Average Score&lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div className=\"stat-card\"&gt;\n          &lt;div className=\"stat-value\"&gt;{statistics.score_statistics.median}&lt;/div&gt;\n          &lt;div className=\"stat-label\"&gt;Median Score&lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div className=\"stat-card\"&gt;\n          &lt;div className=\"stat-value\"&gt;\n            {statistics.score_statistics.min} - {statistics.score_statistics.max}\n          &lt;/div&gt;\n          &lt;div className=\"stat-label\"&gt;Score Range&lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n\n      &lt;div className=\"charts-row\"&gt;\n        &lt;div className=\"chart-card\"&gt;\n          &lt;h3&gt;Score Distribution by Band&lt;/h3&gt;\n          &lt;ResponsiveContainer width=\"100%\" height={300}&gt;\n            &lt;BarChart data={chartData}&gt;\n              &lt;XAxis dataKey=\"band\" /&gt;\n              &lt;YAxis /&gt;\n              &lt;Tooltip \n                formatter={(value, name) =&gt; [value, name === 'count' ? 'Count' : '%']}\n              /&gt;\n              &lt;Bar dataKey=\"count\" fill=\"#3b82f6\" /&gt;\n            &lt;/BarChart&gt;\n          &lt;/ResponsiveContainer&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n\n      &lt;div className=\"recent-activity\"&gt;\n        &lt;h3&gt;Recent Scoring Activity&lt;/h3&gt;\n        &lt;table&gt;\n          &lt;thead&gt;\n            &lt;tr&gt;\n              &lt;th&gt;Party&lt;/th&gt;\n              &lt;th&gt;Score&lt;/th&gt;\n              &lt;th&gt;Band&lt;/th&gt;\n              &lt;th&gt;Time&lt;/th&gt;\n            &lt;/tr&gt;\n          &lt;/thead&gt;\n          &lt;tbody&gt;\n            {recentScores.map(score =&gt; (\n              &lt;tr key={score.id}&gt;\n                &lt;td&gt;{score.party_name}&lt;/td&gt;\n                &lt;td&gt;{score.total_score}&lt;/td&gt;\n                &lt;td className={`band-${score.band}`}&gt;{score.band}&lt;/td&gt;\n                &lt;td&gt;{new Date(score.computed_at).toLocaleString()}&lt;/td&gt;\n              &lt;/tr&gt;\n            ))}\n          &lt;/tbody&gt;\n        &lt;/table&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n\nexport default Dashboard\n</code></pre>"},{"location":"frontend/dashboard/#styling","title":"Styling","text":"<pre><code>/* Dashboard styles */\n.dashboard {\n  padding: 2rem;\n  max-width: 1400px;\n  margin: 0 auto;\n}\n\n.dashboard-header {\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n  margin-bottom: 2rem;\n}\n\n.stats-grid {\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n  gap: 1rem;\n  margin-bottom: 2rem;\n}\n\n.stat-card {\n  background: white;\n  border-radius: 8px;\n  padding: 1.5rem;\n  text-align: center;\n  box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n\n.stat-value {\n  font-size: 2rem;\n  font-weight: bold;\n  color: #3b82f6;\n}\n\n.stat-label {\n  color: #64748b;\n  margin-top: 0.5rem;\n}\n\n.chart-card {\n  background: white;\n  border-radius: 8px;\n  padding: 1.5rem;\n  box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n\n.band-excellent { color: #22c55e; }\n.band-good { color: #84cc16; }\n.band-fair { color: #eab308; }\n.band-poor { color: #f97316; }\n.band-very_poor { color: #ef4444; }\n</code></pre>"},{"location":"frontend/dashboard/#api-integration","title":"API Integration","text":"<pre><code>// src/api/scoring.js\n\nexport async function getStatistics(batchId = null) {\n  const params = batchId ? { batch_id: batchId } : {}\n  const response = await client.get('/api/scoring/statistics', { params })\n  return response.data\n}\n\nexport async function getRecentScores(batchId = null, limit = 10) {\n  const params = { limit, ...(batchId &amp;&amp; { batch_id: batchId }) }\n  const response = await client.get('/api/scoring/recent', { params })\n  return response.data.scores\n}\n\nexport async function getBatches() {\n  const response = await client.get('/api/synthetic/batches')\n  return response.data.batches\n}\n</code></pre>"},{"location":"frontend/dashboard/#refresh-behavior","title":"Refresh Behavior","text":"<p>Auto-refresh statistics:</p> <pre><code>useEffect(() =&gt; {\n  const interval = setInterval(() =&gt; {\n    fetchData()\n  }, 30000) // 30 seconds\n\n  return () =&gt; clearInterval(interval)\n}, [selectedBatch])\n</code></pre>"},{"location":"frontend/ml-dashboard/","title":"ML Dashboard","text":"<p>The ML Dashboard provides visibility into machine learning pipeline status, model performance, and scorecard versions.</p>"},{"location":"frontend/ml-dashboard/#overview","title":"Overview","text":"Property Value Location <code>frontend/src/pages/MLDashboard.jsx</code> Route <code>/ml</code> Data Sources <code>/api/pipeline/runs</code>, <code>/api/scoring/versions</code>, <code>/api/pipeline/models</code>"},{"location":"frontend/ml-dashboard/#features","title":"Features","text":""},{"location":"frontend/ml-dashboard/#pipeline-status","title":"Pipeline Status","text":"<p>Current pipeline execution status:</p> <pre><code>function PipelineStatus({ runs }) {\n  const latestRun = runs[0]\n\n  const statusColors = {\n    SUCCESS: '#22c55e',\n    FAILURE: '#ef4444',\n    STARTED: '#3b82f6',\n    QUEUED: '#94a3b8'\n  }\n\n  return (\n    &lt;div className=\"pipeline-status\"&gt;\n      &lt;h3&gt;Latest Pipeline Run&lt;/h3&gt;\n      {latestRun ? (\n        &lt;div className=\"run-card\"&gt;\n          &lt;div \n            className=\"status-badge\"\n            style={{ background: statusColors[latestRun.status] }}\n          &gt;\n            {latestRun.status}\n          &lt;/div&gt;\n          &lt;div className=\"run-info\"&gt;\n            &lt;span&gt;Pipeline: {latestRun.pipeline}&lt;/span&gt;\n            &lt;span&gt;Batch: {latestRun.batch_id}&lt;/span&gt;\n            &lt;span&gt;Duration: {latestRun.duration_seconds}s&lt;/span&gt;\n            &lt;span&gt;Started: {formatDate(latestRun.started_at)}&lt;/span&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      ) : (\n        &lt;p&gt;No pipeline runs found&lt;/p&gt;\n      )}\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#model-performance","title":"Model Performance","text":"<p>Current model metrics:</p> <pre><code>import { LineChart, Line, XAxis, YAxis, Tooltip, ResponsiveContainer } from 'recharts'\n\nfunction ModelPerformance({ models }) {\n  const chartData = models.map(model =&gt; ({\n    date: formatDate(model.created_at),\n    auc_roc: model.metrics.auc_roc,\n    accuracy: model.metrics.accuracy\n  }))\n\n  return (\n    &lt;div className=\"model-performance\"&gt;\n      &lt;h3&gt;Model Performance Over Time&lt;/h3&gt;\n      &lt;ResponsiveContainer width=\"100%\" height={300}&gt;\n        &lt;LineChart data={chartData}&gt;\n          &lt;XAxis dataKey=\"date\" /&gt;\n          &lt;YAxis domain={[0.5, 1]} /&gt;\n          &lt;Tooltip /&gt;\n          &lt;Line \n            type=\"monotone\" \n            dataKey=\"auc_roc\" \n            stroke=\"#3b82f6\" \n            name=\"AUC-ROC\"\n          /&gt;\n          &lt;Line \n            type=\"monotone\" \n            dataKey=\"accuracy\" \n            stroke=\"#22c55e\" \n            name=\"Accuracy\"\n          /&gt;\n        &lt;/LineChart&gt;\n      &lt;/ResponsiveContainer&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#feature-importance","title":"Feature Importance","text":"<p>Visualization of feature weights:</p> <pre><code>import { BarChart, Bar, XAxis, YAxis, Tooltip, ResponsiveContainer } from 'recharts'\n\nfunction FeatureImportance({ importance }) {\n  const data = Object.entries(importance)\n    .map(([feature, value]) =&gt; ({\n      feature: feature.replace(/_/g, ' '),\n      importance: Math.abs(value),\n      direction: value &gt; 0 ? 'positive' : 'negative'\n    }))\n    .sort((a, b) =&gt; b.importance - a.importance)\n    .slice(0, 10)\n\n  return (\n    &lt;div className=\"feature-importance\"&gt;\n      &lt;h3&gt;Top Feature Importance&lt;/h3&gt;\n      &lt;ResponsiveContainer width=\"100%\" height={400}&gt;\n        &lt;BarChart data={data} layout=\"vertical\"&gt;\n          &lt;XAxis type=\"number\" /&gt;\n          &lt;YAxis dataKey=\"feature\" type=\"category\" width={150} /&gt;\n          &lt;Tooltip /&gt;\n          &lt;Bar dataKey=\"importance\" fill=\"#3b82f6\" /&gt;\n        &lt;/BarChart&gt;\n      &lt;/ResponsiveContainer&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#scorecard-versions","title":"Scorecard Versions","text":"<p>List and manage scorecard versions:</p> <pre><code>function ScorecardVersions({ versions, onActivate }) {\n  return (\n    &lt;div className=\"scorecard-versions\"&gt;\n      &lt;h3&gt;Scorecard Versions&lt;/h3&gt;\n      &lt;table&gt;\n        &lt;thead&gt;\n          &lt;tr&gt;\n            &lt;th&gt;Version&lt;/th&gt;\n            &lt;th&gt;Status&lt;/th&gt;\n            &lt;th&gt;Base&lt;/th&gt;\n            &lt;th&gt;Model&lt;/th&gt;\n            &lt;th&gt;Created&lt;/th&gt;\n            &lt;th&gt;Actions&lt;/th&gt;\n          &lt;/tr&gt;\n        &lt;/thead&gt;\n        &lt;tbody&gt;\n          {versions.map(version =&gt; (\n            &lt;tr key={version.version_id}&gt;\n              &lt;td&gt;{version.version_id}&lt;/td&gt;\n              &lt;td&gt;\n                &lt;span className={`status-${version.status}`}&gt;\n                  {version.status}\n                &lt;/span&gt;\n              &lt;/td&gt;\n              &lt;td&gt;{version.base_version || '-'}&lt;/td&gt;\n              &lt;td&gt;{version.model_id || '-'}&lt;/td&gt;\n              &lt;td&gt;{formatDate(version.created_at)}&lt;/td&gt;\n              &lt;td&gt;\n                {version.status !== 'active' &amp;&amp; (\n                  &lt;button \n                    onClick={() =&gt; onActivate(version.version_id)}\n                    className=\"btn-activate\"\n                  &gt;\n                    Activate\n                  &lt;/button&gt;\n                )}\n              &lt;/td&gt;\n            &lt;/tr&gt;\n          ))}\n        &lt;/tbody&gt;\n      &lt;/table&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#version-comparison","title":"Version Comparison","text":"<p>Compare two scorecard versions:</p> <pre><code>function VersionComparison({ comparison }) {\n  return (\n    &lt;div className=\"version-comparison\"&gt;\n      &lt;h3&gt;\n        Comparing {comparison.version_a} vs {comparison.version_b}\n      &lt;/h3&gt;\n      &lt;table&gt;\n        &lt;thead&gt;\n          &lt;tr&gt;\n            &lt;th&gt;Feature&lt;/th&gt;\n            &lt;th&gt;{comparison.version_a}&lt;/th&gt;\n            &lt;th&gt;{comparison.version_b}&lt;/th&gt;\n            &lt;th&gt;Change&lt;/th&gt;\n          &lt;/tr&gt;\n        &lt;/thead&gt;\n        &lt;tbody&gt;\n          {comparison.features.map(feat =&gt; (\n            &lt;tr key={feat.feature}&gt;\n              &lt;td&gt;{feat.feature}&lt;/td&gt;\n              &lt;td&gt;{feat.weight_a.toFixed(2)}&lt;/td&gt;\n              &lt;td&gt;{feat.weight_b.toFixed(2)}&lt;/td&gt;\n              &lt;td className={feat.pct_change &gt; 0 ? 'positive' : 'negative'}&gt;\n                {feat.pct_change &gt; 0 ? '+' : ''}{feat.pct_change.toFixed(1)}%\n              &lt;/td&gt;\n            &lt;/tr&gt;\n          ))}\n        &lt;/tbody&gt;\n      &lt;/table&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#pipeline-trigger","title":"Pipeline Trigger","text":"<p>Manually trigger ML pipeline:</p> <pre><code>function PipelineTrigger({ batches, onTrigger }) {\n  const [selectedBatch, setSelectedBatch] = useState('')\n  const [triggering, setTriggering] = useState(false)\n\n  const handleTrigger = async () =&gt; {\n    if (!selectedBatch) return\n\n    setTriggering(true)\n    try {\n      await onTrigger(selectedBatch)\n      alert('Pipeline triggered successfully')\n    } catch (err) {\n      alert(`Failed to trigger: ${err.message}`)\n    } finally {\n      setTriggering(false)\n    }\n  }\n\n  return (\n    &lt;div className=\"pipeline-trigger\"&gt;\n      &lt;h3&gt;Trigger ML Pipeline&lt;/h3&gt;\n      &lt;div className=\"trigger-form\"&gt;\n        &lt;select \n          value={selectedBatch}\n          onChange={(e) =&gt; setSelectedBatch(e.target.value)}\n        &gt;\n          &lt;option value=\"\"&gt;Select Batch&lt;/option&gt;\n          {batches.map(batch =&gt; (\n            &lt;option key={batch.id} value={batch.id}&gt;\n              {batch.id}\n            &lt;/option&gt;\n          ))}\n        &lt;/select&gt;\n        &lt;button \n          onClick={handleTrigger}\n          disabled={!selectedBatch || triggering}\n        &gt;\n          {triggering ? 'Triggering...' : 'Trigger Pipeline'}\n        &lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#complete-component","title":"Complete Component","text":"<pre><code>import { useState, useEffect } from 'react'\nimport { \n  getPipelineRuns, \n  getModels, \n  triggerPipeline \n} from '../api/pipeline'\nimport { \n  getScorecardVersions, \n  activateScorecardVersion,\n  compareScorecardVersions \n} from '../api/scoring'\n\nfunction MLDashboard() {\n  const [runs, setRuns] = useState([])\n  const [models, setModels] = useState([])\n  const [versions, setVersions] = useState([])\n  const [comparison, setComparison] = useState(null)\n  const [loading, setLoading] = useState(true)\n\n  useEffect(() =&gt; {\n    async function fetchData() {\n      try {\n        const [runsData, modelsData, versionsData] = await Promise.all([\n          getPipelineRuns(),\n          getModels(),\n          getScorecardVersions()\n        ])\n        setRuns(runsData)\n        setModels(modelsData)\n        setVersions(versionsData)\n      } finally {\n        setLoading(false)\n      }\n    }\n    fetchData()\n  }, [])\n\n  const handleActivate = async (versionId) =&gt; {\n    if (confirm(`Activate scorecard version ${versionId}?`)) {\n      await activateScorecardVersion(versionId)\n      const updatedVersions = await getScorecardVersions()\n      setVersions(updatedVersions)\n    }\n  }\n\n  const handleCompare = async (versionA, versionB) =&gt; {\n    const result = await compareScorecardVersions(versionA, versionB)\n    setComparison(result)\n  }\n\n  const handleTrigger = async (batchId) =&gt; {\n    await triggerPipeline('ml_training_pipeline', { batch_id: batchId })\n    const updatedRuns = await getPipelineRuns()\n    setRuns(updatedRuns)\n  }\n\n  if (loading) return &lt;div className=\"loading\"&gt;Loading...&lt;/div&gt;\n\n  const latestModel = models[0]\n\n  return (\n    &lt;div className=\"ml-dashboard\"&gt;\n      &lt;h1&gt;ML Pipeline Dashboard&lt;/h1&gt;\n\n      &lt;div className=\"dashboard-grid\"&gt;\n        &lt;PipelineStatus runs={runs} /&gt;\n\n        {latestModel &amp;&amp; (\n          &lt;&gt;\n            &lt;div className=\"metrics-card\"&gt;\n              &lt;h3&gt;Latest Model Metrics&lt;/h3&gt;\n              &lt;div className=\"metric\"&gt;\n                &lt;span&gt;AUC-ROC&lt;/span&gt;\n                &lt;span className=\"value\"&gt;{latestModel.metrics.auc_roc.toFixed(3)}&lt;/span&gt;\n              &lt;/div&gt;\n              &lt;div className=\"metric\"&gt;\n                &lt;span&gt;Accuracy&lt;/span&gt;\n                &lt;span className=\"value\"&gt;{latestModel.metrics.accuracy.toFixed(3)}&lt;/span&gt;\n              &lt;/div&gt;\n              &lt;div className=\"metric\"&gt;\n                &lt;span&gt;Samples&lt;/span&gt;\n                &lt;span className=\"value\"&gt;{latestModel.metrics.samples_train}&lt;/span&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;FeatureImportance importance={latestModel.feature_importance} /&gt;\n          &lt;/&gt;\n        )}\n\n        &lt;ModelPerformance models={models} /&gt;\n\n        &lt;ScorecardVersions \n          versions={versions} \n          onActivate={handleActivate}\n          onCompare={handleCompare}\n        /&gt;\n\n        {comparison &amp;&amp; &lt;VersionComparison comparison={comparison} /&gt;}\n\n        &lt;PipelineTrigger \n          batches={[{ id: 'BATCH_001' }]} \n          onTrigger={handleTrigger}\n        /&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n\nexport default MLDashboard\n</code></pre>"},{"location":"frontend/ml-dashboard/#api-integration","title":"API Integration","text":"<pre><code>// src/api/pipeline.js\n\nexport async function getPipelineRuns(limit = 10) {\n  const response = await client.get('/api/pipeline/runs', { params: { limit } })\n  return response.data.runs\n}\n\nexport async function getModels(limit = 10) {\n  const response = await client.get('/api/pipeline/models', { params: { limit } })\n  return response.data.models\n}\n\nexport async function triggerPipeline(pipeline, config) {\n  const response = await client.post(`/api/pipeline/trigger/${pipeline}`, config)\n  return response.data\n}\n\n// src/api/scoring.js\n\nexport async function getScorecardVersions() {\n  const response = await client.get('/api/scoring/versions')\n  return response.data.versions\n}\n\nexport async function activateScorecardVersion(versionId) {\n  const response = await client.post(`/api/scoring/versions/${versionId}/activate`)\n  return response.data\n}\n\nexport async function compareScorecardVersions(versionA, versionB) {\n  const response = await client.get('/api/scoring/versions/compare', {\n    params: { a: versionA, b: versionB }\n  })\n  return response.data\n}\n</code></pre>"},{"location":"frontend/ml-dashboard/#styling","title":"Styling","text":"<pre><code>.ml-dashboard {\n  padding: 2rem;\n  max-width: 1400px;\n  margin: 0 auto;\n}\n\n.dashboard-grid {\n  display: grid;\n  grid-template-columns: repeat(2, 1fr);\n  gap: 1.5rem;\n}\n\n.metrics-card {\n  background: white;\n  border-radius: 8px;\n  padding: 1.5rem;\n  box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n\n.metric {\n  display: flex;\n  justify-content: space-between;\n  padding: 0.5rem 0;\n  border-bottom: 1px solid #e2e8f0;\n}\n\n.metric .value {\n  font-weight: bold;\n  color: #3b82f6;\n}\n\n.status-active {\n  color: #22c55e;\n  font-weight: bold;\n}\n\n.status-draft {\n  color: #f59e0b;\n}\n\n.status-inactive {\n  color: #94a3b8;\n}\n\n.positive { color: #22c55e; }\n.negative { color: #ef4444; }\n</code></pre>"},{"location":"frontend/overview/","title":"Frontend Overview","text":"<p>The KYCC frontend provides a web interface for credit scoring visualization and management.</p>"},{"location":"frontend/overview/#overview","title":"Overview","text":"Property Value Framework React 18 Build Tool Vite Styling CSS Charts Recharts Network Graph ReactFlow HTTP Client Axios Router React Router v7"},{"location":"frontend/overview/#project-structure","title":"Project Structure","text":"<pre><code>frontend/\n\u251c\u2500\u2500 index.html\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 vite.config.js\n\u251c\u2500\u2500 eslint.config.js\n\u251c\u2500\u2500 public/\n\u2502   \u2514\u2500\u2500 favicon.ico\n\u2514\u2500\u2500 src/\n    \u251c\u2500\u2500 main.jsx          # Application entry\n    \u251c\u2500\u2500 App.jsx           # Root component with routing\n    \u251c\u2500\u2500 App.css           # Global styles\n    \u251c\u2500\u2500 index.css         # Base styles\n    \u251c\u2500\u2500 api/\n    \u2502   \u2514\u2500\u2500 client.js     # Axios configuration\n    \u251c\u2500\u2500 components/\n    \u2502   \u251c\u2500\u2500 Header.jsx\n    \u2502   \u251c\u2500\u2500 Sidebar.jsx\n    \u2502   \u251c\u2500\u2500 ScoreCard.jsx\n    \u2502   \u2514\u2500\u2500 NetworkGraph.jsx\n    \u2514\u2500\u2500 pages/\n        \u251c\u2500\u2500 Dashboard.jsx\n        \u251c\u2500\u2500 MLDashboard.jsx\n        \u251c\u2500\u2500 PartyList.jsx\n        \u251c\u2500\u2500 PartyDetail.jsx\n        \u2514\u2500\u2500 NetworkGraph.jsx\n</code></pre>"},{"location":"frontend/overview/#getting-started","title":"Getting Started","text":""},{"location":"frontend/overview/#installation","title":"Installation","text":"<pre><code>cd frontend\nnpm install\n</code></pre>"},{"location":"frontend/overview/#development","title":"Development","text":"<pre><code>npm run dev\n</code></pre> <p>Opens at <code>http://localhost:5173</code></p>"},{"location":"frontend/overview/#production-build","title":"Production Build","text":"<pre><code>npm run build\nnpm run preview\n</code></pre>"},{"location":"frontend/overview/#configuration","title":"Configuration","text":""},{"location":"frontend/overview/#environment-variables","title":"Environment Variables","text":"<p>Create <code>.env</code> file:</p> <pre><code>VITE_API_URL=http://localhost:8000\n</code></pre>"},{"location":"frontend/overview/#vite-configuration","title":"Vite Configuration","text":"<pre><code>// vite.config.js\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [react()],\n  server: {\n    port: 5173,\n    proxy: {\n      '/api': {\n        target: 'http://localhost:8000',\n        changeOrigin: true\n      }\n    }\n  }\n})\n</code></pre>"},{"location":"frontend/overview/#routing","title":"Routing","text":""},{"location":"frontend/overview/#routes","title":"Routes","text":"Path Component Description / Dashboard Main dashboard /ml MLDashboard ML pipeline dashboard /parties PartyList List of parties /parties/:id PartyDetail Party details /network NetworkGraph Network visualization /network/:id NetworkGraph Party network"},{"location":"frontend/overview/#router-setup","title":"Router Setup","text":"<pre><code>// App.jsx\nimport { BrowserRouter, Routes, Route } from 'react-router-dom'\n\nfunction App() {\n  return (\n    &lt;BrowserRouter&gt;\n      &lt;Routes&gt;\n        &lt;Route path=\"/\" element={&lt;Dashboard /&gt;} /&gt;\n        &lt;Route path=\"/ml\" element={&lt;MLDashboard /&gt;} /&gt;\n        &lt;Route path=\"/parties\" element={&lt;PartyList /&gt;} /&gt;\n        &lt;Route path=\"/parties/:id\" element={&lt;PartyDetail /&gt;} /&gt;\n        &lt;Route path=\"/network\" element={&lt;NetworkGraph /&gt;} /&gt;\n        &lt;Route path=\"/network/:id\" element={&lt;NetworkGraph /&gt;} /&gt;\n      &lt;/Routes&gt;\n    &lt;/BrowserRouter&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/overview/#api-client","title":"API Client","text":""},{"location":"frontend/overview/#configuration_1","title":"Configuration","text":"<pre><code>// src/api/client.js\nimport axios from 'axios'\n\nconst client = axios.create({\n  baseURL: import.meta.env.VITE_API_URL || 'http://localhost:8000',\n  headers: {\n    'Content-Type': 'application/json'\n  }\n})\n\n// Request interceptor\nclient.interceptors.request.use(config =&gt; {\n  // Add auth token if available\n  const token = localStorage.getItem('token')\n  if (token) {\n    config.headers.Authorization = `Bearer ${token}`\n  }\n  return config\n})\n\n// Response interceptor\nclient.interceptors.response.use(\n  response =&gt; response,\n  error =&gt; {\n    if (error.response?.status === 401) {\n      // Handle unauthorized\n      window.location.href = '/login'\n    }\n    return Promise.reject(error)\n  }\n)\n\nexport default client\n</code></pre>"},{"location":"frontend/overview/#api-functions","title":"API Functions","text":"<pre><code>// src/api/scoring.js\nimport client from './client'\n\nexport const scoreParty = async (partyId) =&gt; {\n  const response = await client.post('/api/scoring/run', { party_id: partyId })\n  return response.data\n}\n\nexport const getPartyScore = async (partyId) =&gt; {\n  const response = await client.get(`/api/scoring/party/${partyId}`)\n  return response.data\n}\n\nexport const getStatistics = async (batchId) =&gt; {\n  const response = await client.get('/api/scoring/statistics', {\n    params: { batch_id: batchId }\n  })\n  return response.data\n}\n</code></pre>"},{"location":"frontend/overview/#state-management","title":"State Management","text":"<p>Using React hooks for local state:</p> <pre><code>// Example: Dashboard state\nfunction Dashboard() {\n  const [statistics, setStatistics] = useState(null)\n  const [loading, setLoading] = useState(true)\n  const [error, setError] = useState(null)\n\n  useEffect(() =&gt; {\n    async function fetchData() {\n      try {\n        const data = await getStatistics()\n        setStatistics(data)\n      } catch (err) {\n        setError(err.message)\n      } finally {\n        setLoading(false)\n      }\n    }\n    fetchData()\n  }, [])\n\n  if (loading) return &lt;Loading /&gt;\n  if (error) return &lt;Error message={error} /&gt;\n\n  return &lt;DashboardContent statistics={statistics} /&gt;\n}\n</code></pre>"},{"location":"frontend/overview/#components","title":"Components","text":""},{"location":"frontend/overview/#scorecard","title":"ScoreCard","text":"<p>Displays credit score with band indicator:</p> <pre><code>function ScoreCard({ score, band }) {\n  const bandColors = {\n    excellent: '#22c55e',\n    good: '#84cc16',\n    fair: '#eab308',\n    poor: '#f97316',\n    very_poor: '#ef4444'\n  }\n\n  return (\n    &lt;div className=\"score-card\"&gt;\n      &lt;div \n        className=\"score-value\"\n        style={{ color: bandColors[band] }}\n      &gt;\n        {score}\n      &lt;/div&gt;\n      &lt;div className=\"score-band\"&gt;{band.replace('_', ' ')}&lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/overview/#networkgraph","title":"NetworkGraph","text":"<p>ReactFlow network visualization:</p> <pre><code>import ReactFlow, { \n  Background, \n  Controls,\n  MiniMap \n} from 'reactflow'\n\nfunction NetworkGraph({ nodes, edges }) {\n  return (\n    &lt;div style={{ height: 600 }}&gt;\n      &lt;ReactFlow\n        nodes={nodes}\n        edges={edges}\n        fitView\n      &gt;\n        &lt;Background /&gt;\n        &lt;Controls /&gt;\n        &lt;MiniMap /&gt;\n      &lt;/ReactFlow&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"frontend/overview/#styling","title":"Styling","text":""},{"location":"frontend/overview/#global-styles","title":"Global Styles","text":"<pre><code>/* src/index.css */\n:root {\n  --primary: #3b82f6;\n  --success: #22c55e;\n  --warning: #eab308;\n  --danger: #ef4444;\n  --background: #f8fafc;\n  --text: #1e293b;\n}\n\nbody {\n  font-family: system-ui, sans-serif;\n  background: var(--background);\n  color: var(--text);\n}\n</code></pre>"},{"location":"frontend/overview/#component-styles","title":"Component Styles","text":"<pre><code>/* src/App.css */\n.dashboard {\n  display: grid;\n  grid-template-columns: 250px 1fr;\n  min-height: 100vh;\n}\n\n.main-content {\n  padding: 2rem;\n}\n\n.card {\n  background: white;\n  border-radius: 8px;\n  padding: 1.5rem;\n  box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n}\n</code></pre>"},{"location":"frontend/overview/#dependencies","title":"Dependencies","text":"<pre><code>{\n  \"dependencies\": {\n    \"react\": \"^18.2.0\",\n    \"react-dom\": \"^18.2.0\",\n    \"react-router-dom\": \"^7.0.0\",\n    \"axios\": \"^1.6.0\",\n    \"recharts\": \"^2.10.0\",\n    \"reactflow\": \"^11.10.0\"\n  },\n  \"devDependencies\": {\n    \"@vitejs/plugin-react\": \"^4.2.0\",\n    \"vite\": \"^5.0.0\",\n    \"eslint\": \"^8.55.0\"\n  }\n}\n</code></pre>"},{"location":"frontend/overview/#best-practices","title":"Best Practices","text":"<ol> <li>Component Structure: Keep components small and focused</li> <li>Error Handling: Always handle loading and error states</li> <li>API Calls: Centralize in api/ directory</li> <li>Styling: Use CSS variables for theming</li> <li>Performance: Use React.memo for expensive renders</li> <li>Accessibility: Include ARIA labels and keyboard navigation</li> </ol>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>This guide covers all configuration options for KYCC.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"getting-started/configuration/#database-configuration","title":"Database Configuration","text":"Variable Default Description <code>DATABASE_URL</code> <code>postgresql://localhost/kycc_db</code> Full database connection string <code>POSTGRES_USER</code> <code>kycc_user</code> PostgreSQL username <code>POSTGRES_PASSWORD</code> <code>kycc_pass</code> PostgreSQL password <code>POSTGRES_DB</code> <code>kycc_db</code> PostgreSQL database name <code>POSTGRES_PORT</code> <code>5433</code> PostgreSQL port <code>POSTGRES_HOST</code> <code>localhost</code> PostgreSQL host"},{"location":"getting-started/configuration/#application-configuration","title":"Application Configuration","text":"Variable Default Description <code>AUTO_CREATE_TABLES</code> <code>0</code> Auto-create tables on startup (1=yes, 0=no) <code>LOG_LEVEL</code> <code>INFO</code> Logging level (DEBUG, INFO, WARNING, ERROR) <code>FORCE_SQLITE_FALLBACK</code> <code>0</code> Force SQLite instead of PostgreSQL"},{"location":"getting-started/configuration/#dagster-configuration","title":"Dagster Configuration","text":"Variable Default Description <code>DAGSTER_HOME</code> <code>./dagster_instance</code> Dagster instance directory <code>PYTHONPATH</code> <code>.</code> Python path for imports"},{"location":"getting-started/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"getting-started/configuration/#backend-environment-file","title":"Backend Environment File","text":"<p>Location: <code>backend/.env</code></p> <pre><code># Database\nDATABASE_URL=postgresql://kycc_user:kycc_pass@localhost:5433/kycc_db\nPOSTGRES_USER=kycc_user\nPOSTGRES_PASSWORD=kycc_pass\nPOSTGRES_DB=kycc_db\nPOSTGRES_PORT=5433\n\n# Application Settings\nAUTO_CREATE_TABLES=1\nLOG_LEVEL=INFO\n\n# Dagster\nDAGSTER_HOME=./dagster_instance\n</code></pre>"},{"location":"getting-started/configuration/#alembic-configuration","title":"Alembic Configuration","text":"<p>Location: <code>backend/alembic.ini</code></p> <p>Key settings:</p> <pre><code>[alembic]\nscript_location = alembic\nsqlalchemy.url = postgresql://kycc_user:kycc_pass@localhost:5433/kycc_db\n\n[logging]\nlevel = INFO\n</code></pre>"},{"location":"getting-started/configuration/#dagster-configuration_1","title":"Dagster Configuration","text":"<p>Location: <code>backend/dagster_instance/dagster.yaml</code></p> <pre><code>storage:\n  sqlite:\n    base_dir: ./dagster_instance/history\n\nrun_launcher:\n  module: dagster.core.launcher\n  class: DefaultRunLauncher\n\nrun_coordinator:\n  module: dagster.core.run_coordinator\n  class: DefaultRunCoordinator\n\ntelemetry:\n  enabled: false\n</code></pre>"},{"location":"getting-started/configuration/#dagster-workspace","title":"Dagster Workspace","text":"<p>Location: <code>backend/dagster_home/workspace.yaml</code></p> <pre><code>load_from:\n  - python_file:\n      relative_path: definitions.py\n      working_directory: /workspace/dagster_home\n</code></pre>"},{"location":"getting-started/configuration/#scorecard-configuration","title":"Scorecard Configuration","text":"<p>The default scorecard configuration is defined in <code>backend/app/scorecard/scorecard_config.py</code>:</p> <pre><code>INITIAL_SCORECARD_V1 = {\n    'version': '1.0',\n    'base_score': 300,\n    'max_score': 900,\n    'target_default_rate': 0.05,\n\n    'weights': {\n        # KYC Features\n        'kyc_verified': 15,\n        'has_tax_id': 10,\n        'contact_completeness': 5,\n\n        # Company Profile\n        'company_age_years': 10,\n        'party_type_score': 10,\n\n        # Transaction Features\n        'transaction_count_6m': 20,\n        'avg_transaction_amount': 15,\n        'recent_activity_flag': 25,\n        'transaction_regularity_score': 15,\n\n        # Network Features\n        'network_size': 10,\n        'direct_counterparty_count': 10,\n        'network_balance_ratio': 10,\n        'network_depth_downstream': 10,\n    },\n\n    'feature_scaling': {\n        'company_age_years': {'max_value': 5, 'method': 'cap'},\n        'transaction_count_6m': {'max_value': 50, 'method': 'cap'},\n        'avg_transaction_amount': {'max_value': 100000, 'method': 'log_scale'},\n        'network_size': {'max_value': 20, 'method': 'cap'},\n        'direct_counterparty_count': {'max_value': 10, 'method': 'cap'},\n        'network_depth_downstream': {'max_value': 5, 'method': 'cap'},\n    }\n}\n</code></pre>"},{"location":"getting-started/configuration/#modifying-scorecard-weights","title":"Modifying Scorecard Weights","text":"<p>To modify the scorecard:</p> <ol> <li>Through the database: Update the <code>scorecard_versions</code> table</li> <li>Through ML refinement: Run the training pipeline to create a new version</li> <li>Through code: Modify <code>scorecard_config.py</code> (requires restart)</li> </ol>"},{"location":"getting-started/configuration/#cors-configuration","title":"CORS Configuration","text":"<p>Location: <code>backend/main.py</code></p> <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        \"http://localhost:3000\",\n        \"http://localhost:5173\",\n        \"http://localhost:5174\",\n        \"http://localhost:8080\",\n        \"http://localhost:8000\",\n        \"http://127.0.0.1:8000\",\n    ],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n</code></pre> <p>Add additional origins as needed for production deployments.</p>"},{"location":"getting-started/configuration/#ml-pipeline-configuration","title":"ML Pipeline Configuration","text":""},{"location":"getting-started/configuration/#quality-gates","title":"Quality Gates","text":"<p>Located in <code>backend/app/services/scorecard_version_service.py</code>:</p> <pre><code>MIN_AUC_THRESHOLD = 0.55      # Minimum AUC to accept model\nIMPROVEMENT_THRESHOLD = 0.005  # Required improvement over current (0.5%)\n</code></pre>"},{"location":"getting-started/configuration/#model-training-defaults","title":"Model Training Defaults","text":"<p>Located in <code>backend/app/services/model_training_service.py</code>:</p> <pre><code>default_hyperparams = {\n    'C': 1.0,\n    'penalty': 'l2',\n    'max_iter': 1000,\n    'solver': 'lbfgs',\n    'class_weight': 'balanced'\n}\n</code></pre>"},{"location":"getting-started/configuration/#cache-configuration","title":"Cache Configuration","text":"<p>The TTL cache is configured in <code>backend/app/cache/ttl_cache.py</code>:</p> <pre><code>DEFAULT_TTL = 300  # 5 minutes\nMAX_CACHE_SIZE = 1000\n</code></pre> <p>Cache key format: <code>party:{party_id}:features:all</code></p>"},{"location":"getting-started/configuration/#docker-configuration","title":"Docker Configuration","text":""},{"location":"getting-started/configuration/#docker-composeyml","title":"docker-compose.yml","text":"<pre><code>services:\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n      POSTGRES_DB: ${POSTGRES_DB}\n    ports:\n      - \"${POSTGRES_PORT:-5433}:5432\"\n    volumes:\n      - kycc_pgdata:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  backend:\n    build: ./backend\n    environment:\n      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n\n  dagster:\n    build: ./backend\n    command: dagster-webserver -h 0.0.0.0 -p 3000\n    environment:\n      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}\n      DAGSTER_HOME: /workspace/dagster_instance\n    ports:\n      - \"3000:3000\"\n</code></pre>"},{"location":"getting-started/configuration/#production-configuration","title":"Production Configuration","text":"<p>For production deployments:</p>"},{"location":"getting-started/configuration/#security","title":"Security","text":"<pre><code># Use strong passwords\nPOSTGRES_PASSWORD=&lt;strong-random-password&gt;\n\n# Disable auto table creation\nAUTO_CREATE_TABLES=0\n\n# Restrict CORS origins\n# Modify main.py allow_origins list\n</code></pre>"},{"location":"getting-started/configuration/#performance","title":"Performance","text":"<pre><code># Increase worker count\nUVICORN_WORKERS=4\n\n# Enable connection pooling\nDATABASE_POOL_SIZE=20\nDATABASE_MAX_OVERFLOW=10\n</code></pre>"},{"location":"getting-started/configuration/#logging","title":"Logging","text":"<pre><code>LOG_LEVEL=WARNING\nLOG_FORMAT=json\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide provides detailed installation instructions for all KYCC components.</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#minimum-requirements","title":"Minimum Requirements","text":"Component Requirement CPU 2 cores RAM 4 GB Disk 10 GB free space OS Windows 10+, Ubuntu 20.04+, macOS 12+"},{"location":"getting-started/installation/#software-dependencies","title":"Software Dependencies","text":"Software Version Purpose Python 3.11+ Backend runtime Node.js 18+ Frontend build PostgreSQL 15+ Primary database Docker 24+ Containerization Git 2.40+ Version control"},{"location":"getting-started/installation/#backend-installation","title":"Backend Installation","text":""},{"location":"getting-started/installation/#1-clone-repository","title":"1. Clone Repository","text":"<pre><code>git clone https://github.com/kzauha/KYCC.git\ncd KYCC/backend\n</code></pre>"},{"location":"getting-started/installation/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code># Create venv\npython -m venv venv\n\n# Activate (Windows PowerShell)\n.\\venv\\Scripts\\Activate.ps1\n\n# Activate (Windows CMD)\n.\\venv\\Scripts\\activate.bat\n\n# Activate (Linux/macOS)\nsource venv/bin/activate\n</code></pre>"},{"location":"getting-started/installation/#3-install-python-dependencies","title":"3. Install Python Dependencies","text":"<pre><code>pip install --upgrade pip\npip install -r requirements.txt\n</code></pre> <p>Key dependencies:</p> Package Purpose fastapi Web framework uvicorn ASGI server sqlalchemy ORM psycopg2-binary PostgreSQL driver pydantic Data validation dagster Pipeline orchestration scikit-learn Machine learning pandas Data manipulation numpy Numerical computing joblib Model serialization simpleeval Safe expression evaluation"},{"location":"getting-started/installation/#4-configure-environment","title":"4. Configure Environment","text":"<p>Create <code>backend/.env</code>:</p> <pre><code># Database\nDATABASE_URL=postgresql://kycc_user:kycc_pass@localhost:5433/kycc_db\nPOSTGRES_USER=kycc_user\nPOSTGRES_PASSWORD=kycc_pass\nPOSTGRES_DB=kycc_db\nPOSTGRES_PORT=5433\n\n# Application\nAUTO_CREATE_TABLES=1\nLOG_LEVEL=INFO\n\n# Dagster\nDAGSTER_HOME=/path/to/backend/dagster_instance\n</code></pre>"},{"location":"getting-started/installation/#5-initialize-database","title":"5. Initialize Database","text":"<pre><code># Run Alembic migrations\nalembic upgrade head\n\n# Or auto-create tables (development only)\npython -c \"from app.db.database import init_db; init_db()\"\n</code></pre>"},{"location":"getting-started/installation/#6-start-backend-server","title":"6. Start Backend Server","text":"<pre><code># Development mode with auto-reload\npython -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload\n\n# Production mode\npython -m uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4\n</code></pre>"},{"location":"getting-started/installation/#frontend-installation","title":"Frontend Installation","text":""},{"location":"getting-started/installation/#1-navigate-to-frontend","title":"1. Navigate to Frontend","text":"<pre><code>cd frontend\n</code></pre>"},{"location":"getting-started/installation/#2-install-node-dependencies","title":"2. Install Node Dependencies","text":"<pre><code>npm install\n</code></pre> <p>Key dependencies:</p> Package Purpose react UI framework react-router-dom Client-side routing axios HTTP client recharts Chart visualization reactflow Network graph visualization bootstrap CSS framework"},{"location":"getting-started/installation/#3-configure-api-endpoint","title":"3. Configure API Endpoint","text":"<p>The frontend connects to the backend at <code>http://localhost:8000</code> by default. To change this, modify the API base URL in:</p> <ul> <li><code>src/pages/Dashboard.jsx</code></li> <li><code>src/pages/MLDashboard.jsx</code></li> <li><code>src/api/</code> files</li> </ul>"},{"location":"getting-started/installation/#4-start-development-server","title":"4. Start Development Server","text":"<pre><code>npm run dev\n</code></pre> <p>The frontend will be available at http://localhost:5173.</p>"},{"location":"getting-started/installation/#5-build-for-production","title":"5. Build for Production","text":"<pre><code>npm run build\n</code></pre> <p>Built files will be in <code>frontend/dist/</code>.</p>"},{"location":"getting-started/installation/#database-installation","title":"Database Installation","text":""},{"location":"getting-started/installation/#option-1-docker-recommended","title":"Option 1: Docker (Recommended)","text":"<pre><code>docker run -d \\\n  --name kycc-postgres \\\n  -e POSTGRES_USER=kycc_user \\\n  -e POSTGRES_PASSWORD=kycc_pass \\\n  -e POSTGRES_DB=kycc_db \\\n  -p 5433:5432 \\\n  -v kycc_pgdata:/var/lib/postgresql/data \\\n  postgres:15-alpine\n</code></pre>"},{"location":"getting-started/installation/#option-2-local-postgresql","title":"Option 2: Local PostgreSQL","text":"<ol> <li>Install PostgreSQL 15</li> <li>Create database and user:</li> </ol> <pre><code>CREATE USER kycc_user WITH PASSWORD 'kycc_pass';\nCREATE DATABASE kycc_db OWNER kycc_user;\nGRANT ALL PRIVILEGES ON DATABASE kycc_db TO kycc_user;\n</code></pre>"},{"location":"getting-started/installation/#option-3-sqlite-fallback","title":"Option 3: SQLite Fallback","text":"<p>KYCC automatically falls back to SQLite if PostgreSQL is unavailable. This is useful for development and testing but not recommended for production.</p> <p>The fallback creates <code>backend/kycc_local.db</code>.</p>"},{"location":"getting-started/installation/#dagster-installation","title":"Dagster Installation","text":"<p>Dagster provides pipeline orchestration for the ML workflow.</p>"},{"location":"getting-started/installation/#1-configure-dagster-home","title":"1. Configure Dagster Home","text":"<p>Create <code>backend/dagster_instance/dagster.yaml</code>:</p> <pre><code>storage:\n  sqlite:\n    base_dir: ./dagster_instance/history\n\nrun_launcher:\n  module: dagster.core.launcher\n  class: DefaultRunLauncher\n\nrun_coordinator:\n  module: dagster.core.run_coordinator\n  class: DefaultRunCoordinator\n</code></pre>"},{"location":"getting-started/installation/#2-start-dagster-webserver","title":"2. Start Dagster Webserver","text":"<pre><code>cd backend\nexport DAGSTER_HOME=$(pwd)/dagster_instance\nexport PYTHONPATH=$(pwd)\n\ndagster-webserver -h 0.0.0.0 -p 3000 --workspace dagster_home/workspace.yaml\n</code></pre>"},{"location":"getting-started/installation/#3-start-dagster-daemon-optional","title":"3. Start Dagster Daemon (Optional)","text":"<p>For scheduled runs and sensors:</p> <pre><code>dagster-daemon run\n</code></pre>"},{"location":"getting-started/installation/#docker-compose-installation","title":"Docker Compose Installation","text":"<p>The easiest way to run all services together.</p>"},{"location":"getting-started/installation/#1-review-docker-composeyml","title":"1. Review docker-compose.yml","text":"<pre><code>services:\n  postgres:\n    image: postgres:15\n    ports:\n      - \"5433:5432\"\n    volumes:\n      - kycc_pgdata:/var/lib/postgresql/data\n\n  backend:\n    build: ./backend\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n\n  dagster:\n    build: ./backend\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - postgres\n</code></pre>"},{"location":"getting-started/installation/#2-build-and-start","title":"2. Build and Start","text":"<pre><code># Build images\ndocker compose build\n\n# Start all services\ndocker compose up -d\n\n# View logs\ndocker compose logs -f\n\n# Stop services\ndocker compose down\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":""},{"location":"getting-started/installation/#check-all-services","title":"Check All Services","text":"<pre><code># Backend health\ncurl http://localhost:8000/health\n\n# Database connection\ncurl http://localhost:8000/api/stats\n\n# Dagster UI\ncurl http://localhost:3000\n</code></pre>"},{"location":"getting-started/installation/#run-test-suite","title":"Run Test Suite","text":"<pre><code>cd backend\npytest\n</code></pre> <p>All tests should pass before proceeding.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#python-package-conflicts","title":"Python Package Conflicts","text":"<pre><code>pip install --upgrade pip setuptools wheel\npip install -r requirements.txt --force-reinstall\n</code></pre>"},{"location":"getting-started/installation/#node-module-issues","title":"Node Module Issues","text":"<pre><code>rm -rf node_modules package-lock.json\nnpm install\n</code></pre>"},{"location":"getting-started/installation/#docker-network-issues","title":"Docker Network Issues","text":"<pre><code>docker network prune\ndocker compose down -v\ndocker compose up -d\n</code></pre>"},{"location":"getting-started/installation/#permission-errors-linux","title":"Permission Errors (Linux)","text":"<pre><code>sudo chown -R $USER:$USER .\nchmod +x scripts/*.sh\n</code></pre>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will get you up and running with KYCC in minutes.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Node.js 18+</li> <li>Docker and Docker Compose</li> <li>Git</li> </ul>"},{"location":"getting-started/quickstart/#option-1-using-docker-recommended","title":"Option 1: Using Docker (Recommended)","text":"<p>The fastest way to start KYCC is using Docker Compose, which starts all services automatically.</p>"},{"location":"getting-started/quickstart/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/kzauha/KYCC.git\ncd KYCC\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-configure-environment","title":"Step 2: Configure Environment","text":"<p>Create a <code>.env</code> file in the <code>backend/</code> directory:</p> <pre><code>cd backend\ncp .env.example .env\n</code></pre> <p>Default environment variables:</p> <pre><code>POSTGRES_USER=kycc_user\nPOSTGRES_PASSWORD=kycc_pass\nPOSTGRES_DB=kycc_db\nPOSTGRES_PORT=5433\nDATABASE_URL=postgresql://kycc_user:kycc_pass@localhost:5433/kycc_db\n</code></pre>"},{"location":"getting-started/quickstart/#step-3-start-services","title":"Step 3: Start Services","text":"<pre><code>cd ..\ndocker compose up -d\n</code></pre> <p>This starts:</p> <ul> <li>PostgreSQL on port 5433</li> <li>Backend API on port 8000</li> <li>Dagster UI on port 3000</li> </ul>"},{"location":"getting-started/quickstart/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<ul> <li>Backend API: http://localhost:8000/docs</li> <li>Dagster UI: http://localhost:3000</li> <li>Health Check: http://localhost:8000/health</li> </ul>"},{"location":"getting-started/quickstart/#option-2-using-powershell-script-windows","title":"Option 2: Using PowerShell Script (Windows)","text":"<p>For Windows users, the <code>run_all.ps1</code> script automates startup with port conflict detection.</p> <pre><code>.\\run_all.ps1\n</code></pre> <p>This script:</p> <ol> <li>Finds available ports for all services</li> <li>Starts the backend with uvicorn</li> <li>Starts the frontend with Vite</li> <li>Monitors logs from all services</li> </ol>"},{"location":"getting-started/quickstart/#option-3-manual-setup","title":"Option 3: Manual Setup","text":""},{"location":"getting-started/quickstart/#backend-setup","title":"Backend Setup","text":"<pre><code>cd backend\n\n# Create virtual environment\npython -m venv venv\n\n# Activate (Windows)\n.\\venv\\Scripts\\Activate.ps1\n\n# Activate (Linux/Mac)\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Run migrations\nalembic upgrade head\n\n# Start server\npython -m uvicorn main:app --port 8000 --reload\n</code></pre>"},{"location":"getting-started/quickstart/#frontend-setup","title":"Frontend Setup","text":"<pre><code>cd frontend\n\n# Install dependencies\nnpm install\n\n# Start development server\nnpm run dev\n</code></pre>"},{"location":"getting-started/quickstart/#first-steps-after-installation","title":"First Steps After Installation","text":""},{"location":"getting-started/quickstart/#1-check-system-health","title":"1. Check System Health","text":"<pre><code>curl http://localhost:8000/health\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"database\": \"connected\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"getting-started/quickstart/#2-view-api-documentation","title":"2. View API Documentation","text":"<p>Open http://localhost:8000/docs to see the interactive Swagger UI with all available endpoints.</p>"},{"location":"getting-started/quickstart/#3-run-the-pipeline","title":"3. Run the Pipeline","text":"<p>Create a batch of synthetic data and score it:</p> <pre><code># Using the API\ncurl -X POST \"http://localhost:8000/api/pipeline/run?batch_size=100\"\n</code></pre> <p>Or use the Dashboard at http://localhost:5173 and click \"Run Pipeline\".</p>"},{"location":"getting-started/quickstart/#4-view-scores","title":"4. View Scores","text":"<p>After the pipeline completes, view scores through:</p> <ul> <li>API: <code>GET /api/scoring/history/{party_id}</code></li> <li>Dashboard: Navigate to a party and view their credit score</li> </ul>"},{"location":"getting-started/quickstart/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/quickstart/#port-already-in-use","title":"Port Already in Use","text":"<p>If port 8000 or 5433 is already in use:</p> <pre><code># Find process using port\nnetstat -ano | findstr :8000\n\n# Kill process (Windows)\ntaskkill /PID &lt;PID&gt; /F\n</code></pre> <p>Or modify ports in <code>docker-compose.yml</code> and <code>.env</code>.</p>"},{"location":"getting-started/quickstart/#database-connection-failed","title":"Database Connection Failed","text":"<p>If the backend cannot connect to PostgreSQL:</p> <ol> <li>Ensure Docker containers are running: <code>docker compose ps</code></li> <li>Check PostgreSQL logs: <code>docker compose logs postgres</code></li> <li>Verify DATABASE_URL in <code>.env</code> matches docker-compose configuration</li> </ol> <p>The system will automatically fall back to SQLite if PostgreSQL is unavailable.</p>"},{"location":"getting-started/quickstart/#migration-errors","title":"Migration Errors","text":"<p>If Alembic migrations fail:</p> <pre><code>cd backend\n\n# Check current state\nalembic current\n\n# Force upgrade\nalembic upgrade head --sql\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide - Detailed installation instructions</li> <li>Configuration - Environment variables and settings</li> <li>Architecture Overview - Understand the system design</li> </ul>"},{"location":"ml/labels/","title":"Ground Truth Labels","text":"<p>Ground truth labels capture actual credit outcomes for machine learning training.</p>"},{"location":"ml/labels/#overview","title":"Overview","text":"Property Value Location <code>backend/app/services/label_generation_service.py</code> Table ground_truth_labels Label Types default, non-default Observation Window Configurable (default: 180 days)"},{"location":"ml/labels/#label-definition","title":"Label Definition","text":"<p>A ground truth label represents the actual credit outcome for a party:</p> Label Value Description default 1 Party defaulted on credit obligation non-default 0 Party fulfilled credit obligation"},{"location":"ml/labels/#label-generation-process","title":"Label Generation Process","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Label Generation Flow                             \u2502\n\u2502                                                                     \u2502\n\u2502   1. Select parties with credit history                             \u2502\n\u2502      \u2502                                                              \u2502\n\u2502      \u25bc                                                              \u2502\n\u2502   2. Determine observation date                                     \u2502\n\u2502      (score date + observation window)                              \u2502\n\u2502      \u2502                                                              \u2502\n\u2502      \u25bc                                                              \u2502\n\u2502   3. Check for default events                                       \u2502\n\u2502      - Payment delays &gt; 90 days                                     \u2502\n\u2502      - Account write-offs                                           \u2502\n\u2502      - Collection referrals                                         \u2502\n\u2502      \u2502                                                              \u2502\n\u2502      \u25bc                                                              \u2502\n\u2502   4. Assign label                                                   \u2502\n\u2502      default=1 if any default event                                 \u2502\n\u2502      default=0 otherwise                                            \u2502\n\u2502      \u2502                                                              \u2502\n\u2502      \u25bc                                                              \u2502\n\u2502   5. Store in ground_truth_labels table                             \u2502\n\u2502      with feature snapshot                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ml/labels/#labelgenerationservice","title":"LabelGenerationService","text":""},{"location":"ml/labels/#implementation","title":"Implementation","text":"<pre><code>class LabelGenerationService:\n    \"\"\"Generate ground truth labels for ML training.\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n        self.feature_pipeline = FeaturePipelineService(db)\n\n    def generate_labels(\n        self,\n        batch_id: str,\n        outcome_type: str = \"default\",\n        observation_window_days: int = 180\n    ) -&gt; dict:\n        \"\"\"\n        Generate labels for parties in a batch.\n\n        Args:\n            batch_id: Batch identifier\n            outcome_type: Type of outcome to label\n            observation_window_days: Days after score to observe outcome\n\n        Returns:\n            dict with label counts and statistics\n        \"\"\"\n        parties = self.db.query(Party).filter(\n            Party.batch_id == batch_id\n        ).all()\n\n        labels_created = 0\n        default_count = 0\n\n        for party in parties:\n            # Get score date\n            score_request = self.db.query(ScoreRequest).filter(\n                ScoreRequest.party_id == party.id\n            ).order_by(ScoreRequest.created_at.desc()).first()\n\n            if not score_request:\n                continue\n\n            # Calculate observation end date\n            observation_date = score_request.created_at + timedelta(\n                days=observation_window_days\n            )\n\n            # Check for default\n            is_default = self._check_default(party.id, observation_date)\n\n            # Extract features at score date\n            features = self.feature_pipeline.extract_all_features(\n                party.id,\n                as_of_date=score_request.created_at\n            )\n\n            # Create label\n            label = GroundTruthLabel(\n                party_id=party.id,\n                batch_id=batch_id,\n                label_type=outcome_type,\n                label_value=1 if is_default else 0,\n                observation_date=observation_date,\n                features_snapshot=self._flatten_features(features),\n                score_at_label=score_request.total_score\n            )\n\n            self.db.add(label)\n            labels_created += 1\n            if is_default:\n                default_count += 1\n\n        self.db.commit()\n\n        return {\n            \"batch_id\": batch_id,\n            \"labels_created\": labels_created,\n            \"default_count\": default_count,\n            \"non_default_count\": labels_created - default_count,\n            \"default_rate\": default_count / labels_created if labels_created &gt; 0 else 0\n        }\n</code></pre>"},{"location":"ml/labels/#default-detection","title":"Default Detection","text":""},{"location":"ml/labels/#criteria","title":"Criteria","text":"<pre><code>def _check_default(self, party_id: int, observation_date: datetime) -&gt; bool:\n    \"\"\"\n    Check if party defaulted before observation date.\n\n    Default criteria:\n    - Payment delay &gt; 90 days\n    - Account write-off\n    - Collection referral\n    \"\"\"\n    # Check for payment delays\n    late_payments = self.db.query(Transaction).filter(\n        Transaction.party_id == party_id,\n        Transaction.transaction_date &lt;= observation_date,\n        Transaction.days_past_due &gt; 90\n    ).count()\n\n    if late_payments &gt; 0:\n        return True\n\n    # Check for write-offs\n    writeoffs = self.db.query(CreditEvent).filter(\n        CreditEvent.party_id == party_id,\n        CreditEvent.event_type == 'writeoff',\n        CreditEvent.event_date &lt;= observation_date\n    ).count()\n\n    if writeoffs &gt; 0:\n        return True\n\n    return False\n</code></pre>"},{"location":"ml/labels/#synthetic-label-generation","title":"Synthetic Label Generation","text":"<p>For synthetic data without real outcomes:</p> <pre><code>def generate_synthetic_labels(\n    self,\n    batch_id: str,\n    default_rate: float = 0.15\n) -&gt; dict:\n    \"\"\"\n    Generate synthetic labels based on score.\n\n    Higher scores have lower default probability.\n    \"\"\"\n    parties = self.db.query(Party).filter(\n        Party.batch_id == batch_id\n    ).all()\n\n    for party in parties:\n        score_request = self.db.query(ScoreRequest).filter(\n            ScoreRequest.party_id == party.id\n        ).first()\n\n        if not score_request:\n            continue\n\n        # Default probability inversely related to score\n        # Score 300 -&gt; ~30% default, Score 900 -&gt; ~5% default\n        base_prob = 0.35 - (score_request.total_score - 300) / 600 * 0.30\n        adjusted_prob = base_prob * (default_rate / 0.15)  # Adjust to target rate\n\n        is_default = random.random() &lt; adjusted_prob\n\n        features = self.feature_pipeline.extract_all_features(party.id)\n\n        label = GroundTruthLabel(\n            party_id=party.id,\n            batch_id=batch_id,\n            label_type=\"synthetic_default\",\n            label_value=1 if is_default else 0,\n            features_snapshot=self._flatten_features(features),\n            score_at_label=score_request.total_score\n        )\n\n        self.db.add(label)\n\n    self.db.commit()\n</code></pre>"},{"location":"ml/labels/#feature-snapshot","title":"Feature Snapshot","text":"<p>Features are captured at label time to prevent data leakage:</p> <pre><code>def _flatten_features(self, feature_result: dict) -&gt; dict:\n    \"\"\"Flatten features for storage.\"\"\"\n    return {\n        f['feature_name']: f['feature_value']\n        for f in feature_result['features_list']\n    }\n</code></pre> <p>This ensures: - Training uses only features available at decision time - No future information leaks into training - Reproducible model training</p>"},{"location":"ml/labels/#label-schema","title":"Label Schema","text":"<pre><code>CREATE TABLE ground_truth_labels (\n    id SERIAL PRIMARY KEY,\n    party_id INTEGER REFERENCES parties(id),\n    batch_id VARCHAR(100),\n    label_type VARCHAR(50),\n    label_value INTEGER,\n    observation_date TIMESTAMP,\n    features_snapshot JSONB,\n    score_at_label INTEGER,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"ml/labels/#usage","title":"Usage","text":""},{"location":"ml/labels/#api-endpoint","title":"API Endpoint","text":"<pre><code>POST /api/pipeline/trigger/generate_labels\n</code></pre> <pre><code>{\n  \"batch_id\": \"BATCH_001\",\n  \"observation_window_days\": 180\n}\n</code></pre>"},{"location":"ml/labels/#direct-usage","title":"Direct Usage","text":"<pre><code>from app.services.label_generation_service import LabelGenerationService\n\nservice = LabelGenerationService(db)\n\nresult = service.generate_labels(\n    batch_id=\"BATCH_001\",\n    observation_window_days=180\n)\n\nprint(f\"Labels created: {result['labels_created']}\")\nprint(f\"Default rate: {result['default_rate']:.1%}\")\n</code></pre>"},{"location":"ml/labels/#label-quality-checks","title":"Label Quality Checks","text":""},{"location":"ml/labels/#balance-check","title":"Balance Check","text":"<pre><code>def check_label_balance(batch_id: str, db: Session) -&gt; dict:\n    \"\"\"Check if labels are reasonably balanced.\"\"\"\n    labels = db.query(GroundTruthLabel).filter(\n        GroundTruthLabel.batch_id == batch_id\n    ).all()\n\n    total = len(labels)\n    defaults = sum(1 for l in labels if l.label_value == 1)\n    default_rate = defaults / total if total &gt; 0 else 0\n\n    return {\n        \"total\": total,\n        \"defaults\": defaults,\n        \"non_defaults\": total - defaults,\n        \"default_rate\": default_rate,\n        \"is_balanced\": 0.05 &lt;= default_rate &lt;= 0.50\n    }\n</code></pre>"},{"location":"ml/labels/#minimum-sample-check","title":"Minimum Sample Check","text":"<pre><code>MIN_SAMPLES = 100\n\ndef check_sufficient_samples(batch_id: str, db: Session) -&gt; bool:\n    \"\"\"Check if batch has enough labeled samples.\"\"\"\n    count = db.query(GroundTruthLabel).filter(\n        GroundTruthLabel.batch_id == batch_id\n    ).count()\n\n    return count &gt;= MIN_SAMPLES\n</code></pre>"},{"location":"ml/labels/#best-practices","title":"Best Practices","text":"<ol> <li>Observation Window: Use consistent window (typically 180 days)</li> <li>Feature Snapshot: Always capture features at label time</li> <li>Balance: Target 10-30% default rate for best model performance</li> <li>Sample Size: Minimum 100 samples, prefer 500+</li> <li>Temporal Separation: Training data before validation data</li> </ol>"},{"location":"ml/pipeline/","title":"ML Pipeline Overview","text":"<p>The machine learning pipeline refines scorecard weights based on actual credit outcomes.</p>"},{"location":"ml/pipeline/#philosophy","title":"Philosophy","text":"<p>\"The Scorecard is King, AI is the Advisor\"</p> <ul> <li>The rule-based scorecard remains the primary decision engine</li> <li>ML provides data-driven weight optimization</li> <li>Human review required before deploying ML changes</li> <li>Full auditability maintained at all times</li> </ul>"},{"location":"ml/pipeline/#pipeline-architecture","title":"Pipeline Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        ML Pipeline Flow                             \u2502\n\u2502                                                                     \u2502\n\u2502   1. Ground Truth Collection                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Credit outcomes (default/non-default) collected            \u2502  \u2502\n\u2502   \u2502  Minimum 100+ labeled samples required                      \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   2. Feature Assembly                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Features extracted at outcome date                         \u2502  \u2502\n\u2502   \u2502  Training dataset: (features, outcome)                      \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   3. Model Training                                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Logistic Regression trained on labeled data                \u2502  \u2502\n\u2502   \u2502  Model coefficients extracted                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   4. Quality Gate                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  AUC-ROC &gt; 0.60 required                                    \u2502  \u2502\n\u2502   \u2502  Model must improve over baseline                           \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   5. Scorecard Refinement                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Model coefficients converted to scorecard weights          \u2502  \u2502\n\u2502   \u2502  New scorecard version created (not auto-deployed)          \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   6. Human Review                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Compare old vs new weights                                 \u2502  \u2502\n\u2502   \u2502  Activate new version after approval                        \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ml/pipeline/#key-components","title":"Key Components","text":""},{"location":"ml/pipeline/#services","title":"Services","text":"Service Location Purpose LabelGenerationService <code>services/label_generation_service.py</code> Generate ground truth labels ModelTrainingService <code>services/model_training_service.py</code> Train ML models ScorecardVersionService <code>services/scorecard_version_service.py</code> Manage scorecard versions"},{"location":"ml/pipeline/#models-database","title":"Models (Database)","text":"Table Purpose GroundTruthLabel Stores credit outcomes ModelRegistry Tracks trained models ScorecardVersion Stores scorecard configurations"},{"location":"ml/pipeline/#dagster-assets","title":"Dagster Assets","text":"Asset Purpose generate_scorecard_labels Generate labels for training train_model_asset Train and evaluate model refine_scorecard Create new scorecard version"},{"location":"ml/pipeline/#workflow","title":"Workflow","text":""},{"location":"ml/pipeline/#step-1-label-generation","title":"Step 1: Label Generation","text":"<p>Ground truth labels are generated from credit outcomes:</p> <pre><code>from app.services.label_generation_service import LabelGenerationService\n\nlabel_service = LabelGenerationService(db)\n\n# Generate labels for a batch\nresult = label_service.generate_labels(\n    batch_id=\"BATCH_001\",\n    outcome_type=\"default\",\n    observation_window_days=180\n)\n</code></pre>"},{"location":"ml/pipeline/#step-2-model-training","title":"Step 2: Model Training","text":"<p>Train logistic regression on labeled data:</p> <pre><code>from app.services.model_training_service import ModelTrainingService\n\ntraining_service = ModelTrainingService(db)\n\nresult = training_service.train_model(\n    batch_id=\"BATCH_001\",\n    model_type=\"logistic_regression\"\n)\n\n# Result includes:\n# - model_id\n# - metrics (auc_roc, accuracy, etc.)\n# - feature_importance\n</code></pre>"},{"location":"ml/pipeline/#step-3-quality-gate","title":"Step 3: Quality Gate","text":"<p>Model must pass quality threshold:</p> <pre><code>if result['metrics']['auc_roc'] &lt; 0.60:\n    raise QualityGateError(\"AUC-ROC below minimum threshold\")\n</code></pre>"},{"location":"ml/pipeline/#step-4-scorecard-refinement","title":"Step 4: Scorecard Refinement","text":"<p>Convert model to scorecard weights:</p> <pre><code>from app.services.scorecard_version_service import ScorecardVersionService\n\nversion_service = ScorecardVersionService(db)\n\nnew_version = version_service.refine_from_model(\n    model_id=result['model_id'],\n    base_version=\"v1\"\n)\n\n# Creates new version with status='draft'\n</code></pre>"},{"location":"ml/pipeline/#step-5-human-review-and-activation","title":"Step 5: Human Review and Activation","text":"<pre><code># Review weight changes\ncomparison = version_service.compare_versions(\"v1\", \"ml_v2\")\n\n# After approval, activate\nversion_service.activate_version(\"ml_v2\")\n</code></pre>"},{"location":"ml/pipeline/#quality-gates","title":"Quality Gates","text":""},{"location":"ml/pipeline/#model-quality","title":"Model Quality","text":"Metric Threshold Description AUC-ROC &gt;= 0.60 Minimum discrimination ability Sample Size &gt;= 100 Minimum labeled samples Default Rate 5-50% Ensure balanced dataset"},{"location":"ml/pipeline/#scorecard-quality","title":"Scorecard Quality","text":"Check Threshold Description Weight Change &lt; 50% No drastic weight changes Score Correlation &gt; 0.8 New scores correlate with old Band Stability &lt; 10% Band distribution change"},{"location":"ml/pipeline/#dagster-integration","title":"Dagster Integration","text":"<p>The ML pipeline runs as Dagster assets:</p> <pre><code>@asset\ndef generate_scorecard_labels(\n    context: OpExecutionContext,\n    score_batch: dict\n) -&gt; dict:\n    \"\"\"Generate labels for ML training.\"\"\"\n    # ...\n\n@asset\ndef train_model_asset(\n    context: OpExecutionContext,\n    generate_scorecard_labels: dict\n) -&gt; dict:\n    \"\"\"Train ML model on labeled data.\"\"\"\n    # ...\n\n@asset\ndef refine_scorecard(\n    context: OpExecutionContext,\n    train_model_asset: dict\n) -&gt; dict:\n    \"\"\"Refine scorecard from ML model.\"\"\"\n    # ...\n</code></pre>"},{"location":"ml/pipeline/#api-endpoints","title":"API Endpoints","text":""},{"location":"ml/pipeline/#trigger-ml-pipeline","title":"Trigger ML Pipeline","text":"<pre><code>POST /api/pipeline/trigger/ml_training_pipeline\n</code></pre> <pre><code>{\n  \"batch_id\": \"BATCH_001\"\n}\n</code></pre>"},{"location":"ml/pipeline/#get-model-status","title":"Get Model Status","text":"<pre><code>GET /api/pipeline/models/{model_id}\n</code></pre>"},{"location":"ml/pipeline/#list-scorecard-versions","title":"List Scorecard Versions","text":"<pre><code>GET /api/scoring/versions\n</code></pre>"},{"location":"ml/pipeline/#activate-scorecard-version","title":"Activate Scorecard Version","text":"<pre><code>POST /api/scoring/versions/{version}/activate\n</code></pre>"},{"location":"ml/pipeline/#monitoring","title":"Monitoring","text":""},{"location":"ml/pipeline/#model-performance-tracking","title":"Model Performance Tracking","text":"<pre><code># Get model performance over time\nmetrics = db.query(ModelRegistry).filter(\n    ModelRegistry.model_type == 'logistic_regression'\n).order_by(ModelRegistry.created_at.desc()).all()\n\nfor model in metrics:\n    print(f\"Model {model.id}: AUC={model.metrics['auc_roc']:.3f}\")\n</code></pre>"},{"location":"ml/pipeline/#version-comparison","title":"Version Comparison","text":"<pre><code># Compare scorecard versions\nold = version_service.get_version(\"v1\")\nnew = version_service.get_version(\"ml_v2\")\n\nfor feature in old['features']:\n    old_weight = old['features'][feature]['weight']\n    new_weight = new['features'][feature]['weight']\n    change = ((new_weight - old_weight) / old_weight) * 100\n    print(f\"{feature}: {old_weight} -&gt; {new_weight} ({change:+.1f}%)\")\n</code></pre>"},{"location":"ml/pipeline/#best-practices","title":"Best Practices","text":"<ol> <li>Minimum Sample Size: Wait for 100+ labeled outcomes before training</li> <li>Regular Retraining: Retrain monthly or when performance degrades</li> <li>Version Control: Never overwrite active scorecard directly</li> <li>Human Review: Always review ML recommendations before deployment</li> <li>Rollback Plan: Keep previous version ready for quick rollback</li> <li>Monitoring: Track score distribution changes after new version</li> </ol>"},{"location":"ml/refinement/","title":"Scorecard Refinement","text":"<p>Scorecard refinement converts ML model coefficients into updated scorecard weights.</p>"},{"location":"ml/refinement/#overview","title":"Overview","text":"Property Value Location <code>backend/app/services/scorecard_version_service.py</code> Input Trained model coefficients Output New scorecard version (draft) Deployment Manual activation required"},{"location":"ml/refinement/#refinement-process","title":"Refinement Process","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Scorecard Refinement                             \u2502\n\u2502                                                                     \u2502\n\u2502   1. Load Model Coefficients                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  kyc_verified: -1.23                                        \u2502  \u2502\n\u2502   \u2502  company_age_years: -0.45                                   \u2502  \u2502\n\u2502   \u2502  transaction_regularity_score: -0.89                        \u2502  \u2502\n\u2502   \u2502  ...                                                        \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   2. Convert to Positive Weights                                    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  ML predicts default (1 = bad)                              \u2502  \u2502\n\u2502   \u2502  Scorecard wants credit score (higher = better)             \u2502  \u2502\n\u2502   \u2502  So: weight = -coefficient (flip sign)                      \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   3. Normalize Weights                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Scale to sum to 100 (or match base scorecard)              \u2502  \u2502\n\u2502   \u2502  Preserve relative importance                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   4. Blend with Base Weights (optional)                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  new_weight = (1-alpha)*base + alpha*ml                     \u2502  \u2502\n\u2502   \u2502  alpha = 0.3 (conservative) to 0.7 (aggressive)             \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   5. Create Draft Version                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Store as new scorecard version                             \u2502  \u2502\n\u2502   \u2502  Status: draft (not active)                                 \u2502  \u2502\n\u2502   \u2502  Requires manual activation                                 \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ml/refinement/#scorecardversionservice","title":"ScorecardVersionService","text":""},{"location":"ml/refinement/#implementation","title":"Implementation","text":"<pre><code>class ScorecardVersionService:\n    \"\"\"Manage scorecard versions and refinement.\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def refine_from_model(\n        self,\n        model_id: str,\n        base_version: str = \"v1\",\n        blend_factor: float = 0.5\n    ) -&gt; dict:\n        \"\"\"\n        Create new scorecard version from ML model.\n\n        Args:\n            model_id: Trained model ID\n            base_version: Base scorecard to refine\n            blend_factor: Weight for ML vs base (0-1)\n\n        Returns:\n            New scorecard version info\n        \"\"\"\n        # Load model\n        model_registry = self.db.query(ModelRegistry).filter(\n            ModelRegistry.model_id == model_id\n        ).first()\n\n        if not model_registry:\n            raise ValueError(f\"Model {model_id} not found\")\n\n        coefficients = model_registry.feature_importance\n\n        # Load base scorecard\n        base_config = self.get_version(base_version)\n\n        # Convert coefficients to weights\n        ml_weights = self._coefficients_to_weights(coefficients)\n\n        # Blend with base weights\n        blended_weights = self._blend_weights(\n            base_config['features'],\n            ml_weights,\n            blend_factor\n        )\n\n        # Create new version\n        new_version = self._create_version(\n            blended_weights,\n            base_version,\n            model_id\n        )\n\n        return new_version\n</code></pre>"},{"location":"ml/refinement/#coefficient-conversion","title":"Coefficient Conversion","text":"<pre><code>def _coefficients_to_weights(self, coefficients: dict) -&gt; dict:\n    \"\"\"\n    Convert ML coefficients to scorecard weights.\n\n    ML coefficients are for predicting default (bad).\n    Scorecard weights should reward good behavior.\n    \"\"\"\n    weights = {}\n\n    for feature, coef in coefficients.items():\n        # Flip sign: negative coef = reduces default = higher score\n        raw_weight = -coef\n\n        # Ensure non-negative (clip at 0)\n        weights[feature] = max(0, raw_weight)\n\n    # Normalize to sum to 100\n    total = sum(weights.values())\n    if total &gt; 0:\n        weights = {k: (v / total) * 100 for k, v in weights.items()}\n\n    return weights\n</code></pre>"},{"location":"ml/refinement/#weight-blending","title":"Weight Blending","text":"<pre><code>def _blend_weights(\n    self,\n    base_features: dict,\n    ml_weights: dict,\n    blend_factor: float\n) -&gt; dict:\n    \"\"\"\n    Blend base and ML weights.\n\n    blend_factor = 0: Use only base weights\n    blend_factor = 1: Use only ML weights\n    blend_factor = 0.5: Equal blend\n    \"\"\"\n    blended = {}\n\n    for feature, base_config in base_features.items():\n        base_weight = base_config['weight']\n        ml_weight = ml_weights.get(feature, base_weight)\n\n        blended_weight = (1 - blend_factor) * base_weight + blend_factor * ml_weight\n\n        blended[feature] = {\n            'weight': blended_weight,\n            'multiplier': base_config.get('multiplier', 1.0),\n            'max_value': base_config.get('max_value', float('inf'))\n        }\n\n    return blended\n</code></pre>"},{"location":"ml/refinement/#version-creation","title":"Version Creation","text":"<pre><code>def _create_version(\n    self,\n    features: dict,\n    base_version: str,\n    model_id: str\n) -&gt; dict:\n    \"\"\"Create new scorecard version in database.\"\"\"\n    # Generate version ID\n    version_id = f\"ml_v{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n\n    # Create version record\n    version = ScorecardVersion(\n        version_id=version_id,\n        base_version=base_version,\n        model_id=model_id,\n        features=features,\n        status='draft',\n        created_at=datetime.utcnow()\n    )\n\n    self.db.add(version)\n    self.db.commit()\n\n    return {\n        'version_id': version_id,\n        'base_version': base_version,\n        'model_id': model_id,\n        'status': 'draft',\n        'features': features\n    }\n</code></pre>"},{"location":"ml/refinement/#version-comparison","title":"Version Comparison","text":"<pre><code>def compare_versions(self, version_a: str, version_b: str) -&gt; dict:\n    \"\"\"Compare two scorecard versions.\"\"\"\n    a = self.get_version(version_a)\n    b = self.get_version(version_b)\n\n    comparison = []\n\n    for feature in a['features'].keys():\n        weight_a = a['features'][feature]['weight']\n        weight_b = b['features'].get(feature, {}).get('weight', 0)\n\n        change = weight_b - weight_a\n        pct_change = (change / weight_a * 100) if weight_a &gt; 0 else 0\n\n        comparison.append({\n            'feature': feature,\n            'weight_a': weight_a,\n            'weight_b': weight_b,\n            'change': change,\n            'pct_change': pct_change\n        })\n\n    return {\n        'version_a': version_a,\n        'version_b': version_b,\n        'features': comparison,\n        'total_weight_change': sum(abs(c['change']) for c in comparison)\n    }\n</code></pre>"},{"location":"ml/refinement/#version-activation","title":"Version Activation","text":"<pre><code>def activate_version(self, version_id: str) -&gt; dict:\n    \"\"\"\n    Activate a scorecard version.\n\n    Deactivates all other versions.\n    \"\"\"\n    # Deactivate all versions\n    self.db.query(ScorecardVersion).update({'status': 'inactive'})\n\n    # Activate specified version\n    version = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.version_id == version_id\n    ).first()\n\n    if not version:\n        raise ValueError(f\"Version {version_id} not found\")\n\n    version.status = 'active'\n    version.activated_at = datetime.utcnow()\n\n    self.db.commit()\n\n    return {\n        'version_id': version_id,\n        'status': 'active',\n        'activated_at': version.activated_at.isoformat()\n    }\n</code></pre>"},{"location":"ml/refinement/#usage","title":"Usage","text":""},{"location":"ml/refinement/#api-endpoints","title":"API Endpoints","text":"<p>Refine scorecard: <pre><code>POST /api/scoring/refine\n</code></pre></p> <pre><code>{\n  \"model_id\": \"model_BATCH_001_20240115_103045\",\n  \"base_version\": \"v1\",\n  \"blend_factor\": 0.5\n}\n</code></pre> <p>Compare versions: <pre><code>GET /api/scoring/versions/compare?a=v1&amp;b=ml_v20240115\n</code></pre></p> <p>Activate version: <pre><code>POST /api/scoring/versions/{version_id}/activate\n</code></pre></p>"},{"location":"ml/refinement/#direct-usage","title":"Direct Usage","text":"<pre><code>from app.services.scorecard_version_service import ScorecardVersionService\n\nservice = ScorecardVersionService(db)\n\n# Create refined version\nresult = service.refine_from_model(\n    model_id=\"model_BATCH_001\",\n    base_version=\"v1\",\n    blend_factor=0.5\n)\n\nprint(f\"Created version: {result['version_id']}\")\n\n# Compare versions\ncomparison = service.compare_versions(\"v1\", result['version_id'])\n\nfor feat in comparison['features']:\n    print(f\"{feat['feature']}: {feat['weight_a']:.2f} -&gt; {feat['weight_b']:.2f} ({feat['pct_change']:+.1f}%)\")\n\n# After review, activate\nservice.activate_version(result['version_id'])\n</code></pre>"},{"location":"ml/refinement/#validation-checks","title":"Validation Checks","text":"<p>Before activating a new version:</p> <pre><code>def validate_version(self, version_id: str) -&gt; dict:\n    \"\"\"Validate scorecard version before activation.\"\"\"\n    version = self.get_version(version_id)\n\n    issues = []\n\n    # Check weight sum\n    total_weight = sum(f['weight'] for f in version['features'].values())\n    if not (95 &lt;= total_weight &lt;= 105):\n        issues.append(f\"Total weight {total_weight:.1f} not near 100\")\n\n    # Check for zero weights\n    zero_weights = [f for f, c in version['features'].items() if c['weight'] == 0]\n    if zero_weights:\n        issues.append(f\"Zero weights: {zero_weights}\")\n\n    # Compare to base\n    comparison = self.compare_versions(version['base_version'], version_id)\n    large_changes = [\n        c for c in comparison['features']\n        if abs(c['pct_change']) &gt; 50\n    ]\n    if large_changes:\n        issues.append(f\"Large changes (&gt;50%): {[c['feature'] for c in large_changes]}\")\n\n    return {\n        'valid': len(issues) == 0,\n        'issues': issues\n    }\n</code></pre>"},{"location":"ml/refinement/#best-practices","title":"Best Practices","text":"<ol> <li>Conservative Blending: Start with blend_factor=0.3</li> <li>Validation: Always validate before activating</li> <li>Comparison: Review weight changes carefully</li> <li>Rollback: Keep previous version available</li> <li>Monitoring: Track score distribution after activation</li> <li>Documentation: Record reason for version changes</li> </ol>"},{"location":"ml/training/","title":"Model Training","text":"<p>The model training service trains machine learning models on labeled credit data.</p>"},{"location":"ml/training/#overview","title":"Overview","text":"Property Value Location <code>backend/app/services/model_training_service.py</code> Algorithm Logistic Regression Library scikit-learn Serialization joblib"},{"location":"ml/training/#model-architecture","title":"Model Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Model Training Pipeline                          \u2502\n\u2502                                                                     \u2502\n\u2502   Input: Labeled Data                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Features (X)          Labels (y)                           \u2502  \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502  \u2502\n\u2502   \u2502  \u2502 kyc_verified    \u2502   \u2502 0       \u2502                         \u2502  \u2502\n\u2502   \u2502  \u2502 company_age     \u2502   \u2502 1       \u2502                         \u2502  \u2502\n\u2502   \u2502  \u2502 txn_count       \u2502   \u2502 0       \u2502                         \u2502  \u2502\n\u2502   \u2502  \u2502 ...             \u2502   \u2502 ...     \u2502                         \u2502  \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   Preprocessing                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  - Handle missing values (fill with 0)                      \u2502  \u2502\n\u2502   \u2502  - Standardize features (StandardScaler)                    \u2502  \u2502\n\u2502   \u2502  - Train/test split (80/20)                                 \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   Training                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  LogisticRegression(                                        \u2502  \u2502\n\u2502   \u2502    penalty='l2',                                            \u2502  \u2502\n\u2502   \u2502    C=1.0,                                                   \u2502  \u2502\n\u2502   \u2502    max_iter=1000                                            \u2502  \u2502\n\u2502   \u2502  )                                                          \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   Evaluation                                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  - AUC-ROC                                                  \u2502  \u2502\n\u2502   \u2502  - Accuracy                                                 \u2502  \u2502\n\u2502   \u2502  - Precision/Recall                                         \u2502  \u2502\n\u2502   \u2502  - Feature importance (coefficients)                        \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   Output: Model + Metrics                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  - Serialized model (joblib)                                \u2502  \u2502\n\u2502   \u2502  - Performance metrics                                      \u2502  \u2502\n\u2502   \u2502  - Feature coefficients                                     \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ml/training/#modeltrainingservice","title":"ModelTrainingService","text":""},{"location":"ml/training/#implementation","title":"Implementation","text":"<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, accuracy_score, classification_report\nimport joblib\nimport numpy as np\n\nclass ModelTrainingService:\n    \"\"\"Train ML models for credit scoring.\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n        self.feature_columns = [\n            'kyc_verified',\n            'company_age_years',\n            'party_type_score',\n            'contact_completeness',\n            'has_tax_id',\n            'transaction_count_6m',\n            'avg_transaction_amount',\n            'total_transaction_volume_6m',\n            'transaction_regularity_score',\n            'recent_activity_flag',\n            'direct_counterparty_count',\n            'network_depth_downstream',\n            'network_size',\n            'supplier_count',\n            'customer_count',\n            'network_balance_ratio'\n        ]\n\n    def train_model(\n        self,\n        batch_id: str,\n        model_type: str = \"logistic_regression\",\n        test_size: float = 0.2\n    ) -&gt; dict:\n        \"\"\"\n        Train model on labeled data.\n\n        Args:\n            batch_id: Batch with ground truth labels\n            model_type: Type of model to train\n            test_size: Fraction for test set\n\n        Returns:\n            dict with model_id, metrics, feature_importance\n        \"\"\"\n        # Load labeled data\n        labels = self.db.query(GroundTruthLabel).filter(\n            GroundTruthLabel.batch_id == batch_id\n        ).all()\n\n        if len(labels) &lt; 100:\n            raise ValueError(f\"Insufficient samples: {len(labels)} &lt; 100\")\n\n        # Prepare features and labels\n        X, y = self._prepare_data(labels)\n\n        # Split data\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=test_size, random_state=42, stratify=y\n        )\n\n        # Standardize features\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n\n        # Train model\n        model = LogisticRegression(\n            penalty='l2',\n            C=1.0,\n            max_iter=1000,\n            random_state=42\n        )\n        model.fit(X_train_scaled, y_train)\n\n        # Evaluate\n        y_pred = model.predict(X_test_scaled)\n        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n\n        metrics = {\n            'auc_roc': roc_auc_score(y_test, y_prob),\n            'accuracy': accuracy_score(y_test, y_pred),\n            'samples_train': len(X_train),\n            'samples_test': len(X_test),\n            'default_rate_train': y_train.mean(),\n            'default_rate_test': y_test.mean()\n        }\n\n        # Quality gate\n        if metrics['auc_roc'] &lt; 0.60:\n            raise QualityGateError(\n                f\"AUC-ROC {metrics['auc_roc']:.3f} below threshold 0.60\"\n            )\n\n        # Extract feature importance\n        feature_importance = dict(zip(\n            self.feature_columns,\n            model.coef_[0].tolist()\n        ))\n\n        # Save model\n        model_id = self._save_model(\n            model, scaler, batch_id, metrics, feature_importance\n        )\n\n        return {\n            'model_id': model_id,\n            'metrics': metrics,\n            'feature_importance': feature_importance\n        }\n</code></pre>"},{"location":"ml/training/#data-preparation","title":"Data Preparation","text":"<pre><code>def _prepare_data(self, labels: list) -&gt; tuple:\n    \"\"\"Prepare feature matrix and label vector.\"\"\"\n    X = []\n    y = []\n\n    for label in labels:\n        features = label.features_snapshot\n\n        # Extract features in consistent order\n        row = []\n        for col in self.feature_columns:\n            value = features.get(col, 0.0)\n            row.append(float(value) if value is not None else 0.0)\n\n        X.append(row)\n        y.append(label.label_value)\n\n    return np.array(X), np.array(y)\n</code></pre>"},{"location":"ml/training/#model-persistence","title":"Model Persistence","text":""},{"location":"ml/training/#saving-models","title":"Saving Models","text":"<pre><code>def _save_model(\n    self,\n    model,\n    scaler,\n    batch_id: str,\n    metrics: dict,\n    feature_importance: dict\n) -&gt; str:\n    \"\"\"Save model to database and filesystem.\"\"\"\n    model_id = f\"model_{batch_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n\n    # Save to filesystem\n    model_path = f\"models/{model_id}.joblib\"\n    os.makedirs(\"models\", exist_ok=True)\n    joblib.dump({\n        'model': model,\n        'scaler': scaler,\n        'feature_columns': self.feature_columns\n    }, model_path)\n\n    # Save to database\n    registry_entry = ModelRegistry(\n        model_id=model_id,\n        batch_id=batch_id,\n        model_type='logistic_regression',\n        model_path=model_path,\n        metrics=metrics,\n        feature_importance=feature_importance,\n        status='trained'\n    )\n    self.db.add(registry_entry)\n    self.db.commit()\n\n    return model_id\n</code></pre>"},{"location":"ml/training/#loading-models","title":"Loading Models","text":"<pre><code>def load_model(self, model_id: str) -&gt; dict:\n    \"\"\"Load model from filesystem.\"\"\"\n    registry = self.db.query(ModelRegistry).filter(\n        ModelRegistry.model_id == model_id\n    ).first()\n\n    if not registry:\n        raise ValueError(f\"Model {model_id} not found\")\n\n    model_data = joblib.load(registry.model_path)\n\n    return {\n        'model': model_data['model'],\n        'scaler': model_data['scaler'],\n        'feature_columns': model_data['feature_columns'],\n        'metrics': registry.metrics,\n        'feature_importance': registry.feature_importance\n    }\n</code></pre>"},{"location":"ml/training/#feature-importance","title":"Feature Importance","text":"<p>Model coefficients indicate feature importance:</p> <pre><code>def get_feature_importance(model_id: str) -&gt; dict:\n    \"\"\"Get sorted feature importance.\"\"\"\n    registry = db.query(ModelRegistry).filter(\n        ModelRegistry.model_id == model_id\n    ).first()\n\n    importance = registry.feature_importance\n\n    # Sort by absolute value\n    sorted_features = sorted(\n        importance.items(),\n        key=lambda x: abs(x[1]),\n        reverse=True\n    )\n\n    return {\n        'features': [f[0] for f in sorted_features],\n        'coefficients': [f[1] for f in sorted_features],\n        'interpretation': [\n            'increases default risk' if f[1] &gt; 0 else 'decreases default risk'\n            for f in sorted_features\n        ]\n    }\n</code></pre> <p>Example output:</p> <pre><code>{\n  \"features\": [\"kyc_verified\", \"transaction_regularity_score\", \"recent_activity_flag\"],\n  \"coefficients\": [-1.23, -0.89, -0.76],\n  \"interpretation\": [\"decreases default risk\", \"decreases default risk\", \"decreases default risk\"]\n}\n</code></pre>"},{"location":"ml/training/#metrics","title":"Metrics","text":""},{"location":"ml/training/#auc-roc","title":"AUC-ROC","text":"<p>Area Under the Receiver Operating Characteristic curve:</p> <ul> <li>0.5: Random guessing</li> <li>0.6: Minimum acceptable</li> <li>0.7: Good discrimination</li> <li>0.8+: Excellent discrimination</li> </ul>"},{"location":"ml/training/#classification-report","title":"Classification Report","text":"<pre><code>from sklearn.metrics import classification_report\n\nreport = classification_report(y_test, y_pred, target_names=['non-default', 'default'])\nprint(report)\n</code></pre> <p>Output: <pre><code>              precision    recall  f1-score   support\n\n non-default       0.89      0.94      0.91       170\n     default       0.72      0.58      0.64        30\n\n    accuracy                           0.87       200\n   macro avg       0.80      0.76      0.78       200\nweighted avg       0.86      0.87      0.86       200\n</code></pre></p>"},{"location":"ml/training/#usage","title":"Usage","text":""},{"location":"ml/training/#api-endpoint","title":"API Endpoint","text":"<pre><code>POST /api/pipeline/trigger/train_model\n</code></pre> <pre><code>{\n  \"batch_id\": \"BATCH_001\"\n}\n</code></pre>"},{"location":"ml/training/#direct-usage","title":"Direct Usage","text":"<pre><code>from app.services.model_training_service import ModelTrainingService\n\nservice = ModelTrainingService(db)\n\nresult = service.train_model(batch_id=\"BATCH_001\")\n\nprint(f\"Model ID: {result['model_id']}\")\nprint(f\"AUC-ROC: {result['metrics']['auc_roc']:.3f}\")\nprint(f\"Top features: {list(result['feature_importance'].keys())[:3]}\")\n</code></pre>"},{"location":"ml/training/#model-registry-schema","title":"Model Registry Schema","text":"<pre><code>CREATE TABLE model_registry (\n    id SERIAL PRIMARY KEY,\n    model_id VARCHAR(100) UNIQUE,\n    batch_id VARCHAR(100),\n    model_type VARCHAR(50),\n    model_path VARCHAR(255),\n    metrics JSONB,\n    feature_importance JSONB,\n    status VARCHAR(20),\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"ml/training/#best-practices","title":"Best Practices","text":"<ol> <li>Minimum Samples: Require 100+ labeled samples</li> <li>Stratified Split: Maintain class balance in train/test</li> <li>Feature Scaling: Always standardize features</li> <li>Quality Gate: Enforce minimum AUC-ROC</li> <li>Versioning: Track all trained models</li> <li>Reproducibility: Set random seeds</li> </ol>"},{"location":"ml/versioning/","title":"Scorecard Versioning","text":"<p>The versioning system maintains multiple scorecard configurations with full audit trail.</p>"},{"location":"ml/versioning/#overview","title":"Overview","text":"Property Value Location <code>backend/app/services/scorecard_version_service.py</code> Table scorecard_versions Initial Version v1 Status States draft, active, inactive"},{"location":"ml/versioning/#version-lifecycle","title":"Version Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Version Lifecycle                               \u2502\n\u2502                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502   DRAFT    \u2502\u2500\u2500\u2500&gt;\u2502   ACTIVE   \u2502\u2500\u2500\u2500&gt;\u2502  INACTIVE  \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502         \u2502                 \u2502                  \u2502                      \u2502\n\u2502         \u2502                 \u2502                  \u2502                      \u2502\n\u2502   Created by:       Activated by:      Replaced by:                 \u2502\n\u2502   - ML refinement   - Manual approval  - New version                \u2502\n\u2502   - Manual create   - API call         - Rollback                   \u2502\n\u2502                                                                     \u2502\n\u2502   Can be:           Only ONE active    Can be:                      \u2502\n\u2502   - Edited          at a time          - Reactivated               \u2502\n\u2502   - Deleted                            - Archived                   \u2502\n\u2502   - Activated                                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ml/versioning/#version-schema","title":"Version Schema","text":"<pre><code>CREATE TABLE scorecard_versions (\n    id SERIAL PRIMARY KEY,\n    version_id VARCHAR(50) UNIQUE NOT NULL,\n    base_version VARCHAR(50),\n    model_id VARCHAR(100),\n    features JSONB NOT NULL,\n    status VARCHAR(20) DEFAULT 'draft',\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    activated_at TIMESTAMP,\n    deactivated_at TIMESTAMP,\n    created_by VARCHAR(100),\n    notes TEXT\n);\n</code></pre>"},{"location":"ml/versioning/#version-model","title":"Version Model","text":"<pre><code>class ScorecardVersion(Base):\n    __tablename__ = \"scorecard_versions\"\n\n    id = Column(Integer, primary_key=True)\n    version_id = Column(String(50), unique=True, nullable=False)\n    base_version = Column(String(50))\n    model_id = Column(String(100))\n    features = Column(JSON, nullable=False)\n    status = Column(String(20), default='draft')\n    created_at = Column(DateTime, default=datetime.utcnow)\n    activated_at = Column(DateTime)\n    deactivated_at = Column(DateTime)\n    created_by = Column(String(100))\n    notes = Column(Text)\n</code></pre>"},{"location":"ml/versioning/#initial-version","title":"Initial Version","text":"<p>The initial scorecard configuration (v1):</p> <pre><code>INITIAL_SCORECARD_V1 = {\n    \"version_id\": \"v1\",\n    \"features\": {\n        \"kyc_verified\": {\n            \"weight\": 15,\n            \"multiplier\": 1.0,\n            \"max_value\": 1\n        },\n        \"company_age_years\": {\n            \"weight\": 10,\n            \"multiplier\": 2.0,\n            \"max_value\": 10\n        },\n        \"party_type_score\": {\n            \"weight\": 5,\n            \"multiplier\": 1.0,\n            \"max_value\": 10\n        },\n        \"contact_completeness\": {\n            \"weight\": 5,\n            \"multiplier\": 0.1,\n            \"max_value\": 100\n        },\n        \"has_tax_id\": {\n            \"weight\": 10,\n            \"multiplier\": 1.0,\n            \"max_value\": 1\n        },\n        \"transaction_count_6m\": {\n            \"weight\": 10,\n            \"multiplier\": 0.5,\n            \"max_value\": 100\n        },\n        \"avg_transaction_amount\": {\n            \"weight\": 5,\n            \"multiplier\": 0.001,\n            \"max_value\": 50000\n        },\n        \"total_transaction_volume_6m\": {\n            \"weight\": 5,\n            \"multiplier\": 0.00001,\n            \"max_value\": 1000000\n        },\n        \"transaction_regularity_score\": {\n            \"weight\": 10,\n            \"multiplier\": 0.1,\n            \"max_value\": 100\n        },\n        \"recent_activity_flag\": {\n            \"weight\": 15,\n            \"multiplier\": 1.0,\n            \"max_value\": 1\n        },\n        \"direct_counterparty_count\": {\n            \"weight\": 5,\n            \"multiplier\": 0.5,\n            \"max_value\": 20\n        },\n        \"network_size\": {\n            \"weight\": 5,\n            \"multiplier\": 0.2,\n            \"max_value\": 50\n        }\n    },\n    \"status\": \"active\"\n}\n</code></pre>"},{"location":"ml/versioning/#version-operations","title":"Version Operations","text":""},{"location":"ml/versioning/#create-version","title":"Create Version","text":"<pre><code>def create_version(\n    self,\n    version_id: str,\n    features: dict,\n    base_version: str = None,\n    notes: str = None\n) -&gt; dict:\n    \"\"\"Create a new scorecard version.\"\"\"\n    # Check version doesn't exist\n    existing = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.version_id == version_id\n    ).first()\n\n    if existing:\n        raise ValueError(f\"Version {version_id} already exists\")\n\n    version = ScorecardVersion(\n        version_id=version_id,\n        base_version=base_version,\n        features=features,\n        status='draft',\n        notes=notes\n    )\n\n    self.db.add(version)\n    self.db.commit()\n\n    return self._version_to_dict(version)\n</code></pre>"},{"location":"ml/versioning/#get-version","title":"Get Version","text":"<pre><code>def get_version(self, version_id: str) -&gt; dict:\n    \"\"\"Get scorecard version by ID.\"\"\"\n    version = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.version_id == version_id\n    ).first()\n\n    if not version:\n        # Return default v1 if not in database\n        return INITIAL_SCORECARD_V1\n\n    return self._version_to_dict(version)\n</code></pre>"},{"location":"ml/versioning/#get-active-version","title":"Get Active Version","text":"<pre><code>def get_active_version(self) -&gt; dict:\n    \"\"\"Get currently active scorecard version.\"\"\"\n    version = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.status == 'active'\n    ).first()\n\n    if not version:\n        return INITIAL_SCORECARD_V1\n\n    return self._version_to_dict(version)\n</code></pre>"},{"location":"ml/versioning/#list-versions","title":"List Versions","text":"<pre><code>def list_versions(self, include_inactive: bool = False) -&gt; list:\n    \"\"\"List all scorecard versions.\"\"\"\n    query = self.db.query(ScorecardVersion)\n\n    if not include_inactive:\n        query = query.filter(ScorecardVersion.status != 'inactive')\n\n    versions = query.order_by(ScorecardVersion.created_at.desc()).all()\n\n    return [self._version_to_dict(v) for v in versions]\n</code></pre>"},{"location":"ml/versioning/#activate-version","title":"Activate Version","text":"<pre><code>def activate_version(self, version_id: str) -&gt; dict:\n    \"\"\"Activate a scorecard version.\"\"\"\n    # Get version\n    version = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.version_id == version_id\n    ).first()\n\n    if not version:\n        raise ValueError(f\"Version {version_id} not found\")\n\n    if version.status == 'active':\n        return self._version_to_dict(version)\n\n    # Deactivate current active version\n    current_active = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.status == 'active'\n    ).first()\n\n    if current_active:\n        current_active.status = 'inactive'\n        current_active.deactivated_at = datetime.utcnow()\n\n    # Activate new version\n    version.status = 'active'\n    version.activated_at = datetime.utcnow()\n\n    self.db.commit()\n\n    return self._version_to_dict(version)\n</code></pre>"},{"location":"ml/versioning/#rollback-version","title":"Rollback Version","text":"<pre><code>def rollback_to_version(self, version_id: str) -&gt; dict:\n    \"\"\"Rollback to a previous version.\"\"\"\n    # Verify version exists and is inactive\n    version = self.db.query(ScorecardVersion).filter(\n        ScorecardVersion.version_id == version_id,\n        ScorecardVersion.status == 'inactive'\n    ).first()\n\n    if not version:\n        raise ValueError(f\"Inactive version {version_id} not found\")\n\n    return self.activate_version(version_id)\n</code></pre>"},{"location":"ml/versioning/#version-comparison","title":"Version Comparison","text":"<pre><code>def compare_versions(self, version_a: str, version_b: str) -&gt; dict:\n    \"\"\"Compare two scorecard versions.\"\"\"\n    a = self.get_version(version_a)\n    b = self.get_version(version_b)\n\n    features_a = a['features']\n    features_b = b['features']\n\n    comparison = []\n    all_features = set(features_a.keys()) | set(features_b.keys())\n\n    for feature in all_features:\n        config_a = features_a.get(feature, {})\n        config_b = features_b.get(feature, {})\n\n        weight_a = config_a.get('weight', 0)\n        weight_b = config_b.get('weight', 0)\n\n        comparison.append({\n            'feature': feature,\n            'version_a': {\n                'weight': weight_a,\n                'multiplier': config_a.get('multiplier', 0),\n                'max_value': config_a.get('max_value', 0)\n            },\n            'version_b': {\n                'weight': weight_b,\n                'multiplier': config_b.get('multiplier', 0),\n                'max_value': config_b.get('max_value', 0)\n            },\n            'weight_change': weight_b - weight_a,\n            'pct_change': ((weight_b - weight_a) / weight_a * 100) if weight_a &gt; 0 else 0\n        })\n\n    return {\n        'version_a': version_a,\n        'version_b': version_b,\n        'comparison': sorted(comparison, key=lambda x: abs(x['pct_change']), reverse=True)\n    }\n</code></pre>"},{"location":"ml/versioning/#api-endpoints","title":"API Endpoints","text":""},{"location":"ml/versioning/#list-versions_1","title":"List Versions","text":"<pre><code>GET /api/scoring/versions\n</code></pre> <p>Response: <pre><code>{\n  \"versions\": [\n    {\n      \"version_id\": \"ml_v20240115\",\n      \"status\": \"active\",\n      \"created_at\": \"2024-01-15T10:30:45\",\n      \"activated_at\": \"2024-01-15T14:00:00\"\n    },\n    {\n      \"version_id\": \"v1\",\n      \"status\": \"inactive\",\n      \"created_at\": \"2024-01-01T00:00:00\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"ml/versioning/#get-version-details","title":"Get Version Details","text":"<pre><code>GET /api/scoring/versions/{version_id}\n</code></pre>"},{"location":"ml/versioning/#compare-versions","title":"Compare Versions","text":"<pre><code>GET /api/scoring/versions/compare?a=v1&amp;b=ml_v20240115\n</code></pre>"},{"location":"ml/versioning/#activate-version_1","title":"Activate Version","text":"<pre><code>POST /api/scoring/versions/{version_id}/activate\n</code></pre>"},{"location":"ml/versioning/#rollback","title":"Rollback","text":"<pre><code>POST /api/scoring/versions/{version_id}/rollback\n</code></pre>"},{"location":"ml/versioning/#audit-trail","title":"Audit Trail","text":"<p>Every version change is logged:</p> <pre><code>class ScorecardVersionAudit(Base):\n    __tablename__ = \"scorecard_version_audit\"\n\n    id = Column(Integer, primary_key=True)\n    version_id = Column(String(50))\n    action = Column(String(20))  # created, activated, deactivated\n    previous_state = Column(JSON)\n    new_state = Column(JSON)\n    changed_by = Column(String(100))\n    changed_at = Column(DateTime, default=datetime.utcnow)\n    reason = Column(Text)\n</code></pre>"},{"location":"ml/versioning/#best-practices","title":"Best Practices","text":"<ol> <li>Never Edit Active: Create new version instead of editing active</li> <li>Test Before Activate: Validate draft versions thoroughly</li> <li>Document Changes: Include notes explaining why changes were made</li> <li>Gradual Rollout: Consider A/B testing before full activation</li> <li>Keep History: Never delete inactive versions</li> <li>Monitor Impact: Track score distribution after version change</li> </ol>"},{"location":"scoring/bands/","title":"Score Bands","text":"<p>Score bands categorize credit scores into risk levels for business decisions.</p>"},{"location":"scoring/bands/#overview","title":"Overview","text":"Band Score Range Risk Level excellent 800-900 Very Low good 700-799 Low fair 600-699 Medium poor 450-599 High very_poor 300-449 Very High"},{"location":"scoring/bands/#band-assignment","title":"Band Assignment","text":""},{"location":"scoring/bands/#implementation","title":"Implementation","text":"<pre><code>def get_score_band(score: int) -&gt; str:\n    \"\"\"\n    Map score to risk band.\n\n    Args:\n        score: Credit score (300-900)\n\n    Returns:\n        Band name\n    \"\"\"\n    if score &gt;= 800:\n        return \"excellent\"\n    elif score &gt;= 700:\n        return \"good\"\n    elif score &gt;= 600:\n        return \"fair\"\n    elif score &gt;= 450:\n        return \"poor\"\n    else:\n        return \"very_poor\"\n</code></pre>"},{"location":"scoring/bands/#band-descriptions","title":"Band Descriptions","text":""},{"location":"scoring/bands/#excellent-800-900","title":"Excellent (800-900)","text":"<ul> <li>Risk Level: Very Low</li> <li>Characteristics:</li> <li>Strong KYC verification</li> <li>Established business (5+ years)</li> <li>High transaction volume and regularity</li> <li>Diverse network of counterparties</li> <li>Recommendation: Standard terms, priority processing</li> </ul>"},{"location":"scoring/bands/#good-700-799","title":"Good (700-799)","text":"<ul> <li>Risk Level: Low</li> <li>Characteristics:</li> <li>KYC verified</li> <li>Established business (2-5 years)</li> <li>Regular transaction history</li> <li>Active network connections</li> <li>Recommendation: Standard terms</li> </ul>"},{"location":"scoring/bands/#fair-600-699","title":"Fair (600-699)","text":"<ul> <li>Risk Level: Medium</li> <li>Characteristics:</li> <li>May have some KYC gaps</li> <li>Moderate business age (1-2 years)</li> <li>Adequate transaction history</li> <li>Some network connections</li> <li>Recommendation: Enhanced monitoring, shorter terms</li> </ul>"},{"location":"scoring/bands/#poor-450-599","title":"Poor (450-599)","text":"<ul> <li>Risk Level: High</li> <li>Characteristics:</li> <li>KYC concerns</li> <li>New or young business</li> <li>Limited transaction history</li> <li>Few network connections</li> <li>Recommendation: Collateral requirements, manual review</li> </ul>"},{"location":"scoring/bands/#very-poor-300-449","title":"Very Poor (300-449)","text":"<ul> <li>Risk Level: Very High</li> <li>Characteristics:</li> <li>Major KYC issues</li> <li>Very new or problematic business</li> <li>Minimal or no transactions</li> <li>Isolated from network</li> <li>Recommendation: Decline or heavy restrictions</li> </ul>"},{"location":"scoring/bands/#band-distribution","title":"Band Distribution","text":"<p>Typical distribution in healthy portfolio:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Score Band Distribution                         \u2502\n\u2502                                                                      \u2502\n\u2502  excellent  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                               15%           \u2502\n\u2502  good       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588               35%           \u2502\n\u2502  fair       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 30%           \u2502\n\u2502  poor       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                               15%           \u2502\n\u2502  very_poor  \u2588\u2588\u2588\u2588                                        5%           \u2502\n\u2502                                                                      \u2502\n\u2502             0%   10%   20%   30%   40%   50%                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"scoring/bands/#band-statistics","title":"Band Statistics","text":""},{"location":"scoring/bands/#api-endpoint","title":"API Endpoint","text":"<pre><code>GET /api/scoring/statistics\n</code></pre>"},{"location":"scoring/bands/#response","title":"Response","text":"<pre><code>{\n  \"total_scored\": 1000,\n  \"band_distribution\": {\n    \"excellent\": {\"count\": 150, \"percentage\": 15.0},\n    \"good\": {\"count\": 350, \"percentage\": 35.0},\n    \"fair\": {\"count\": 300, \"percentage\": 30.0},\n    \"poor\": {\"count\": 150, \"percentage\": 15.0},\n    \"very_poor\": {\"count\": 50, \"percentage\": 5.0}\n  },\n  \"average_score\": 652,\n  \"median_score\": 665,\n  \"score_range\": {\n    \"min\": 320,\n    \"max\": 875\n  }\n}\n</code></pre>"},{"location":"scoring/bands/#band-based-decisions","title":"Band-Based Decisions","text":""},{"location":"scoring/bands/#credit-limits","title":"Credit Limits","text":"Band Suggested Limit excellent Up to 100% of requested good Up to 80% of requested fair Up to 50% of requested poor Up to 25% or collateralized very_poor Decline or 100% collateral"},{"location":"scoring/bands/#payment-terms","title":"Payment Terms","text":"Band Suggested Terms excellent Net 60 good Net 45 fair Net 30 poor Net 15 or prepay very_poor Prepay only"},{"location":"scoring/bands/#review-requirements","title":"Review Requirements","text":"Band Review Process excellent Auto-approve good Auto-approve with notification fair Supervisor review poor Committee review very_poor Executive review or decline"},{"location":"scoring/bands/#usage-in-code","title":"Usage in Code","text":""},{"location":"scoring/bands/#basic-usage","title":"Basic Usage","text":"<pre><code>from app.scorecard.scorecard_engine import get_score_band\n\nscore = 720\nband = get_score_band(score)\n\nprint(f\"Score {score} is in band: {band}\")\n# Output: Score 720 is in band: good\n</code></pre>"},{"location":"scoring/bands/#with-scoring-service","title":"With Scoring Service","text":"<pre><code>result = scoring_service.compute_score(party_id=123)\n\nprint(f\"Score: {result['total_score']}\")\nprint(f\"Band: {result['band']}\")\n\n# Make decision based on band\nif result['band'] in ['excellent', 'good']:\n    approve_credit()\nelif result['band'] == 'fair':\n    request_review()\nelse:\n    decline_or_restrict()\n</code></pre>"},{"location":"scoring/bands/#band-filtering","title":"Band Filtering","text":"<pre><code># Get all parties in specific bands\nfrom app.models.models import ScoreRequest\n\nexcellent_parties = db.query(ScoreRequest).filter(\n    ScoreRequest.band == 'excellent'\n).all()\n\nhigh_risk_parties = db.query(ScoreRequest).filter(\n    ScoreRequest.band.in_(['poor', 'very_poor'])\n).all()\n</code></pre>"},{"location":"scoring/bands/#band-transitions","title":"Band Transitions","text":"<p>Track how scores change over time:</p> <pre><code>def get_band_transitions(party_id: int, db: Session) -&gt; list:\n    \"\"\"Get band transition history for a party.\"\"\"\n    scores = db.query(ScoreRequest).filter(\n        ScoreRequest.party_id == party_id\n    ).order_by(ScoreRequest.created_at).all()\n\n    transitions = []\n    for i in range(1, len(scores)):\n        if scores[i].band != scores[i-1].band:\n            transitions.append({\n                'from_band': scores[i-1].band,\n                'to_band': scores[i].band,\n                'date': scores[i].created_at,\n                'score_change': scores[i].total_score - scores[i-1].total_score\n            })\n\n    return transitions\n</code></pre>"},{"location":"scoring/bands/#customizing-bands","title":"Customizing Bands","text":""},{"location":"scoring/bands/#configuration","title":"Configuration","text":"<p>Bands can be customized via configuration:</p> <pre><code>BAND_CONFIG = {\n    \"excellent\": {\"min\": 800, \"max\": 900},\n    \"good\": {\"min\": 700, \"max\": 799},\n    \"fair\": {\"min\": 600, \"max\": 699},\n    \"poor\": {\"min\": 450, \"max\": 599},\n    \"very_poor\": {\"min\": 300, \"max\": 449}\n}\n\ndef get_score_band_custom(score: int, config: dict = None) -&gt; str:\n    \"\"\"Get band with custom configuration.\"\"\"\n    config = config or BAND_CONFIG\n\n    for band_name, ranges in config.items():\n        if ranges['min'] &lt;= score &lt;= ranges['max']:\n            return band_name\n\n    return \"unknown\"\n</code></pre>"},{"location":"scoring/bands/#adding-bands","title":"Adding Bands","text":"<p>For finer granularity:</p> <pre><code>EXTENDED_BAND_CONFIG = {\n    \"excellent_plus\": {\"min\": 850, \"max\": 900},\n    \"excellent\": {\"min\": 800, \"max\": 849},\n    \"good_plus\": {\"min\": 750, \"max\": 799},\n    \"good\": {\"min\": 700, \"max\": 749},\n    \"fair_plus\": {\"min\": 650, \"max\": 699},\n    \"fair\": {\"min\": 600, \"max\": 649},\n    \"poor\": {\"min\": 450, \"max\": 599},\n    \"very_poor\": {\"min\": 300, \"max\": 449}\n}\n</code></pre>"},{"location":"scoring/bands/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"scoring/bands/#band-drift-detection","title":"Band Drift Detection","text":"<pre><code>def check_band_drift(batch_id: str, db: Session) -&gt; dict:\n    \"\"\"Check for unusual band distributions in a batch.\"\"\"\n    expected = {\"excellent\": 0.15, \"good\": 0.35, \"fair\": 0.30, \"poor\": 0.15, \"very_poor\": 0.05}\n\n    results = db.query(\n        ScoreRequest.band,\n        func.count(ScoreRequest.id)\n    ).filter(\n        ScoreRequest.batch_id == batch_id\n    ).group_by(ScoreRequest.band).all()\n\n    total = sum(count for _, count in results)\n    actual = {band: count/total for band, count in results}\n\n    drift = {}\n    for band, expected_pct in expected.items():\n        actual_pct = actual.get(band, 0)\n        drift[band] = {\n            'expected': expected_pct,\n            'actual': actual_pct,\n            'difference': actual_pct - expected_pct,\n            'alert': abs(actual_pct - expected_pct) &gt; 0.1\n        }\n\n    return drift\n</code></pre>"},{"location":"scoring/bands/#alert-on-high-risk-concentration","title":"Alert on High-Risk Concentration","text":"<pre><code>def alert_high_risk_concentration(batch_id: str, threshold: float = 0.25) -&gt; bool:\n    \"\"\"Alert if too many scores are in poor/very_poor bands.\"\"\"\n    high_risk_count = db.query(ScoreRequest).filter(\n        ScoreRequest.batch_id == batch_id,\n        ScoreRequest.band.in_(['poor', 'very_poor'])\n    ).count()\n\n    total_count = db.query(ScoreRequest).filter(\n        ScoreRequest.batch_id == batch_id\n    ).count()\n\n    if total_count &gt; 0 and high_risk_count / total_count &gt; threshold:\n        send_alert(f\"High risk concentration: {high_risk_count/total_count:.1%}\")\n        return True\n\n    return False\n</code></pre>"},{"location":"scoring/computation/","title":"Score Computation","text":"<p>The scoring system transforms features into credit scores through a multi-stage process.</p>"},{"location":"scoring/computation/#overview","title":"Overview","text":"<pre><code>Features \u2192 Scorecard Engine \u2192 Decision Rules \u2192 Score Band \u2192 Final Result\n</code></pre>"},{"location":"scoring/computation/#computation-stages","title":"Computation Stages","text":""},{"location":"scoring/computation/#stage-1-feature-collection","title":"Stage 1: Feature Collection","text":"<p>Features are collected from the feature pipeline:</p> <pre><code>from app.services.feature_pipeline_service import FeaturePipelineService\n\npipeline = FeaturePipelineService(db)\nfeature_result = pipeline.extract_all_features(party_id)\n\n# Convert to dictionary\nfeatures = {\n    f['feature_name']: f['feature_value'] \n    for f in feature_result['features_list']\n}\n</code></pre>"},{"location":"scoring/computation/#stage-2-scorecard-calculation","title":"Stage 2: Scorecard Calculation","text":"<p>The scorecard engine computes the raw score:</p> <pre><code>from app.scorecard.scorecard_engine import compute_scorecard_score\n\nscore_result = compute_scorecard_score(features)\n# Returns: {total_score, band, components, raw_score, max_possible, version}\n</code></pre>"},{"location":"scoring/computation/#stage-3-decision-rules","title":"Stage 3: Decision Rules","text":"<p>Business rules can override or adjust scores:</p> <pre><code>from app.rules.evaluator import evaluate_rules\n\nrules_result = evaluate_rules(features, score_result['total_score'])\n# Returns: {adjustments, flags, final_score}\n</code></pre>"},{"location":"scoring/computation/#stage-4-band-assignment","title":"Stage 4: Band Assignment","text":"<p>Final score is mapped to a risk band:</p> <pre><code>from app.scorecard.scorecard_engine import get_score_band\n\nband = get_score_band(final_score)\n# Returns: 'excellent', 'good', 'fair', 'poor', or 'very_poor'\n</code></pre>"},{"location":"scoring/computation/#scoringservice-implementation","title":"ScoringService Implementation","text":""},{"location":"scoring/computation/#location","title":"Location","text":"<p><code>backend/app/services/scoring_service.py</code></p>"},{"location":"scoring/computation/#full-score-computation","title":"Full Score Computation","text":"<pre><code>class ScoringService:\n    def __init__(self, db: Session):\n        self.db = db\n        self.feature_pipeline = FeaturePipelineService(db)\n\n    def compute_score(\n        self,\n        party_id: int,\n        source: str = \"database\",\n        profile_data: dict = None,\n        scorecard_version: str = \"v1\"\n    ) -&gt; dict:\n        \"\"\"\n        Compute credit score for a party.\n\n        Args:\n            party_id: ID of the party\n            source: 'database' or 'synthetic'\n            profile_data: Optional synthetic profile data\n            scorecard_version: Scorecard version to use\n\n        Returns:\n            Complete scoring result\n        \"\"\"\n        # Step 1: Get features\n        if source == \"synthetic\" and profile_data:\n            features = self._extract_synthetic_features(profile_data)\n        else:\n            feature_result = self.feature_pipeline.extract_all_features(party_id)\n            features = self._flatten_features(feature_result)\n\n        # Step 2: Load scorecard config\n        scorecard_config = self._get_scorecard_config(scorecard_version)\n\n        # Step 3: Compute score\n        score_result = compute_scorecard_score(features, scorecard_config)\n\n        # Step 4: Apply decision rules\n        rules_result = evaluate_rules(features, score_result['total_score'])\n\n        # Step 5: Determine final score and band\n        final_score = rules_result.get('final_score', score_result['total_score'])\n        band = get_score_band(final_score)\n\n        # Step 6: Build response\n        result = {\n            'party_id': party_id,\n            'total_score': final_score,\n            'band': band,\n            'scorecard_version': scorecard_version,\n            'components': score_result['components'],\n            'rules_applied': rules_result.get('rules_applied', []),\n            'explanation': self._generate_explanation(score_result, rules_result),\n            'computed_at': datetime.utcnow().isoformat()\n        }\n\n        # Step 7: Log to database\n        self._log_score_request(party_id, result)\n\n        return result\n</code></pre>"},{"location":"scoring/computation/#feature-flattening","title":"Feature Flattening","text":"<p>Features from the pipeline are flattened for scorecard input:</p> <pre><code>def _flatten_features(self, feature_result: dict) -&gt; dict:\n    \"\"\"Convert feature list to dictionary.\"\"\"\n    return {\n        f['feature_name']: f['feature_value']\n        for f in feature_result['features_list']\n    }\n</code></pre>"},{"location":"scoring/computation/#synthetic-scoring","title":"Synthetic Scoring","text":"<p>For synthetic profiles (without database records):</p> <pre><code>def _extract_synthetic_features(self, profile_data: dict) -&gt; dict:\n    \"\"\"Extract features from synthetic profile data.\"\"\"\n    from app.adapters.synthetic_adapter import SyntheticAdapter\n\n    adapter = SyntheticAdapter()\n    normalized = adapter.parse(profile_data)\n\n    return {\n        'kyc_verified': 1.0 if normalized.get('kyc_verified') else 0.0,\n        'company_age_years': normalized.get('company_age_years', 0),\n        'party_type_score': self._encode_party_type(normalized.get('party_type')),\n        'contact_completeness': normalized.get('contact_completeness', 0),\n        'has_tax_id': 1.0 if normalized.get('tax_id') else 0.0,\n        'transaction_count_6m': normalized.get('transaction_count', 0),\n        'avg_transaction_amount': normalized.get('avg_transaction_amount', 0),\n        'total_transaction_volume_6m': normalized.get('total_volume', 0),\n        'transaction_regularity_score': normalized.get('regularity_score', 50),\n        'recent_activity_flag': 1.0 if normalized.get('recent_activity') else 0.0,\n        'direct_counterparty_count': normalized.get('counterparty_count', 0),\n        'network_size': normalized.get('network_size', 0),\n        'supplier_count': normalized.get('supplier_count', 0),\n        'customer_count': normalized.get('customer_count', 0),\n        'network_balance_ratio': normalized.get('network_balance', 0.5)\n    }\n</code></pre>"},{"location":"scoring/computation/#score-logging","title":"Score Logging","text":"<p>Every score computation is logged:</p> <pre><code>def _log_score_request(self, party_id: int, result: dict):\n    \"\"\"Log score request to database.\"\"\"\n    score_request = ScoreRequest(\n        party_id=party_id,\n        total_score=result['total_score'],\n        band=result['band'],\n        scorecard_version=result['scorecard_version'],\n        request_metadata={\n            'components': result['components'],\n            'rules_applied': result['rules_applied'],\n            'computed_at': result['computed_at']\n        }\n    )\n    self.db.add(score_request)\n    self.db.commit()\n</code></pre>"},{"location":"scoring/computation/#batch-scoring","title":"Batch Scoring","text":"<p>For scoring multiple parties:</p> <pre><code>def score_batch(self, batch_id: str, scorecard_version: str = \"v1\") -&gt; dict:\n    \"\"\"\n    Score all parties in a batch.\n\n    Returns:\n        dict with batch_id, scored_count, results\n    \"\"\"\n    parties = self.db.query(Party).filter(Party.batch_id == batch_id).all()\n\n    results = []\n    for party in parties:\n        try:\n            result = self.compute_score(party.id, scorecard_version=scorecard_version)\n            results.append(result)\n        except Exception as e:\n            results.append({\n                'party_id': party.id,\n                'error': str(e),\n                'total_score': None\n            })\n\n    return {\n        'batch_id': batch_id,\n        'scored_count': len([r for r in results if r.get('total_score')]),\n        'error_count': len([r for r in results if r.get('error')]),\n        'results': results\n    }\n</code></pre>"},{"location":"scoring/computation/#score-explanation-generation","title":"Score Explanation Generation","text":"<pre><code>def _generate_explanation(self, score_result: dict, rules_result: dict) -&gt; str:\n    \"\"\"Generate human-readable score explanation.\"\"\"\n    explanation_parts = []\n\n    # Top contributing factors\n    components = sorted(\n        score_result['components'],\n        key=lambda x: x['contribution'],\n        reverse=True\n    )[:3]\n\n    for comp in components:\n        pct = (comp['contribution'] / comp['max_contribution']) * 100\n        explanation_parts.append(\n            f\"{comp['feature']}: {pct:.0f}% of maximum\"\n        )\n\n    # Rules applied\n    if rules_result.get('rules_applied'):\n        explanation_parts.append(\n            f\"Rules applied: {', '.join(rules_result['rules_applied'])}\"\n        )\n\n    return \"; \".join(explanation_parts)\n</code></pre>"},{"location":"scoring/computation/#performance-optimization","title":"Performance Optimization","text":""},{"location":"scoring/computation/#caching","title":"Caching","text":"<p>Features are cached to avoid recomputation:</p> <pre><code>from app.cache.ttl_cache import feature_cache\n\ndef compute_score_cached(self, party_id: int, **kwargs) -&gt; dict:\n    cache_key = f\"party:{party_id}:score\"\n\n    cached = feature_cache.get(cache_key)\n    if cached:\n        return cached\n\n    result = self.compute_score(party_id, **kwargs)\n    feature_cache.set(cache_key, result, ttl=300)\n\n    return result\n</code></pre>"},{"location":"scoring/computation/#parallel-feature-extraction","title":"Parallel Feature Extraction","text":"<p>Extractors can run in parallel:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\n\ndef extract_features_parallel(self, party_id: int) -&gt; list:\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        futures = [\n            executor.submit(ext.extract, party_id, self.db)\n            for ext in self.extractors\n        ]\n        results = [f.result() for f in futures]\n    return [item for sublist in results for item in sublist]\n</code></pre>"},{"location":"scoring/computation/#error-handling","title":"Error Handling","text":"<pre><code>def compute_score_safe(self, party_id: int, **kwargs) -&gt; dict:\n    \"\"\"Compute score with error handling.\"\"\"\n    try:\n        return self.compute_score(party_id, **kwargs)\n    except PartyNotFoundError:\n        return {\n            'party_id': party_id,\n            'error': 'Party not found',\n            'total_score': None\n        }\n    except FeatureExtractionError as e:\n        return {\n            'party_id': party_id,\n            'error': f'Feature extraction failed: {e}',\n            'total_score': None\n        }\n    except Exception as e:\n        return {\n            'party_id': party_id,\n            'error': f'Unexpected error: {e}',\n            'total_score': None\n        }\n</code></pre>"},{"location":"scoring/decision-rules/","title":"Decision Rules","text":"<p>Decision rules provide business logic overrides and adjustments to computed scores.</p>"},{"location":"scoring/decision-rules/#overview","title":"Overview","text":"Property Value Location <code>backend/app/rules/evaluator.py</code> Expression Engine simpleeval Rule Types override, adjust, flag"},{"location":"scoring/decision-rules/#rule-system-architecture","title":"Rule System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Rule Evaluation                                 \u2502\n\u2502                                                                     \u2502\n\u2502   Input: Features + Base Score                                      \u2502\n\u2502          \u2502                                                          \u2502\n\u2502          \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Rule 1: KYC Override                                       \u2502  \u2502\n\u2502   \u2502  IF kyc_verified == 0 AND company_age_years &lt; 1             \u2502  \u2502\n\u2502   \u2502  THEN set_max_score(500)                                    \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502          \u2502                                                          \u2502\n\u2502          \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Rule 2: Activity Penalty                                   \u2502  \u2502\n\u2502   \u2502  IF recent_activity_flag == 0                               \u2502  \u2502\n\u2502   \u2502  THEN adjust_score(-50)                                     \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502          \u2502                                                          \u2502\n\u2502          \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Rule 3: Manual Review Flag                                 \u2502  \u2502\n\u2502   \u2502  IF network_size == 0                                       \u2502  \u2502\n\u2502   \u2502  THEN flag_for_review(\"no_network\")                         \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502          \u2502                                                          \u2502\n\u2502          \u25bc                                                          \u2502\n\u2502   Output: Adjusted Score + Flags + Applied Rules                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"scoring/decision-rules/#rule-definition","title":"Rule Definition","text":""},{"location":"scoring/decision-rules/#structure","title":"Structure","text":"<pre><code>RULE = {\n    \"id\": \"rule_001\",\n    \"name\": \"KYC Override\",\n    \"description\": \"Cap score for unverified new companies\",\n    \"condition\": \"kyc_verified == 0 and company_age_years &lt; 1\",\n    \"action\": {\n        \"type\": \"set_max_score\",\n        \"value\": 500\n    },\n    \"priority\": 1,\n    \"enabled\": True\n}\n</code></pre>"},{"location":"scoring/decision-rules/#properties","title":"Properties","text":"Property Type Description id string Unique rule identifier name string Human-readable name description string Rule explanation condition string Expression evaluated by simpleeval action object Action to take when condition is true priority int Order of evaluation (lower = first) enabled bool Whether rule is active"},{"location":"scoring/decision-rules/#action-types","title":"Action Types","text":""},{"location":"scoring/decision-rules/#set_max_score","title":"set_max_score","text":"<p>Caps the score at a maximum value:</p> <pre><code>{\n    \"type\": \"set_max_score\",\n    \"value\": 500\n}\n</code></pre> <p>Result: <code>final_score = min(base_score, 500)</code></p>"},{"location":"scoring/decision-rules/#set_min_score","title":"set_min_score","text":"<p>Sets a minimum score floor:</p> <pre><code>{\n    \"type\": \"set_min_score\",\n    \"value\": 400\n}\n</code></pre> <p>Result: <code>final_score = max(base_score, 400)</code></p>"},{"location":"scoring/decision-rules/#adjust_score","title":"adjust_score","text":"<p>Adds or subtracts from the score:</p> <pre><code>{\n    \"type\": \"adjust_score\",\n    \"value\": -50\n}\n</code></pre> <p>Result: <code>final_score = base_score - 50</code></p>"},{"location":"scoring/decision-rules/#multiply_score","title":"multiply_score","text":"<p>Multiplies the score by a factor:</p> <pre><code>{\n    \"type\": \"multiply_score\",\n    \"value\": 0.9\n}\n</code></pre> <p>Result: <code>final_score = base_score * 0.9</code></p>"},{"location":"scoring/decision-rules/#flag_for_review","title":"flag_for_review","text":"<p>Adds a review flag without changing score:</p> <pre><code>{\n    \"type\": \"flag_for_review\",\n    \"value\": \"manual_review_required\"\n}\n</code></pre> <p>Result: Adds flag to output, score unchanged</p>"},{"location":"scoring/decision-rules/#rule-evaluator-implementation","title":"Rule Evaluator Implementation","text":"<pre><code>from simpleeval import simple_eval\n\nclass RuleEvaluator:\n    \"\"\"Evaluate business rules against features and scores.\"\"\"\n\n    def __init__(self):\n        self.rules = self._load_rules()\n\n    def evaluate_rules(\n        self, \n        features: dict, \n        base_score: int\n    ) -&gt; dict:\n        \"\"\"\n        Evaluate all rules and return adjustments.\n\n        Args:\n            features: Feature dictionary\n            base_score: Score before rules\n\n        Returns:\n            dict with final_score, rules_applied, flags\n        \"\"\"\n        final_score = base_score\n        rules_applied = []\n        flags = []\n\n        # Sort by priority\n        sorted_rules = sorted(\n            [r for r in self.rules if r['enabled']],\n            key=lambda x: x['priority']\n        )\n\n        for rule in sorted_rules:\n            try:\n                # Evaluate condition\n                result = simple_eval(\n                    rule['condition'],\n                    names=features\n                )\n\n                if result:\n                    # Apply action\n                    final_score, flag = self._apply_action(\n                        rule['action'],\n                        final_score\n                    )\n\n                    rules_applied.append(rule['id'])\n                    if flag:\n                        flags.append(flag)\n\n            except Exception as e:\n                print(f\"Rule {rule['id']} error: {e}\")\n\n        # Ensure score stays in valid range\n        final_score = min(900, max(300, final_score))\n\n        return {\n            'final_score': final_score,\n            'rules_applied': rules_applied,\n            'flags': flags,\n            'adjustment': final_score - base_score\n        }\n\n    def _apply_action(self, action: dict, score: int) -&gt; tuple:\n        \"\"\"Apply rule action and return new score and optional flag.\"\"\"\n        action_type = action['type']\n        value = action['value']\n\n        if action_type == 'set_max_score':\n            return min(score, value), None\n        elif action_type == 'set_min_score':\n            return max(score, value), None\n        elif action_type == 'adjust_score':\n            return score + value, None\n        elif action_type == 'multiply_score':\n            return int(score * value), None\n        elif action_type == 'flag_for_review':\n            return score, value\n        else:\n            return score, None\n</code></pre>"},{"location":"scoring/decision-rules/#default-rules","title":"Default Rules","text":""},{"location":"scoring/decision-rules/#rule-kyc-override","title":"Rule: KYC Override","text":"<p>Unverified new companies are capped:</p> <pre><code>{\n    \"id\": \"kyc_override\",\n    \"name\": \"KYC Override\",\n    \"condition\": \"kyc_verified == 0 and company_age_years &lt; 1\",\n    \"action\": {\"type\": \"set_max_score\", \"value\": 500},\n    \"priority\": 1\n}\n</code></pre>"},{"location":"scoring/decision-rules/#rule-no-activity-penalty","title":"Rule: No Activity Penalty","text":"<p>No recent activity reduces score:</p> <pre><code>{\n    \"id\": \"no_activity_penalty\",\n    \"name\": \"No Activity Penalty\",\n    \"condition\": \"recent_activity_flag == 0\",\n    \"action\": {\"type\": \"adjust_score\", \"value\": -30},\n    \"priority\": 2\n}\n</code></pre>"},{"location":"scoring/decision-rules/#rule-high-volume-bonus","title":"Rule: High Volume Bonus","text":"<p>High transaction volume gets bonus:</p> <pre><code>{\n    \"id\": \"high_volume_bonus\",\n    \"name\": \"High Volume Bonus\",\n    \"condition\": \"total_transaction_volume_6m &gt; 500000\",\n    \"action\": {\"type\": \"adjust_score\", \"value\": 25},\n    \"priority\": 3\n}\n</code></pre>"},{"location":"scoring/decision-rules/#rule-network-isolation-flag","title":"Rule: Network Isolation Flag","text":"<p>Isolated parties need review:</p> <pre><code>{\n    \"id\": \"network_isolation_flag\",\n    \"name\": \"Network Isolation Flag\",\n    \"condition\": \"network_size == 0 or direct_counterparty_count == 0\",\n    \"action\": {\"type\": \"flag_for_review\", \"value\": \"isolated_network\"},\n    \"priority\": 4\n}\n</code></pre>"},{"location":"scoring/decision-rules/#rule-missing-contact-flag","title":"Rule: Missing Contact Flag","text":"<p>Incomplete profiles need review:</p> <pre><code>{\n    \"id\": \"missing_contact_flag\",\n    \"name\": \"Missing Contact Flag\",\n    \"condition\": \"contact_completeness &lt; 50\",\n    \"action\": {\"type\": \"flag_for_review\", \"value\": \"incomplete_profile\"},\n    \"priority\": 5\n}\n</code></pre>"},{"location":"scoring/decision-rules/#condition-expressions","title":"Condition Expressions","text":""},{"location":"scoring/decision-rules/#supported-operators","title":"Supported Operators","text":"Operator Description Example == Equals <code>kyc_verified == 1</code> != Not equals <code>party_type != 'customer'</code> &gt; Greater than <code>company_age_years &gt; 5</code> &gt;= Greater or equal <code>transaction_count_6m &gt;= 10</code> &lt; Less than <code>score &lt; 500</code> &lt;= Less or equal <code>network_size &lt;= 2</code> and Logical AND <code>kyc_verified == 1 and company_age_years &gt; 2</code> or Logical OR <code>kyc_verified == 0 or has_tax_id == 0</code> not Logical NOT <code>not recent_activity_flag</code>"},{"location":"scoring/decision-rules/#available-variables","title":"Available Variables","text":"<p>All features are available as variables:</p> <ul> <li><code>kyc_verified</code></li> <li><code>company_age_years</code></li> <li><code>party_type_score</code></li> <li><code>contact_completeness</code></li> <li><code>has_tax_id</code></li> <li><code>transaction_count_6m</code></li> <li><code>avg_transaction_amount</code></li> <li><code>total_transaction_volume_6m</code></li> <li><code>transaction_regularity_score</code></li> <li><code>recent_activity_flag</code></li> <li><code>direct_counterparty_count</code></li> <li><code>network_depth_downstream</code></li> <li><code>network_size</code></li> <li><code>supplier_count</code></li> <li><code>customer_count</code></li> <li><code>network_balance_ratio</code></li> </ul>"},{"location":"scoring/decision-rules/#usage","title":"Usage","text":""},{"location":"scoring/decision-rules/#basic-evaluation","title":"Basic Evaluation","text":"<pre><code>from app.rules.evaluator import evaluate_rules\n\nfeatures = {\n    \"kyc_verified\": 0,\n    \"company_age_years\": 0.5,\n    \"recent_activity_flag\": 1,\n    \"network_size\": 5\n}\n\nresult = evaluate_rules(features, base_score=650)\n\nprint(f\"Final Score: {result['final_score']}\")\nprint(f\"Rules Applied: {result['rules_applied']}\")\nprint(f\"Flags: {result['flags']}\")\n</code></pre> <p>Output: <pre><code>Final Score: 500\nRules Applied: ['kyc_override']\nFlags: []\n</code></pre></p>"},{"location":"scoring/decision-rules/#with-integration","title":"With Integration","text":"<pre><code># In ScoringService.compute_score()\nscore_result = compute_scorecard_score(features)\nrules_result = evaluate_rules(features, score_result['total_score'])\n\nfinal_score = rules_result['final_score']\n</code></pre>"},{"location":"scoring/decision-rules/#rule-management","title":"Rule Management","text":""},{"location":"scoring/decision-rules/#adding-rules","title":"Adding Rules","text":"<pre><code>evaluator = RuleEvaluator()\n\nnew_rule = {\n    \"id\": \"custom_rule\",\n    \"name\": \"Custom Rule\",\n    \"condition\": \"some_feature &gt; threshold\",\n    \"action\": {\"type\": \"adjust_score\", \"value\": 10},\n    \"priority\": 10,\n    \"enabled\": True\n}\n\nevaluator.add_rule(new_rule)\n</code></pre>"},{"location":"scoring/decision-rules/#disabling-rules","title":"Disabling Rules","text":"<pre><code>evaluator.disable_rule(\"kyc_override\")\n</code></pre>"},{"location":"scoring/decision-rules/#loading-from-database","title":"Loading from Database","text":"<pre><code>def _load_rules(self) -&gt; list:\n    \"\"\"Load rules from database or config file.\"\"\"\n    # From database\n    db_rules = self.db.query(DecisionRule).filter(\n        DecisionRule.enabled == True\n    ).all()\n\n    return [rule.to_dict() for rule in db_rules]\n</code></pre>"},{"location":"scoring/decision-rules/#testing-rules","title":"Testing Rules","text":"<pre><code>def test_kyc_override_rule():\n    \"\"\"Test that unverified new companies are capped.\"\"\"\n    features = {\n        \"kyc_verified\": 0,\n        \"company_age_years\": 0.5\n    }\n\n    result = evaluate_rules(features, base_score=700)\n\n    assert result['final_score'] == 500\n    assert 'kyc_override' in result['rules_applied']\n</code></pre>"},{"location":"scoring/scorecard-engine/","title":"Scorecard Engine","text":"<p>The Scorecard Engine computes credit scores using a weighted feature scoring model.</p>"},{"location":"scoring/scorecard-engine/#overview","title":"Overview","text":"Property Value Location <code>backend/app/scorecard/scorecard_engine.py</code> Score Range 300-900 Default Version v1 Calculation Weighted sum of normalized features"},{"location":"scoring/scorecard-engine/#core-philosophy","title":"Core Philosophy","text":"<p>\"The Scorecard is King, AI is the Advisor\"</p> <p>The scorecard provides transparent, explainable credit decisions:</p> <ol> <li>Transparency: Every score component is traceable</li> <li>Auditability: Decision rules are documented</li> <li>Stability: Scores change predictably with inputs</li> <li>ML Refinement: AI improves weights, not replaces logic</li> </ol>"},{"location":"scoring/scorecard-engine/#score-calculation","title":"Score Calculation","text":""},{"location":"scoring/scorecard-engine/#formula","title":"Formula","text":"<pre><code>Raw Score = Sum(feature_value * weight * multiplier)\nNormalized Score = 300 + (Raw Score / Max Possible Score) * 600\nFinal Score = min(900, max(300, Normalized Score))\n</code></pre>"},{"location":"scoring/scorecard-engine/#process-flow","title":"Process Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Scorecard Engine                                 \u2502\n\u2502                                                                     \u2502\n\u2502   Input: Feature Dictionary                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  {                                                          \u2502  \u2502\n\u2502   \u2502    \"kyc_verified\": 1.0,                                     \u2502  \u2502\n\u2502   \u2502    \"company_age_years\": 5.0,                                \u2502  \u2502\n\u2502   \u2502    \"transaction_count_6m\": 45.0,                            \u2502  \u2502\n\u2502   \u2502    ...                                                      \u2502  \u2502\n\u2502   \u2502  }                                                          \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Scorecard Configuration                                    \u2502  \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502\n\u2502   \u2502  \u2502 Feature: kyc_verified                                 \u2502 \u2502  \u2502\n\u2502   \u2502  \u2502   weight: 15, multiplier: 1.0, max_raw: 15           \u2502 \u2502  \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502\n\u2502   \u2502  \u2502 Feature: company_age_years                            \u2502 \u2502  \u2502\n\u2502   \u2502  \u2502   weight: 10, multiplier: 2.0, max_raw: 20           \u2502 \u2502  \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Weighted Sum Calculation                                   \u2502  \u2502\n\u2502   \u2502                                                             \u2502  \u2502\n\u2502   \u2502  kyc_verified: 1.0 * 15 * 1.0 = 15                         \u2502  \u2502\n\u2502   \u2502  company_age_years: min(5.0, 10) * 10 * 2.0 = 100          \u2502  \u2502\n\u2502   \u2502  ...                                                        \u2502  \u2502\n\u2502   \u2502  Raw Score: 185                                             \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                          \u2502                                          \u2502\n\u2502                          \u25bc                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502  Normalization                                              \u2502  \u2502\n\u2502   \u2502                                                             \u2502  \u2502\n\u2502   \u2502  Max Possible: 300                                          \u2502  \u2502\n\u2502   \u2502  Normalized: 300 + (185/300) * 600 = 670                   \u2502  \u2502\n\u2502   \u2502  Final Score: 670                                           \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"scoring/scorecard-engine/#implementation","title":"Implementation","text":"<pre><code>def compute_scorecard_score(\n    features: dict,\n    scorecard_config: dict = None,\n    version: str = \"v1\"\n) -&gt; dict:\n    \"\"\"\n    Compute credit score from features.\n\n    Args:\n        features: Dictionary of feature_name -&gt; feature_value\n        scorecard_config: Optional custom scorecard configuration\n        version: Scorecard version to use\n\n    Returns:\n        dict with total_score, band, components, version\n    \"\"\"\n    config = scorecard_config or get_scorecard_config(version)\n\n    raw_score = 0.0\n    max_possible = 0.0\n    components = []\n\n    for feature_name, feature_config in config['features'].items():\n        weight = feature_config['weight']\n        multiplier = feature_config.get('multiplier', 1.0)\n        max_value = feature_config.get('max_value', float('inf'))\n\n        # Get feature value (default to 0)\n        value = features.get(feature_name, 0.0)\n\n        # Cap at max value\n        capped_value = min(value, max_value)\n\n        # Calculate contribution\n        contribution = capped_value * weight * multiplier\n        max_contribution = max_value * weight * multiplier\n\n        raw_score += contribution\n        max_possible += max_contribution\n\n        components.append({\n            'feature': feature_name,\n            'value': value,\n            'weight': weight,\n            'contribution': contribution,\n            'max_contribution': max_contribution\n        })\n\n    # Normalize to 300-900 range\n    if max_possible &gt; 0:\n        normalized = 300 + (raw_score / max_possible) * 600\n    else:\n        normalized = 300\n\n    final_score = min(900, max(300, int(normalized)))\n\n    return {\n        'total_score': final_score,\n        'band': get_score_band(final_score),\n        'components': components,\n        'raw_score': raw_score,\n        'max_possible': max_possible,\n        'version': version\n    }\n</code></pre>"},{"location":"scoring/scorecard-engine/#scorecard-configuration","title":"Scorecard Configuration","text":""},{"location":"scoring/scorecard-engine/#structure","title":"Structure","text":"<pre><code>SCORECARD_CONFIG = {\n    \"version\": \"v1\",\n    \"features\": {\n        \"kyc_verified\": {\n            \"weight\": 15,\n            \"multiplier\": 1.0,\n            \"max_value\": 1\n        },\n        \"company_age_years\": {\n            \"weight\": 10,\n            \"multiplier\": 2.0,\n            \"max_value\": 10\n        },\n        \"transaction_count_6m\": {\n            \"weight\": 10,\n            \"multiplier\": 0.5,\n            \"max_value\": 100\n        },\n        # ... more features\n    }\n}\n</code></pre>"},{"location":"scoring/scorecard-engine/#feature-configuration-properties","title":"Feature Configuration Properties","text":"Property Type Description weight float Base importance of the feature multiplier float Scaling factor for feature value max_value float Cap for feature value (prevents outliers)"},{"location":"scoring/scorecard-engine/#default-feature-weights","title":"Default Feature Weights","text":""},{"location":"scoring/scorecard-engine/#kyc-features","title":"KYC Features","text":"Feature Weight Multiplier Max Value kyc_verified 15 1.0 1 company_age_years 10 2.0 10 party_type_score 5 1.0 10 contact_completeness 5 0.1 100 has_tax_id 10 1.0 1"},{"location":"scoring/scorecard-engine/#transaction-features","title":"Transaction Features","text":"Feature Weight Multiplier Max Value transaction_count_6m 10 0.5 100 avg_transaction_amount 5 0.001 50000 total_transaction_volume_6m 5 0.00001 1000000 transaction_regularity_score 10 0.1 100 recent_activity_flag 15 1.0 1"},{"location":"scoring/scorecard-engine/#network-features","title":"Network Features","text":"Feature Weight Multiplier Max Value direct_counterparty_count 5 0.5 20 network_depth_downstream 3 1.0 5 network_size 5 0.2 50 supplier_count 5 0.5 10 customer_count 5 0.5 10 network_balance_ratio 7 10.0 1"},{"location":"scoring/scorecard-engine/#usage","title":"Usage","text":""},{"location":"scoring/scorecard-engine/#basic-usage","title":"Basic Usage","text":"<pre><code>from app.scorecard.scorecard_engine import compute_scorecard_score\n\nfeatures = {\n    \"kyc_verified\": 1.0,\n    \"company_age_years\": 5.0,\n    \"transaction_count_6m\": 45.0,\n    \"avg_transaction_amount\": 5000.0,\n    \"transaction_regularity_score\": 75.0,\n    \"recent_activity_flag\": 1.0,\n    \"direct_counterparty_count\": 8.0,\n    \"network_size\": 15.0\n}\n\nresult = compute_scorecard_score(features)\n\nprint(f\"Score: {result['total_score']}\")\nprint(f\"Band: {result['band']}\")\n</code></pre> <p>Output: <pre><code>Score: 720\nBand: good\n</code></pre></p>"},{"location":"scoring/scorecard-engine/#with-custom-config","title":"With Custom Config","text":"<pre><code>custom_config = {\n    \"version\": \"custom_v1\",\n    \"features\": {\n        \"kyc_verified\": {\"weight\": 20, \"multiplier\": 1.0, \"max_value\": 1},\n        \"company_age_years\": {\"weight\": 15, \"multiplier\": 1.5, \"max_value\": 15}\n    }\n}\n\nresult = compute_scorecard_score(features, scorecard_config=custom_config)\n</code></pre>"},{"location":"scoring/scorecard-engine/#with-specific-version","title":"With Specific Version","text":"<pre><code># Use ML-refined scorecard version\nresult = compute_scorecard_score(features, version=\"ml_v2\")\n</code></pre>"},{"location":"scoring/scorecard-engine/#score-explanation","title":"Score Explanation","text":"<p>The engine provides detailed explanations:</p> <pre><code>result = compute_scorecard_score(features)\n\nfor component in result['components']:\n    print(f\"{component['feature']}:\")\n    print(f\"  Value: {component['value']}\")\n    print(f\"  Weight: {component['weight']}\")\n    print(f\"  Contribution: {component['contribution']:.2f}\")\n    print(f\"  Max Possible: {component['max_contribution']:.2f}\")\n    print()\n</code></pre> <p>Output: <pre><code>kyc_verified:\n  Value: 1.0\n  Weight: 15\n  Contribution: 15.00\n  Max Possible: 15.00\n\ncompany_age_years:\n  Value: 5.0\n  Weight: 10\n  Contribution: 100.00\n  Max Possible: 200.00\n</code></pre></p>"},{"location":"scoring/scorecard-engine/#missing-features","title":"Missing Features","text":"<p>When features are missing:</p> <ol> <li>Default value of 0 is used</li> <li>Contribution to score is 0</li> <li>Max possible score is still calculated</li> <li>Result includes flag for missing features</li> </ol> <pre><code># Features with missing values\nfeatures = {\n    \"kyc_verified\": 1.0\n    # Other features missing\n}\n\nresult = compute_scorecard_score(features)\n# Score will be low due to missing features\n</code></pre>"},{"location":"testing/running/","title":"Running Tests","text":"<p>This guide covers how to run tests for the KYCC backend.</p>"},{"location":"testing/running/#quick-start","title":"Quick Start","text":"<pre><code>cd backend\npytest\n</code></pre>"},{"location":"testing/running/#prerequisites","title":"Prerequisites","text":""},{"location":"testing/running/#virtual-environment","title":"Virtual Environment","text":"<pre><code># Windows\ncd backend\n.\\venv\\Scripts\\Activate.ps1\n\n# Linux/Mac\ncd backend\nsource venv/bin/activate\n</code></pre>"},{"location":"testing/running/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"testing/running/#running-tests_1","title":"Running Tests","text":""},{"location":"testing/running/#all-tests","title":"All Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"testing/running/#specific-test-file","title":"Specific Test File","text":"<pre><code>pytest tests/test_scorecard_service.py\n</code></pre>"},{"location":"testing/running/#specific-test-function","title":"Specific Test Function","text":"<pre><code>pytest tests/test_scorecard_service.py::test_compute_score\n</code></pre>"},{"location":"testing/running/#tests-matching-pattern","title":"Tests Matching Pattern","text":"<pre><code>pytest -k \"score\"           # Tests containing \"score\"\npytest -k \"not slow\"        # Exclude slow tests\npytest -k \"score and batch\" # Multiple patterns\n</code></pre>"},{"location":"testing/running/#output-options","title":"Output Options","text":""},{"location":"testing/running/#verbose-output","title":"Verbose Output","text":"<pre><code>pytest -v                 # Verbose\npytest -vv                # Very verbose\npytest -vvv               # Maximum verbosity\n</code></pre>"},{"location":"testing/running/#show-print-statements","title":"Show Print Statements","text":"<pre><code>pytest -s\n</code></pre>"},{"location":"testing/running/#show-test-durations","title":"Show Test Durations","text":"<pre><code>pytest --durations=10     # Show 10 slowest tests\npytest --durations=0      # Show all test durations\n</code></pre>"},{"location":"testing/running/#stop-on-first-failure","title":"Stop on First Failure","text":"<pre><code>pytest -x                 # Stop on first failure\npytest --maxfail=3        # Stop after 3 failures\n</code></pre>"},{"location":"testing/running/#coverage-reports","title":"Coverage Reports","text":""},{"location":"testing/running/#basic-coverage","title":"Basic Coverage","text":"<pre><code>pytest --cov=app\n</code></pre>"},{"location":"testing/running/#html-report","title":"HTML Report","text":"<pre><code>pytest --cov=app --cov-report=html\n</code></pre> <p>Opens: <code>backend/htmlcov/index.html</code></p>"},{"location":"testing/running/#terminal-report-with-missing-lines","title":"Terminal Report with Missing Lines","text":"<pre><code>pytest --cov=app --cov-report=term-missing\n</code></pre>"},{"location":"testing/running/#xml-report-for-ci","title":"XML Report (for CI)","text":"<pre><code>pytest --cov=app --cov-report=xml\n</code></pre>"},{"location":"testing/running/#test-categories","title":"Test Categories","text":""},{"location":"testing/running/#run-by-marker","title":"Run by Marker","text":"<pre><code>pytest -m slow            # Only slow tests\npytest -m \"not slow\"      # Exclude slow tests\npytest -m integration     # Only integration tests\n</code></pre>"},{"location":"testing/running/#run-by-directory","title":"Run by Directory","text":"<pre><code>pytest tests/             # All tests in directory\npytest tests/unit/        # Only unit tests\npytest tests/integration/ # Only integration tests\n</code></pre>"},{"location":"testing/running/#parallel-execution","title":"Parallel Execution","text":""},{"location":"testing/running/#install-pytest-xdist","title":"Install pytest-xdist","text":"<pre><code>pip install pytest-xdist\n</code></pre>"},{"location":"testing/running/#run-in-parallel","title":"Run in Parallel","text":"<pre><code>pytest -n auto            # Use all CPU cores\npytest -n 4               # Use 4 processes\n</code></pre>"},{"location":"testing/running/#debugging","title":"Debugging","text":""},{"location":"testing/running/#drop-into-debugger-on-failure","title":"Drop into Debugger on Failure","text":"<pre><code>pytest --pdb\n</code></pre>"},{"location":"testing/running/#drop-into-debugger-at-start","title":"Drop into Debugger at Start","text":"<pre><code>pytest --pdb --pdbcls=IPython.terminal.debugger:Pdb\n</code></pre>"},{"location":"testing/running/#run-last-failed-tests","title":"Run Last Failed Tests","text":"<pre><code>pytest --lf               # Last failed\npytest --ff               # Failed first, then rest\n</code></pre>"},{"location":"testing/running/#configuration","title":"Configuration","text":""},{"location":"testing/running/#pytestini","title":"pytest.ini","text":"<p>Create <code>backend/pytest.ini</code>:</p> <pre><code>[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_functions = test_*\npython_classes = Test*\naddopts = -v --tb=short\nmarkers =\n    slow: marks tests as slow\n    integration: marks integration tests\nfilterwarnings =\n    ignore::DeprecationWarning\n</code></pre>"},{"location":"testing/running/#pyprojecttoml-alternative","title":"pyproject.toml Alternative","text":"<pre><code>[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\naddopts = \"-v --tb=short\"\n</code></pre>"},{"location":"testing/running/#test-database","title":"Test Database","text":""},{"location":"testing/running/#default-configuration","title":"Default Configuration","text":"<p>Tests automatically use SQLite (<code>test_run.db</code>) set in <code>conftest.py</code>:</p> <pre><code>os.environ[\"DATABASE_URL\"] = \"sqlite:///test_run.db\"\n</code></pre>"},{"location":"testing/running/#fresh-database-each-run","title":"Fresh Database Each Run","text":"<p>The test database is deleted at the start of each test run:</p> <pre><code>test_db = Path(\"test_run.db\")\nif test_db.exists():\n    test_db.unlink()\n</code></pre>"},{"location":"testing/running/#in-memory-database-faster","title":"In-Memory Database (Faster)","text":"<p>For even faster tests, modify <code>conftest.py</code>:</p> <pre><code>os.environ[\"DATABASE_URL\"] = \"sqlite:///:memory:\"\n</code></pre>"},{"location":"testing/running/#common-commands","title":"Common Commands","text":""},{"location":"testing/running/#development-workflow","title":"Development Workflow","text":"<pre><code># Run all tests with coverage\npytest --cov=app -v\n\n# Run only failed tests from last run\npytest --lf -v\n\n# Run tests matching pattern\npytest -k \"score\" -v\n\n# Run with maximum output\npytest -vvs --tb=long\n</code></pre>"},{"location":"testing/running/#cicd-commands","title":"CI/CD Commands","text":"<pre><code># Full test suite with XML coverage\npytest --cov=app --cov-report=xml --junitxml=results.xml\n\n# Parallel execution for speed\npytest -n auto --cov=app\n\n# Fail if coverage below threshold\npytest --cov=app --cov-fail-under=80\n</code></pre>"},{"location":"testing/running/#quick-checks","title":"Quick Checks","text":"<pre><code># Syntax check only (no execution)\npytest --collect-only\n\n# Show test items that would run\npytest --collect-only -q\n\n# List available markers\npytest --markers\n\n# List available fixtures\npytest --fixtures\n</code></pre>"},{"location":"testing/running/#troubleshooting","title":"Troubleshooting","text":""},{"location":"testing/running/#import-errors","title":"Import Errors","text":"<p>Ensure you are in the backend directory:</p> <pre><code>cd backend\npytest tests/\n</code></pre>"},{"location":"testing/running/#database-errors","title":"Database Errors","text":"<p>Delete test database and retry:</p> <pre><code># Windows\ndel test_run.db\n\n# Linux/Mac\nrm test_run.db\n</code></pre>"},{"location":"testing/running/#module-not-found","title":"Module Not Found","text":"<p>Install package in editable mode:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"testing/running/#fixture-not-found","title":"Fixture Not Found","text":"<p>Check conftest.py is in the tests directory and fixtures are properly decorated.</p>"},{"location":"testing/running/#test-output-example","title":"Test Output Example","text":"<pre><code>================================ test session starts ================================\nplatform win32 -- Python 3.11.0, pytest-7.4.0\nrootdir: c:\\Users\\Anshu\\Desktop\\KYCC\\backend\nconfigfile: pytest.ini\nplugins: cov-4.1.0\ncollected 24 items\n\ntests/test_adapter_registry.py::test_register_adapter PASSED               [  4%]\ntests/test_adapter_registry.py::test_get_adapter PASSED                    [  8%]\ntests/test_feature_pipeline.py::test_extract_kyc_features PASSED           [ 12%]\ntests/test_feature_pipeline.py::test_extract_transaction_features PASSED   [ 16%]\ntests/test_feature_pipeline.py::test_extract_network_features PASSED       [ 20%]\ntests/test_rule_evaluator.py::test_simple_rule PASSED                      [ 25%]\ntests/test_rule_evaluator.py::test_complex_rule PASSED                     [ 29%]\ntests/test_scorecard_service.py::test_compute_score PASSED                 [ 33%]\ntests/test_scorecard_service.py::test_score_breakdown PASSED               [ 37%]\ntests/test_scorecard_service.py::test_batch_scoring PASSED                 [ 41%]\ntests/test_ttl_cache.py::test_cache_set_get PASSED                         [ 45%]\ntests/test_ttl_cache.py::test_cache_expiration PASSED                      [ 50%]\n...\n\n================================ 24 passed in 2.45s =================================\n</code></pre>"},{"location":"testing/strategy/","title":"Testing Strategy","text":"<p>This document outlines the testing approach for the KYCC credit scoring platform.</p>"},{"location":"testing/strategy/#overview","title":"Overview","text":"Property Value Framework pytest Database SQLite (in-memory for tests) Coverage Tool pytest-cov Location <code>backend/tests/</code>"},{"location":"testing/strategy/#testing-philosophy","title":"Testing Philosophy","text":"<ol> <li>Real Database Operations: Tests use real SQLAlchemy operations against SQLite, not mocks</li> <li>Isolation: Each test run gets a fresh database</li> <li>Comprehensive: Cover all service layers and edge cases</li> <li>Fast: SQLite in-memory keeps tests fast</li> </ol>"},{"location":"testing/strategy/#test-structure","title":"Test Structure","text":"<pre><code>backend/tests/\n\u251c\u2500\u2500 conftest.py                    # Shared fixtures\n\u251c\u2500\u2500 test_adapter_registry.py       # Adapter pattern tests\n\u251c\u2500\u2500 test_feature_pipeline.py       # Feature extraction tests\n\u251c\u2500\u2500 test_feature_service.py        # Feature service tests\n\u251c\u2500\u2500 test_iterative_learning.py     # ML refinement tests\n\u251c\u2500\u2500 test_rule_evaluator.py         # Decision rules tests\n\u251c\u2500\u2500 test_scorecard_persistence.py  # Scorecard storage tests\n\u251c\u2500\u2500 test_scorecard_service.py      # Scoring tests\n\u251c\u2500\u2500 test_synthetic_adapter.py      # Synthetic data tests\n\u2514\u2500\u2500 test_ttl_cache.py              # Cache tests\n</code></pre>"},{"location":"testing/strategy/#test-configuration","title":"Test Configuration","text":""},{"location":"testing/strategy/#conftestpy","title":"conftest.py","text":"<pre><code># backend/tests/conftest.py\n\nimport os\nimport sys\nfrom pathlib import Path\n\n# Set test database BEFORE any imports\nos.environ[\"DATABASE_URL\"] = \"sqlite:///test_run.db\"\nos.environ[\"TESTING\"] = \"true\"\n\n# Delete existing test database\ntest_db = Path(\"test_run.db\")\nif test_db.exists():\n    test_db.unlink()\n\nimport pytest\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom app.db.database import Base, get_db\nfrom app.models.models import *  # Import all models\n\n# Create test engine\nengine = create_engine(\n    \"sqlite:///test_run.db\",\n    connect_args={\"check_same_thread\": False}\n)\n\n# Create all tables\nBase.metadata.create_all(bind=engine)\n\n# Test session factory\nTestingSessionLocal = sessionmaker(\n    autocommit=False, \n    autoflush=False, \n    bind=engine\n)\n\n\n@pytest.fixture\ndef db():\n    \"\"\"Provide database session for tests.\"\"\"\n    session = TestingSessionLocal()\n    try:\n        yield session\n    finally:\n        session.close()\n\n\n@pytest.fixture\ndef sample_party(db):\n    \"\"\"Create a sample party for testing.\"\"\"\n    from app.models.models import Party\n\n    party = Party(\n        party_id=\"TEST-001\",\n        party_type=\"supplier\",\n        name=\"Test Supplier\",\n        kyc_score=75.0,\n        company_age_days=1000,\n        batch_id=\"TEST_BATCH\"\n    )\n    db.add(party)\n    db.commit()\n    db.refresh(party)\n    return party\n</code></pre>"},{"location":"testing/strategy/#test-categories","title":"Test Categories","text":""},{"location":"testing/strategy/#unit-tests","title":"Unit Tests","text":"<p>Test individual functions in isolation:</p> <pre><code># test_ttl_cache.py\n\nimport time\nfrom app.cache.ttl_cache import TTLCache\n\n\ndef test_cache_set_get():\n    \"\"\"Test basic cache operations.\"\"\"\n    cache = TTLCache(default_ttl=60)\n\n    cache.set(\"key1\", \"value1\")\n    assert cache.get(\"key1\") == \"value1\"\n\n\ndef test_cache_expiration():\n    \"\"\"Test TTL expiration.\"\"\"\n    cache = TTLCache(default_ttl=1)  # 1 second TTL\n\n    cache.set(\"key1\", \"value1\")\n    assert cache.get(\"key1\") == \"value1\"\n\n    time.sleep(1.5)\n    assert cache.get(\"key1\") is None\n\n\ndef test_cache_delete():\n    \"\"\"Test cache deletion.\"\"\"\n    cache = TTLCache(default_ttl=60)\n\n    cache.set(\"key1\", \"value1\")\n    cache.delete(\"key1\")\n    assert cache.get(\"key1\") is None\n</code></pre>"},{"location":"testing/strategy/#integration-tests","title":"Integration Tests","text":"<p>Test service interactions:</p> <pre><code># test_feature_pipeline.py\n\nfrom app.services.feature_pipeline_service import FeaturePipelineService\n\n\ndef test_feature_extraction_pipeline(db, sample_party):\n    \"\"\"Test complete feature extraction.\"\"\"\n    service = FeaturePipelineService(db)\n\n    features = service.extract_all_features(sample_party.party_id)\n\n    assert len(features) &gt; 0\n    assert any(f.feature_name == \"kyc_score\" for f in features)\n    assert any(f.feature_name == \"company_age_days\" for f in features)\n\n\ndef test_feature_extraction_with_transactions(db, sample_party):\n    \"\"\"Test feature extraction with transaction data.\"\"\"\n    from app.models.models import Transaction, Relationship\n\n    # Create counterparty\n    counterparty = Party(\n        party_id=\"COUNTER-001\",\n        party_type=\"manufacturer\",\n        name=\"Counterparty Inc\",\n        batch_id=\"TEST_BATCH\"\n    )\n    db.add(counterparty)\n\n    # Create relationship\n    rel = Relationship(\n        party_id=sample_party.party_id,\n        counterparty_id=\"COUNTER-001\",\n        relationship_type=\"customer\"\n    )\n    db.add(rel)\n\n    # Create transactions\n    for i in range(5):\n        txn = Transaction(\n            party_id=sample_party.party_id,\n            counterparty_id=\"COUNTER-001\",\n            amount=1000.0 + i * 100,\n            currency=\"USD\"\n        )\n        db.add(txn)\n\n    db.commit()\n\n    service = FeaturePipelineService(db)\n    features = service.extract_all_features(sample_party.party_id)\n\n    # Should have transaction features\n    feature_names = [f.feature_name for f in features]\n    assert \"txn_count\" in feature_names\n    assert \"avg_amount\" in feature_names\n</code></pre>"},{"location":"testing/strategy/#service-tests","title":"Service Tests","text":"<p>Test business logic:</p> <pre><code># test_scorecard_service.py\n\nfrom app.services.scoring_service import ScoringService\n\n\ndef test_compute_score(db, sample_party):\n    \"\"\"Test score computation.\"\"\"\n    service = ScoringService(db)\n\n    result = service.compute_score(sample_party.party_id)\n\n    assert \"total_score\" in result\n    assert 300 &lt;= result[\"total_score\"] &lt;= 900\n    assert result[\"band\"] in [\"excellent\", \"good\", \"fair\", \"poor\", \"very_poor\"]\n\n\ndef test_score_breakdown(db, sample_party):\n    \"\"\"Test score breakdown components.\"\"\"\n    service = ScoringService(db)\n\n    result = service.compute_score(sample_party.party_id)\n\n    assert \"breakdown\" in result\n    breakdown = result[\"breakdown\"]\n\n    # Should have component scores\n    assert \"kyc_score\" in breakdown or \"base_score\" in breakdown\n\n\ndef test_batch_scoring(db):\n    \"\"\"Test scoring multiple parties.\"\"\"\n    # Create multiple parties\n    for i in range(5):\n        party = Party(\n            party_id=f\"BATCH-{i:03d}\",\n            party_type=\"supplier\",\n            name=f\"Batch Party {i}\",\n            kyc_score=60 + i * 5,\n            batch_id=\"BATCH_TEST\"\n        )\n        db.add(party)\n    db.commit()\n\n    service = ScoringService(db)\n    results = service.score_batch(\"BATCH_TEST\")\n\n    assert len(results) == 5\n    assert all(\"total_score\" in r for r in results)\n</code></pre>"},{"location":"testing/strategy/#rule-evaluator-tests","title":"Rule Evaluator Tests","text":"<p>Test decision rules:</p> <pre><code># test_rule_evaluator.py\n\nfrom app.rules.evaluator import RuleEvaluator\n\n\ndef test_simple_rule():\n    \"\"\"Test simple comparison rule.\"\"\"\n    evaluator = RuleEvaluator()\n\n    rule = \"score &gt;= 700\"\n    context = {\"score\": 750}\n\n    assert evaluator.evaluate(rule, context) is True\n\n\ndef test_complex_rule():\n    \"\"\"Test complex rule with multiple conditions.\"\"\"\n    evaluator = RuleEvaluator()\n\n    rule = \"score &gt;= 700 and risk_flags == 0\"\n    context = {\"score\": 750, \"risk_flags\": 0}\n\n    assert evaluator.evaluate(rule, context) is True\n\n\ndef test_rule_with_functions():\n    \"\"\"Test rule with function calls.\"\"\"\n    evaluator = RuleEvaluator()\n\n    rule = \"abs(score_change) &lt; 50\"\n    context = {\"score_change\": -30}\n\n    assert evaluator.evaluate(rule, context) is True\n\n\ndef test_invalid_rule():\n    \"\"\"Test handling of invalid rules.\"\"\"\n    evaluator = RuleEvaluator()\n\n    result = evaluator.evaluate(\"invalid syntax {{{\", {})\n\n    assert result is False\n</code></pre>"},{"location":"testing/strategy/#fixtures","title":"Fixtures","text":""},{"location":"testing/strategy/#common-fixtures","title":"Common Fixtures","text":"<pre><code>@pytest.fixture\ndef sample_party_with_history(db, sample_party):\n    \"\"\"Party with transaction history.\"\"\"\n    from app.models.models import Transaction\n    from datetime import datetime, timedelta\n\n    for i in range(10):\n        txn = Transaction(\n            party_id=sample_party.party_id,\n            counterparty_id=\"COUNTER-001\",\n            amount=1000.0,\n            transaction_date=datetime.utcnow() - timedelta(days=i*30)\n        )\n        db.add(txn)\n\n    db.commit()\n    return sample_party\n\n\n@pytest.fixture\ndef sample_network(db, sample_party):\n    \"\"\"Party with network relationships.\"\"\"\n    from app.models.models import Relationship, Party\n\n    for i in range(5):\n        counterparty = Party(\n            party_id=f\"NETWORK-{i:03d}\",\n            party_type=\"distributor\",\n            name=f\"Network Party {i}\",\n            batch_id=\"TEST_BATCH\"\n        )\n        db.add(counterparty)\n\n        rel = Relationship(\n            party_id=sample_party.party_id,\n            counterparty_id=f\"NETWORK-{i:03d}\",\n            relationship_type=\"supplier\"\n        )\n        db.add(rel)\n\n    db.commit()\n    return sample_party\n\n\n@pytest.fixture\ndef scored_party(db, sample_party):\n    \"\"\"Party with existing score.\"\"\"\n    from app.services.scoring_service import ScoringService\n\n    service = ScoringService(db)\n    service.compute_score(sample_party.party_id)\n    return sample_party\n</code></pre>"},{"location":"testing/strategy/#mocking-strategy","title":"Mocking Strategy","text":""},{"location":"testing/strategy/#when-to-mock","title":"When to Mock","text":"<ul> <li>External API calls</li> <li>Time-dependent functions</li> <li>Random number generators</li> <li>File system operations (optional)</li> </ul>"},{"location":"testing/strategy/#what-not-to-mock","title":"What NOT to Mock","text":"<ul> <li>Database operations</li> <li>Service layer interactions</li> <li>Model validations</li> </ul>"},{"location":"testing/strategy/#mock-examples","title":"Mock Examples","text":"<pre><code>from unittest.mock import patch, MagicMock\n\ndef test_with_mocked_time():\n    \"\"\"Test time-dependent behavior.\"\"\"\n    with patch('app.cache.ttl_cache.time') as mock_time:\n        mock_time.time.return_value = 1000\n\n        cache = TTLCache(default_ttl=60)\n        cache.set(\"key\", \"value\")\n\n        mock_time.time.return_value = 1100  # 100 seconds later\n        assert cache.get(\"key\") is None\n\n\ndef test_with_mocked_external_api():\n    \"\"\"Test with mocked external service.\"\"\"\n    with patch('app.adapters.external_adapter.requests.get') as mock_get:\n        mock_get.return_value.json.return_value = {\"data\": \"value\"}\n\n        adapter = ExternalAdapter()\n        result = adapter.fetch(\"endpoint\")\n\n        assert result == {\"data\": \"value\"}\n</code></pre>"},{"location":"testing/strategy/#test-coverage","title":"Test Coverage","text":""},{"location":"testing/strategy/#generate-coverage-report","title":"Generate Coverage Report","text":"<pre><code>cd backend\npytest --cov=app --cov-report=html tests/\n</code></pre>"},{"location":"testing/strategy/#coverage-targets","title":"Coverage Targets","text":"Module Target Services 90% Extractors 85% Rules 95% Models 80% API Routes 75%"},{"location":"testing/strategy/#best-practices","title":"Best Practices","text":"<ol> <li>One Assertion Focus: Each test should verify one concept</li> <li>Descriptive Names: Test names should describe what is tested</li> <li>Setup in Fixtures: Move common setup to fixtures</li> <li>Clean Teardown: Ensure tests clean up after themselves</li> <li>Independence: Tests should not depend on execution order</li> <li>Fast Execution: Keep tests fast for quick feedback</li> </ol>"}]}